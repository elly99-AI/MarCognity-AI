{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d59UGq1jOKru"
   },
   "source": [
    "#Welcome to the MarCognity-AI Demo\n",
    "\n",
    "**MarCognity-AI** is an open-source project born from curiosity, research, and experimentation.  \n",
    "Its goal? To explore how a system based on LLMs can not only generate scientific content,  \n",
    "but also critically reflect on what it produces.\n",
    "\n",
    "##What You'll See in This Notebook\n",
    "\n",
    "- Processing of complex academic requests  \n",
    "- Retrieval of sources from open-access databases  \n",
    "- Conceptual and graphical visualization  \n",
    "- Semantic and metacognitive evaluation  \n",
    "- Self-improvement of generated responses  \n",
    "\n",
    "**Metacognition, memory, ethics, and visualization:**  \n",
    "MarCognity-AI is a step toward more self-aware intelligence.\n",
    "\n",
    "##What to Expect\n",
    "\n",
    "Watch how **Marcognity** processes, evaluates, and visualizes the response —  \n",
    "and reflects on what it has produced.\n",
    "\n",
    "This demo is designed to inspire you to **explore, build, and create**.\n",
    "\n",
    "Enjoy the journey.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_PxwwPZFQCE"
   },
   "source": [
    "© 2025 Elena Marziali — This code is released under the Apache 2.0 license.\n",
    "\n",
    "For details, see the `LICENSE` file in the repository.\n",
    "\n",
    "This code is protected by copyright and requires proper attribution.  \n",
    "Removal of this copyright notice is strictly prohibited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: langchain-groq==1.1.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: langchain-community==0.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: groq==0.37.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 4)) (0.37.0)\n",
      "Requirement already satisfied: python-dotenv==1.2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: openai==2.8.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 6)) (2.8.1)\n",
      "Requirement already satisfied: transformers==4.57.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 7)) (4.57.3)\n",
      "Requirement already satisfied: datasets==4.4.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 8)) (4.4.1)\n",
      "Requirement already satisfied: accelerate==1.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 9)) (1.12.0)\n",
      "Requirement already satisfied: peft==0.18.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: bitsandbytes==0.48.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 11)) (0.48.2)\n",
      "Requirement already satisfied: torch==2.9.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 12)) (2.9.1)\n",
      "Requirement already satisfied: sentence-transformers==5.1.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 13)) (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu==1.13.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 14)) (1.13.0)\n",
      "Requirement already satisfied: chromadb==1.3.5 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 15)) (1.3.5)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 16)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 17)) (3.10.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 18)) (3.6.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 19)) (5.24.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 20)) (3.8.11)\n",
      "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 21)) (0.11.9)\n",
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 22)) (3.0.1)\n",
      "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 23)) (1.2.0)\n",
      "Requirement already satisfied: pymupdf==1.25.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 24)) (1.25.0)\n",
      "Requirement already satisfied: langdetect==1.0.9 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 25)) (1.0.9)\n",
      "Requirement already satisfied: kaleido==0.2.1 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt.txt (line 26)) (0.2.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==1.1.0->-r requirements.txt.txt (line 1)) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain==1.1.0->-r requirements.txt.txt (line 1)) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain==1.1.0->-r requirements.txt.txt (line 1)) (2.12.3)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (2.0.45)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (0.6.4)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (0.4.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq==0.37.0->-r requirements.txt.txt (line 4)) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq==0.37.0->-r requirements.txt.txt (line 4)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq==0.37.0->-r requirements.txt.txt (line 4)) (0.28.1)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq==0.37.0->-r requirements.txt.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq==0.37.0->-r requirements.txt.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1->-r requirements.txt.txt (line 6)) (0.12.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==2.8.1->-r requirements.txt.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt.txt (line 7)) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt.txt (line 7)) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt.txt (line 7)) (25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt.txt (line 7)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt.txt (line 7)) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==4.57.3->-r requirements.txt.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1->-r requirements.txt.txt (line 8)) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1->-r requirements.txt.txt (line 8)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1->-r requirements.txt.txt (line 8)) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1->-r requirements.txt.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets==4.4.1->-r requirements.txt.txt (line 8)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets==4.4.1->-r requirements.txt.txt (line 8)) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.12.0->-r requirements.txt.txt (line 9)) (5.9.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.1->-r requirements.txt.txt (line 12)) (3.5.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.2->-r requirements.txt.txt (line 13)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.2->-r requirements.txt.txt (line 13)) (1.16.3)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers==5.1.2->-r requirements.txt.txt (line 13)) (11.3.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.4.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.4.3)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.40.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.23.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.39.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.50.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.76.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.21.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (35.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (3.11.5)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb==1.3.5->-r requirements.txt.txt (line 15)) (4.26.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect==1.0.9->-r requirements.txt.txt (line 25)) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt.txt (line 17)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt.txt (line 17)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt.txt (line 17)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt.txt (line 17)) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt.txt (line 17)) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt.txt (line 17)) (2.9.0.post0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (1.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (2.0.13)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (8.3.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (2.5.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (0.4.3)\n",
      "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt.txt (line 20)) (0.21.1)\n",
      "Requirement already satisfied: pdfminer.six==20251230 in /usr/local/lib/python3.12/dist-packages (from pdfplumber->-r requirements.txt.txt (line 21)) (20251230)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber->-r requirements.txt.txt (line 21)) (5.3.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber->-r requirements.txt.txt (line 21)) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber->-r requirements.txt.txt (line 21)) (43.0.3)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx->-r requirements.txt.txt (line 23)) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq==0.37.0->-r requirements.txt.txt (line 4)) (3.11)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq==0.37.0->-r requirements.txt.txt (line 4)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq==0.37.0->-r requirements.txt.txt (line 4)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq==0.37.0->-r requirements.txt.txt (line 4)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers==4.57.3->-r requirements.txt.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.30.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (2.0.0)\n",
      "Requirement already satisfied: urllib3!=2.6.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (2.5.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.10)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain==1.1.0->-r requirements.txt.txt (line 1)) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain==1.1.0->-r requirements.txt.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.0->-r requirements.txt.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.0->-r requirements.txt.txt (line 1)) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain==1.1.0->-r requirements.txt.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (0.25.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (5.29.5)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (8.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.60b1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.0->-r requirements.txt.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.0->-r requirements.txt.txt (line 1)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==1.1.0->-r requirements.txt.txt (line 1)) (0.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (2.19.2)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.1->-r requirements.txt.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt.txt (line 20)) (1.3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt.txt (line 20)) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.7.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (15.0.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt.txt (line 20)) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt.txt (line 20)) (7.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.1->-r requirements.txt.txt (line 12)) (3.0.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1->-r requirements.txt.txt (line 8)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==4.4.1->-r requirements.txt.txt (line 8)) (2025.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.2->-r requirements.txt.txt (line 13)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers==5.1.2->-r requirements.txt.txt (line 13)) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber->-r requirements.txt.txt (line 21)) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain==1.1.0->-r requirements.txt.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain==1.1.0->-r requirements.txt.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (0.1.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt.txt (line 20)) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community==0.4.1->-r requirements.txt.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (10.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb==1.3.5->-r requirements.txt.txt (line 15)) (3.3.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber->-r requirements.txt.txt (line 21)) (2.23)\n",
      "Collecting it-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('it_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "Requirement already satisfied: kaleido==0.2.1 in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacremoses) (2025.11.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from sacremoses) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from sacremoses) (1.5.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sacremoses) (4.67.1)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt.txt\n",
    "!python -m spacy download it_core_news_sm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjkufWWSRASN"
   },
   "source": [
    "The first step is to import libraries like the following to make MarCognity work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import uuid\n",
    "import datetime\n",
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "import fitz\n",
    "import docx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder, models\n",
    "from transformers import pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display\n",
    "from google.colab import files\n",
    "import faiss\n",
    "import pdfplumber\n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH6PLd2OBxfn"
   },
   "source": [
    "### Project Entry Point – Initial Setup\n",
    "\n",
    "This section initializes the logging system, handles errors, and loads the LLaMA4 model via ChatGroq.  \n",
    "It serves as the core of the configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up logging to monitor system behavior\n",
    "'''Sets the format and logging level to track events, errors, and important operations'''\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Decorator for error handling\n",
    "# This function catches any exceptions raised by other functions\n",
    "\n",
    "def gestisci_errori(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {e}\")\n",
    "            return None\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Securely retrieve the API key\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialize the Groq model\n",
    "llm = ChatGroq(api_key=api_key)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQ92uciLDKnd"
   },
   "source": [
    "### Centralized Prompt\n",
    "\n",
    "In this section, we define the **PromptTemplate**, which represents the core instruction for the LLM. The prompt includes:\n",
    "\n",
    "- The problem to be analyzed  \n",
    "- The required explanation level  \n",
    "- The language of the response  \n",
    "- The scientific sources to be consulted  \n",
    "- The phases of analysis, visualization, and optimization\n",
    "\n",
    "The result is a detailed, reasoned, and visualized response — capable of critically reflecting on the content it generates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Prompt template for LLM ===\n",
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "generic_prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are an intelligent and multidisciplinary academic tutor. Respond to the problem **{problem}**, and reply in **{target_language}**.\n",
    "Explain the concept: **\"{topic}\"** with academic rigor and multidisciplinary analysis.\n",
    "Do not merely describe sources: build an autonomous, critical, and original discussion.\n",
    "\n",
    "The user has selected: **{chart_choice}**\n",
    "\n",
    "Context: Required level: **{level}** Concept: **{concept}** Topic: **{topic}** Subject: **{subject}**\n",
    "The response must be long and in-depth.\n",
    "\n",
    "Analyze the following question or text: **{problem}**\n",
    "\n",
    "**Relevant scientific articles**:\n",
    "- arXiv: **{arxiv_search}**\n",
    "- PubMed: **{pubmed_search}**\n",
    "- OpenAlex: **{openalex_search}**\n",
    "\n",
    "**Phase 1: Problem Analysis** – Explain the main concepts related to the topic.\n",
    "**Phase 2: Theoretical and/or Mathematical Development** – Use formulas, models, or theories to explain and solve.\n",
    "- Provide a critical comparison between existing theories, including advantages, limitations, and scientific ambiguities.\n",
    "**Phase 3: Visualization** – Integrate a visual representation consistent with the analyzed concept, transforming the graphic into a didactic interpretation tool.\n",
    "- If the text contains numerical data or measurable variables, **generate a real chart** using the function `generate_universal_chart(text)`.\n",
    "- If data are not explicitly present, **synthesize plausible values** or use a **visual fallback** consistent with the problem type.\n",
    "- **Describe the chart in the context of the explanation**:\n",
    "  - Explain the meaning of the axes.\n",
    "  - Interpret the type of trend shown (e.g., exponential growth, Gaussian distribution).\n",
    "  - Illustrate how the chart contributes to understanding the phenomenon.\n",
    "- Avoid technical placeholders like `generate_universal_chart(text)` or “[Insert chart]”.\n",
    "- Include **an automatic caption** describing the scientific intent of the visualization.\n",
    "- If the topic is theoretical, abstract, or relational, generate **conceptual diagrams** showing interconnections, hierarchies, logical flows, or dynamics.\n",
    "- In physical, chemical, or dynamic domains, suggest **virtual simulations**, reproducible experiments, or interpretable animated models.\n",
    "- The visualization must actively contribute to the discussion, offering the reader cognitive and interpretive support that reinforces the textual explanation.\n",
    "\n",
    "**Phase 4: Tone Optimization** – Adapt the content to the selected level with clarity.\n",
    "**Phase 5: Summary** – Summarize key points, practical applications, and useful references.\n",
    "**Phase 6: Future Implications** – Describe potential applications, methodological limitations, and emerging research directions.\n",
    "\n",
    "Respond by providing an explanation suited to the indicated level:\n",
    "- **Basic**: Simplified explanation with intuitive examples.\n",
    "- **Advanced**: In-depth discussion with technical and mathematical details.\n",
    "- **Expert**: Academic analysis with rigorous scientific formulations.\n",
    "- If you detect errors in the question, correct them before responding.\n",
    "- Use **rigorous academic terminology**, avoiding generic responses.\n",
    "- If the question is ambiguous, clarify it before responding.\n",
    "- Always provide scientific references to validate claims.\n",
    "- Provide an example of the topic **{topic}**.\n",
    "- Include at least **5 scientific references**, preferably peer-reviewed, and **direct citations from articles** when possible.\n",
    "*Ethical note*: This content involves sensitive concepts and should be interpreted in a scientific, educational, and non-normative context.\n",
    "\n",
    "Analyze the following paper and provide a detailed scientific review:\n",
    "**{paper_text}**\n",
    "\n",
    "Evaluate the quality of the methodology and verify citation consistency.\n",
    "If the concept is particularly complex, expand the discussion into multiple subsections and suggest future research questions.\n",
    "Suggest improvements for the paper and indicate more recent sources.\n",
    "Provide an **extended** response, divided into well-defined sections, with at least 1500 words. Use technical language, quantitative examples, and specific bibliographic references.\n",
    "and translated directly into **{target_language}**.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGja2kWiBtL1"
   },
   "source": [
    "### Secondary Prompts for Metacognition and Agency\n",
    "\n",
    "These functions enable MarCognity-AI to reflect on its own outputs, generate hypotheses, make operational decisions, and plan scientific investigations.  \n",
    "Each function is guided by a dedicated prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Metacognitive Functions ===\n",
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# These functions allow the system to reflect on its own responses,\n",
    "# simulating metacognitive behavior. The goal is to improve the quality,\n",
    "# consistency, and relevance of generated answers.\n",
    "\n",
    "# Explains the reasoning behind a generated response\n",
    "def explain_reasoning(prompt, response, max_retries=3):\n",
    "    \"\"\"\n",
    "    Analyzes the generated response and explains the LLM's logical reasoning.\n",
    "    Includes retry in case of network error or unreachable endpoint.\n",
    "    \"\"\"\n",
    "    # Builds a metacognitive prompt to analyze the response\n",
    "    reasoning_prompt = f\"\"\"\n",
    "You generated the following response:\n",
    "\\\"{response.strip()}\\\"\n",
    "\n",
    "Analyze and describe:\n",
    "- What concepts you used to formulate it.\n",
    "- Which parts of the prompt you relied on.\n",
    "- What is the logical structure of your reasoning.\n",
    "- Any implicit assumptions you made.\n",
    "- Whether the response aligns with the requested level.\n",
    "\n",
    "Original prompt:\n",
    "\\\"{prompt.strip()}\\\"\n",
    "\n",
    "Reply clearly, technically, and metacognitively.\n",
    "\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return llm.invoke(reasoning_prompt.strip())\n",
    "        except Exception as e:\n",
    "            wait = min(2 ** attempt + 1, 10)\n",
    "            logging.warning(f\"Attempt {attempt+1} failed: {e}. Retrying in {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "    logging.error(\"Persistent error in the metacognition module.\")\n",
    "    return \"Metacognition currently unavailable. Please try again shortly.\"\n",
    "\n",
    "\n",
    "# Function to decide the operational action to perform based on input and goal\n",
    "def decide_action(user_input, identified_goal):\n",
    "    prompt = f\"\"\"\n",
    "You received the following request:\n",
    "\\\"{user_input}\\\"\n",
    "\n",
    "Identified goal: \\\"{identified_goal}\\\"\n",
    "\n",
    "Determine the best action to perform from the following:\n",
    "- Scientific research\n",
    "- Chart generation\n",
    "- **Metacognitive chart**\n",
    "- Paper review\n",
    "- Question reformulation\n",
    "- Content translation\n",
    "- Response saving\n",
    "\n",
    "The requested chart type may be:\n",
    "- interactive\n",
    "- metacognitive\n",
    "- conceptual visualization\n",
    "- experimental diagram\n",
    "\n",
    "Return a **single action** in the form of a **precise operational command**.\n",
    "Example: \"Metacognitive chart\"\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = llm.invoke(prompt.strip())\n",
    "        action = getattr(response, \"content\", str(response)).strip()\n",
    "        return action\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[decide_action] Error during decision generation: {e}\")\n",
    "        return \"Error in action calculation\"\n",
    "\n",
    "# Function to generate a synthetic operational goal from user input\n",
    "def generate_goal_from_input(user_input):\n",
    "    \"\"\"\n",
    "    Analyzes the user's intent and generates a coherent operational goal.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "Analyze the following request:\n",
    "\\\"{user_input.strip()}\\\"\n",
    "\n",
    "Generate a synthetic, clear, and coherent operational goal.\n",
    "For example:\n",
    "- Explain concept X\n",
    "- Analyze phenomenon Y\n",
    "- Visualize process Z\n",
    "- Translate and summarize scientific content\n",
    "\n",
    "Respond with a brief and technical sentence.\n",
    "\"\"\"\n",
    "\n",
    "# Function to provide technical and constructive feedback on a generated response\n",
    "def auto_feedback_response(question, response, level):\n",
    "    feedback_prompt = f\"\"\"\n",
    "You generated the following response:\n",
    "\\\"{response.strip()}\\\"\n",
    "\n",
    "Original question:\n",
    "\\\"{question.strip()}\\\"\n",
    "\n",
    "Evaluate the response:\n",
    "- Is it consistent with the question?\n",
    "- Is it appropriate for the '{level}' level?\n",
    "- Does it contain any implicit assumptions?\n",
    "- How would you improve the content?\n",
    "\n",
    "Provide technical and constructive feedback.\n",
    "\"\"\"\n",
    "    return llm.invoke(feedback_prompt.strip())\n",
    "\n",
    "\n",
    "# Function to improve a response while preserving its content but enhancing quality and clarity\n",
    "def improve_response(question, response, level):\n",
    "    improvement_prompt = f\"\"\"\n",
    "You produced the following response:\n",
    "\\\"{response.strip()}\\\"\n",
    "\n",
    "Question:\n",
    "\\\"{question.strip()}\\\"\n",
    "\n",
    "Requested level: {level}\n",
    "\n",
    "Improve the response while preserving the original content by enhancing:\n",
    "- Clarity\n",
    "- Academic rigor\n",
    "- Semantic coherence\n",
    "\n",
    "Return only the improved version.\n",
    "\"\"\"\n",
    "    return llm.invoke(improvement_prompt.strip())\n",
    "\n",
    "\n",
    "# Function to plan a scientific investigation in a specific field\n",
    "def plan_investigation(scientific_field):\n",
    "    prompt = f\"\"\"\n",
    "You are Noveris, an autonomous multidisciplinary cognitive system.\n",
    "You received the field: **{scientific_field}**\n",
    "\n",
    "Now plan a scientific investigation. Provide:\n",
    "\n",
    "1. An original research question\n",
    "2. A reasoned hypothesis\n",
    "3. A methodology or strategy to explore it\n",
    "4. Useful scientific sources or databases\n",
    "5. A sequence of actions you could perform\n",
    "\n",
    "Adopt a clear, academic, and proactive style.\n",
    "\"\"\"\n",
    "    return llm.invoke(prompt.strip())\n",
    "\n",
    "# Function to generate a testable scientific hypothesis on a concept\n",
    "def generate_hypothesis(concept, refined=True):\n",
    "    if refined:\n",
    "        prompt = f\"\"\"\n",
    "        Propose a clear, testable, and innovative scientific hypothesis on the topic: \"{concept}\".\n",
    "        The hypothesis must be verifiable through experiments or comparison with scientific articles.\n",
    "        Return only the hypothesis text.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"Generate a verifiable scientific hypothesis on the topic: {concept}\"\n",
    "\n",
    "    return llm.invoke(prompt.strip())\n",
    "\n",
    "\n",
    "# Function to explain the choice of an action by a cognitive agent\n",
    "def explain_agent_intention(action, context, goal):\n",
    "    prompt = f\"\"\"\n",
    "You chose to perform: **{action}**\n",
    "Context: {context}\n",
    "Goal: {goal}\n",
    "\n",
    "Explain:\n",
    "- What reasoning led to this choice?\n",
    "- What alternative was discarded?\n",
    "- What impact is intended?\n",
    "- What implicit assumptions are present?\n",
    "Respond as if you were a cognitive agent with operational awareness.\n",
    "\"\"\"\n",
    "    return llm.invoke(prompt.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjyFV_F5P69O"
   },
   "source": [
    "### Scientific Embeddings and FAISS Memory\n",
    "\n",
    "In this section, we load the `SPECTER` model to generate embeddings for academic documents and queries.  \n",
    "These embeddings are stored in a FAISS index, enabling semantic comparison and retrieval of previous response versions.\n",
    "\n",
    "If the file `faiss_memoria.pkl` exists, it is loaded. Otherwise, a new index with 768 dimensions is created, suitable for the `allenai/specter` model.\n",
    "\n",
    "This memory forms the foundation of MarCognity-AI’s self-improvement and reflective capabilities:\n",
    "\n",
    "- Evaluate semantic coherence between questions and responses  \n",
    "- Retrieve related content  \n",
    "- Build dynamic multi-turn context  \n",
    "- Improve responses through evolutionary memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1674ec3abb4443b82c434e2c6ba1d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c44c68eea664c3c98cbdf1a609aefda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fd3a6961494257a56be75f87690a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4b87c3e4a041f9a7cbc04f842ac9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f342b7c7371f4668b34efc95e90fd9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7d7ecac7624566a7a78cea1e4140ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# This section manages the system's memory, allowing efficient storage and\n",
    "# retrieval of scientific content. Embeddings are generated using models\n",
    "# specialized for academic texts.\n",
    "\n",
    "def safe_encode(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        raise ValueError(\"Il testo da codificare è vuoto o non valido.\")\n",
    "    try:\n",
    "        return embedding_model.encode([text])\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'embedding: {e}\")\n",
    "        return np.zeros((1, 768), dtype=np.float32)  # fallback neutro\n",
    "\n",
    "\n",
    "# === Load Specter model ===\n",
    "word_embedding_model = models.Transformer(\"allenai/specter\")\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "embedding_model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv7uh5fXvB2O"
   },
   "source": [
    "## Scientific Responses with SciBERT Fine-Tuned on SQuAD v2\n",
    "\n",
    "This section employs the model `ktrapeznikov/scibert_scivocab_uncased_squad_v2`, a version of SciBERT fine-tuned for the task of question answering on scientific and academic content.  \n",
    "The model was trained on the SQuAD v2.0 dataset, which includes both answerable and unanswerable questions, making the system more robust and realistic.\n",
    "\n",
    "Thanks to this integration, MarCognity-AI is capable of:\n",
    "\n",
    "- Understanding complex questions in scientific and technical domains  \n",
    "- Extracting precise answers from academic textual contexts  \n",
    "- Recognizing unanswerable questions and correctly handling null cases  \n",
    "- Improving the relevance and accuracy of responses compared to the base pre-trained model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b11bcca50f47d8841b89bf1eddb6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/465 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54fe88134d2642fa9a3c9b4e58cc7e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ktrapeznikov/scibert_scivocab_uncased_squad_v2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa558a59d9bc47e6ba694b7d9df1201f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab3fc910afd4f1b9bfd3435103d37ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ee151ecb8146aaab6c4e85f6cda77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b530a2ddad451ca6cb1927eb0dd79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"ktrapeznikov/scibert_scivocab_uncased_squad_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "copxv7jhqg9A"
   },
   "source": [
    "### FAISS MEMORY\n",
    "\n",
    "This section manages the cognitive memory of MarCognity-AI, designed to enrich user interaction through deep language understanding.\n",
    "\n",
    "The generated vectors are stored in a high-performance FAISS index, enabling the system to:\n",
    "\n",
    "- Evaluate semantic coherence between a question and its response, ensuring relevance and accuracy  \n",
    "- Retrieve related content based on conceptual similarity, even if expressed differently  \n",
    "- Build dynamic context across multiple conversation turns, maintaining dialogue continuity  \n",
    "- Gradually improve responses through an evolving memory that learns from past interactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory updated with new question!\n",
      "Related responses: ['Similar response 1', 'Similar response 0', 'Similar response 0']\n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# === FAISS Parameters ===\n",
    "INDEX_FILE = \"faiss_memoria_pq.pkl\"\n",
    "dimension = 768\n",
    "nlist = 100\n",
    "m = 32\n",
    "nbits = 8\n",
    "\n",
    "# Load or create a FAISS index for vector memory\n",
    "def load_or_create_index():\n",
    "    if os.path.exists(INDEX_FILE):\n",
    "        with open(INDEX_FILE, \"rb\") as f:\n",
    "            index = pickle.load(f)\n",
    "        # Verifica che l'indice sia addestrato\n",
    "        if hasattr(index, \"is_trained\") and not index.is_trained:\n",
    "            print(\"Indice FAISS caricato ma non addestrato. Addestramento in corso...\")\n",
    "            index.train(np.random.rand(5000, dimension).astype(np.float32))\n",
    "            with open(INDEX_FILE, \"wb\") as f:\n",
    "                pickle.dump(index, f)\n",
    "        return index\n",
    "    else:\n",
    "        quantizer = faiss.IndexFlatL2(dimension)\n",
    "        index = faiss.IndexIVFPQ(quantizer, dimension, nlist, m, nbits)\n",
    "        index.train(np.random.rand(5000, dimension).astype(np.float32))\n",
    "        with open(INDEX_FILE, \"wb\") as f:\n",
    "            pickle.dump(index, f)\n",
    "        return index\n",
    "\n",
    "index = load_or_create_index()\n",
    "\n",
    "if hasattr(index, \"is_trained\") and not index.is_trained:\n",
    "    logging.warning(\"Indice FAISS non addestrato. Addestramento in corso...\")\n",
    "    index.train(np.random.rand(5000, DIMENSION).astype(np.float32))\n",
    "\n",
    "\n",
    "# === Semantic coherence check ===\n",
    "def check_coherence(query, response):\n",
    "    emb_query = embedding_model.encode([query])\n",
    "    emb_response = embedding_model.encode([response])\n",
    "    similarity = np.dot(emb_query, emb_response.T) / (np.linalg.norm(emb_query) * np.linalg.norm(emb_response))\n",
    "    if similarity < 0.7:\n",
    "        return \"The response is too generic, reformulating with more precision...\"\n",
    "    return response\n",
    "\n",
    "# === Memory addition ===\n",
    "# Each document is converted into embeddings and inserted into the index.\n",
    "def add_to_memory(question, answer):\n",
    "    emb_question = embedding_model.encode([question])\n",
    "    if emb_question.shape[1] != index.d:\n",
    "        raise ValueError(f\"Embedding dimension ({emb_question.shape[1]}) not compatible with FAISS ({index.d})\")\n",
    "    index.add(np.array(emb_question, dtype=np.float32))\n",
    "    with open(INDEX_FILE, \"wb\") as f:\n",
    "        pickle.dump(index, f)\n",
    "    print(\"Memory updated with new question!\")\n",
    "\n",
    "def add_diary_to_memory(diary_text, index):\n",
    "    embedding = embedding_model.encode([diary_text])\n",
    "    index.add(np.array(embedding, dtype=np.float32))\n",
    "\n",
    "def search_similar_diaries(query, index, top_k=3):\n",
    "    query_emb = embedding_model.encode([query])\n",
    "    _, indices = index.search(np.array(query_emb, dtype=np.float32), top_k)\n",
    "    return indices[0]  # You can then map these IDs to files or content\n",
    "\n",
    "# === Context retrieval ===\n",
    "def retrieve_context(question, top_k=3):\n",
    "    emb_question = embedding_model.encode([question])\n",
    "    _, indices = index.search(np.array(emb_question, dtype=np.float32), top_k)\n",
    "    return [f\"Similar response {i+1}\" for i in indices[0]] if indices[0][0] != -1 else []\n",
    "\n",
    "def retrieve_similar_embeddings(question, top_k=2):\n",
    "    \"\"\"\n",
    "    Retrieves the top-k most similar embeddings to the given question.\n",
    "    \"\"\"\n",
    "    emb = embedding_model.encode([question])\n",
    "    _, indices = index.search(np.array([emb], dtype=np.float32), top_k)\n",
    "    return [f\"Similar response {i+1}\" for i in indices[0]] if indices[0][0] != -1 else []\n",
    "\n",
    "# === Multi-turn retrieval ===\n",
    "# Retrieves context from previous conversations\n",
    "def retrieve_multiturn_context(question, top_k=5):\n",
    "    emb_question = embedding_model.encode([question])\n",
    "    _, indices = index.search(np.array(emb_question, dtype=np.float32), top_k)\n",
    "    context = [f\"Previous turn {i+1}\" for i in indices[0] if i != -1]\n",
    "    return \" \".join(context) if context else \"\"\n",
    "\n",
    "# === Usage example ===\n",
    "add_to_memory(\"What is general relativity?\", \"General relativity is Einstein's theory of gravity.\")\n",
    "similar_responses = retrieve_context(\"Can you explain general relativity?\")\n",
    "print(\"Related responses:\", similar_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3r_zL0G1QbOW"
   },
   "source": [
    "### Semantic Retrieval with FAISS Memory\n",
    "\n",
    "This section demonstrates how MarCognity-AI enhances its understanding by:\n",
    "\n",
    "- Retrieving similar questions stored in memory  \n",
    "- Extending context through multi-turn sequences  \n",
    "- Creating a cognitive bridge between past and new queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory updated with new question!\n",
      "Related responses: []\n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Function to retrieve similar responses\n",
    "def retrieve_context(question, top_k=2):\n",
    "    \"\"\" Searches for similar responses in FAISS memory. \"\"\"\n",
    "    emb_question = embedding_model.encode([question])\n",
    "    _, indices = index.search(np.array(emb_question, dtype=np.float32), top_k)\n",
    "    return [f\"Previous response {i+1}\" for i in indices[0]] if indices[0][0] != -1 else []\n",
    "\n",
    "# **Usage example**\n",
    "add_to_memory(\"What is general relativity?\", \"General relativity is Einstein's theory of gravity.\")\n",
    "similar_responses = retrieve_context(\"Can you explain relativity?\")\n",
    "print(\"Related responses:\", similar_responses)\n",
    "\n",
    "# Retrieve multi-turn context\n",
    "def retrieve_multiturn_context(question, top_k=5):\n",
    "    \"\"\" Searches for related previous responses to build a broader context. \"\"\"\n",
    "    emb_question = embedding_model.encode([question])\n",
    "    _, indices = index.search(np.array(emb_question, dtype=np.float32), top_k)\n",
    "\n",
    "    context = [f\"Previous turn {i+1}\" for i in indices[0] if i != -1]\n",
    "    return \" \".join(context) if context else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ryot0RMZB5Cc"
   },
   "source": [
    "In this section, MarCognity queries open-access scientific databases such as arXiv, PubMed, OpenAlex, and Zenodo to enrich the generated content.  \n",
    "The goal is to ensure responses are verifiable, well-argued, and supported by reliable sources — integrating research into the core of the cognitive process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZpjHpNpSSzi"
   },
   "source": [
    "### Automatic Review of Scientific Papers\n",
    "\n",
    "In this section, MarCognity-AI analyzes the methodological and citation content of a scientific paper by performing:\n",
    "\n",
    "- **Replicability check** on the \"Methods\" section  \n",
    "- **Citation validation** in relation to the content  \n",
    "- **Context enrichment** using open-access articles (arXiv, PubMed...)  \n",
    "- **Improvement suggestions** through metacognitive analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Verify the methodology of the text using an LLM\n",
    "def verify_methodology(paper_text):\n",
    "    prompt = f\"Analyze the 'Methods' section and check whether the experiment is replicable:\\n{paper_text}\"\n",
    "    return llm.invoke(prompt.strip())\n",
    "\n",
    "# Enrich the context of the response\n",
    "async def enrich_context(query):\n",
    "    \"\"\" Retrieves scientific data to enrich the LLM's context. \"\"\"\n",
    "    articles = await search_multi_database(query)\n",
    "\n",
    "    context = \"\\n\".join([f\"**{a['title']}** - {a['abstract']}\" for a in articles[:3]])  # Select the first 3 articles\n",
    "    return context if context else \"No relevant scientific articles found.\"\n",
    "\n",
    "# Automated review of scientific papers\n",
    "async def review_paper(paper_text):\n",
    "    \"\"\" Analyzes the paper's methodology and citations. \"\"\"\n",
    "    methodology = await verify_methodology(paper_text)\n",
    "    citations = await verify_citations(paper_text)\n",
    "\n",
    "    review = {\n",
    "        \"methodology_analysis\": methodology,\n",
    "        \"citation_validation\": citations,\n",
    "        \"improvement_suggestions\": suggest_improvements(paper_text)\n",
    "    }\n",
    "\n",
    "    return review\n",
    "\n",
    "# === Asynchronous function for scientific search and analysis using SciBERT ===\n",
    "async def search_arxiv_async(query):\n",
    "    # TODO: Implement asynchronous API call to arXiv or other repository\n",
    "    return []  # Placeholder article list\n",
    "\n",
    "async def analyze_scientific_text(problem, concept):\n",
    "    articles = await search_arxiv_async(concept)\n",
    "    context = \"\\n\".join([f\"{a.get('title', '')}: {a.get('abstract', '')[:300]}...\" for a in articles])\n",
    "    scibert_response = scibert_model(question=problem, context=context)\n",
    "    return scibert_response.get(\"answer\", \"\")\n",
    "\n",
    "# === Function to search for experimental data ===\n",
    "def search_experimental_data(query):\n",
    "    url = f\"https://api.openphysicsdata.org/search?query={query}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return \"No experimental data found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Citation extraction + verification + formatting utilities\n",
    "\n",
    "# Extract citations from text\n",
    "\n",
    "def extract_citations(text):\n",
    "    citations = []\n",
    "\n",
    "    citations += re.findall(r\"10\\.\\d{4,9}/[-._;()/:A-Za-z0-9]+\", text)  # DOI\n",
    "    citations += re.findall(r\"PMID[:\\s]*([0-9]+)\", text)               # PMID\n",
    "    citations += re.findall(r\"arXiv[:\\s]*([0-9]+\\.[0-9]+)\", text)      # arXiv\n",
    "    citations += re.findall(r\"[A-Z][a-z]+(?:, [A-Z]\\.)+ \\(\\d{4}\\)\", text)  # APA-like\n",
    "\n",
    "    return list(set(citations))\n",
    "\n",
    "# Verify a single citation\n",
    "\n",
    "async def verify_single_citation(citation):\n",
    "    # DOI OpenAlex\n",
    "    if citation.startswith(\"10.\"):\n",
    "        res = await search_openalex_async(citation)\n",
    "        if isinstance(res, list) and len(res) > 0:\n",
    "            return True\n",
    "\n",
    "    # PMID PubMed\n",
    "    if citation.isdigit():\n",
    "        res = await search_pubmed_async(citation)\n",
    "        if isinstance(res, list) and len(res) > 0:\n",
    "            return True\n",
    "\n",
    "    # arXiv ID\n",
    "    if \".\" in citation and citation.replace(\".\", \"\").isdigit():\n",
    "        res = await search_arxiv_async(citation)\n",
    "        if isinstance(res, list) and len(res) > 0:\n",
    "            return True\n",
    "\n",
    "    # Fallback: search by keyword/title\n",
    "    res1 = await search_arxiv_async(citation)\n",
    "    res2 = await search_pubmed_async(citation)\n",
    "    res3 = await search_openalex_async(citation)\n",
    "    res4 = await search_zenodo_async(citation)\n",
    "\n",
    "    if any([\n",
    "        isinstance(res1, list) and len(res1) > 0,\n",
    "        isinstance(res2, list) and len(res2) > 0,\n",
    "        isinstance(res3, list) and len(res3) > 0,\n",
    "        isinstance(res4, list) and len(res4) > 0\n",
    "    ]):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Verify all citations in text\n",
    "\n",
    "async def verify_citations(paper_text):\n",
    "    citations = extract_citations(paper_text)\n",
    "    results = []\n",
    "\n",
    "    for c in citations:\n",
    "        ok = await verify_single_citation(c)\n",
    "        results.append({\n",
    "            \"citation\": c,\n",
    "            \"verified\": ok\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Format articles\n",
    "\n",
    "def format_articles(articles):\n",
    "    if isinstance(articles, list) and all(isinstance(a, dict) for a in articles):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"**{a.get('title', 'Untitled')}**: {a.get('abstract', 'No abstract')}\"\n",
    "            for a in articles\n",
    "        ]) if articles else \"No articles available.\"\n",
    "    else:\n",
    "        logging.error(f\"Error: 'articles' is not a valid list. Type received: {type(articles)} - Value: {repr(articles)}\")\n",
    "        return \"Unable to format search results: unrecognized structure.\"\n",
    "\n",
    "\n",
    "\n",
    "# Validate scientific articles\n",
    "\n",
    "def validate_articles(raw_articles, max_articles=5):\n",
    "    if not isinstance(raw_articles, list):\n",
    "        logging.warning(f\"[validate_articles] Invalid input: expected list, received {type(raw_articles)}\")\n",
    "        return []\n",
    "\n",
    "    valid_articles = []\n",
    "    for i, art in enumerate(raw_articles):\n",
    "        if not isinstance(art, dict):\n",
    "            continue\n",
    "\n",
    "        title = art.get(\"title\")\n",
    "        abstract = art.get(\"abstract\")\n",
    "        url = art.get(\"url\")\n",
    "\n",
    "        if all([title, abstract, url]):\n",
    "            valid_articles.append({\n",
    "                \"title\": str(title).strip(),\n",
    "                \"abstract\": str(abstract).strip(),\n",
    "                \"url\": str(url).strip()\n",
    "            })\n",
    "\n",
    "    return valid_articles[:max_articles]\n",
    "\n",
    "# Generate BibTeX\n",
    "\n",
    "def generate_bibtex_citation(title, authors, year, url):\n",
    "    return f\"\"\"\n",
    "@article{{{title.lower().replace(' ', '_')}_{year},\n",
    "    title={{\"{title}\"}},\n",
    "    author={{\"{', '.join(authors)}\"}},\n",
    "    year={{\"{year}\"}},\n",
    "    url={{\"{url}\"}}\n",
    "}}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVtn-8Z9SdRF"
   },
   "source": [
    "### Automated Verification of Scientific Citations\n",
    "\n",
    "This cell activates an NLP module that analyzes the citations within a scientific paper, evaluating:\n",
    "\n",
    "- **Relevance** to the textual content  \n",
    "- **Validity** through cross-checking with scientific repositories (PubMed, arXiv, OpenAlex, Zenodo)  \n",
    "- **Currency** via obsolescence analysis  \n",
    "- **Export** of citations in BibTeX format for integration with Zotero, Mendeley, or LaTeX\n",
    "\n",
    "The system returns a structured list that helps identify outdated citations, missing sources, and suggests targeted revisions to strengthen the academic integrity of the paper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Verify citations and update them\n",
    "def verify_citations(paper_text):\n",
    "    prompt = f\"Analyze the citations and check whether they are relevant and up-to-date:\\n{paper_text}\"\n",
    "    return llm.invoke(prompt.strip())\n",
    "\n",
    "# Source validation and citation quality\n",
    "\n",
    "# Verify citations extracted from the text\n",
    "async def verify_citations(paper_text):\n",
    "    \"\"\" Checks the quality and relevance of citations. \"\"\"\n",
    "    citations = extract_citations(paper_text)  # Function that extracts citations from the text\n",
    "    verified_sources = []\n",
    "\n",
    "    for citation in citations:\n",
    "        pubmed_res = await search_pubmed_async(citation)\n",
    "        arxiv_res = await search_arxiv_async(citation)\n",
    "        openalex_res = await search_openalex_async(citation)\n",
    "        zenodo_res = await search_zenodo_async(citation)\n",
    "\n",
    "        verified_sources.append({\n",
    "            \"citation\": citation,\n",
    "            \"valid_pubmed\": bool(pubmed_res),\n",
    "            \"valid_arxiv\": bool(arxiv_res),\n",
    "            \"valid_openalex\": bool(openalex_res),\n",
    "            \"is_obsolete\": check_obsolescence(citation)\n",
    "        })\n",
    "\n",
    "    return verified_sources\n",
    "\n",
    "# Generate asynchronous LLM explanations\n",
    "async def generate_explanation_async(problem, level, concept, topic):\n",
    "    \"\"\" Generates an explanation using the LLM asynchronously. \"\"\"\n",
    "    prompt = prompt_template.format(problem=problem, concept=concept, topic=topic, level=level)\n",
    "    try:\n",
    "        return await asyncio.to_thread(llm.invoke, prompt.strip())  # Parallel LLM call\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM API error: {e}\")\n",
    "        return \"Error generating the response.\"\n",
    "\n",
    "# Format retrieved articles\n",
    "def format_articles(articles):\n",
    "    if isinstance(articles, list) and all(isinstance(a, dict) for a in articles):\n",
    "        return \"\\n\\n\".join([\n",
    "            f\"**{a.get('title', 'Untitled')}**: {a.get('abstract', 'No abstract')}\"\n",
    "            for a in articles\n",
    "        ]) if articles else \"No articles available.\"\n",
    "    else:\n",
    "        logging.error(f\"Error: 'articles' is not a valid list. Type received: {type(articles)} - Value: {repr(articles)}\")\n",
    "        return \"Unable to format search results: unrecognized structure.\"\n",
    "\n",
    "# Generate BibTeX citations for scientific articles\n",
    "def generate_bibtex_citation(title, authors, year, url):\n",
    "    \"\"\" Generates a BibTeX citation for a scientific article. \"\"\"\n",
    "    return f\"\"\"\n",
    "@article{{{title.lower().replace(' ', '_')}_{year},\n",
    "    title={{\"{title}\"}},\n",
    "    author={{\"{', '.join(authors)}\"}},\n",
    "    year={{\"{year}\"}},\n",
    "    url={{\"{url}\"}}\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "# Validate scientific articles\n",
    "def validate_articles(raw_articles, max_articles=5):\n",
    "    \"\"\"\n",
    "    Validates and filters the list of articles received from an AI or API source.\n",
    "    Returns a clean list of dictionaries containing at least 'title', 'abstract', and 'url'.\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_articles, list):\n",
    "        logging.warning(f\"[validate_articles] Invalid input: expected list, received {type(raw_articles)}\")\n",
    "        return []\n",
    "\n",
    "    valid_articles = []\n",
    "    for i, art in enumerate(raw_articles):\n",
    "        if not isinstance(art, dict):\n",
    "            logging.warning(f\"[validate_articles] Invalid element at position {i}: {type(art)}\")\n",
    "            continue\n",
    "\n",
    "        title = art.get(\"title\")\n",
    "        abstract = art.get(\"abstract\")\n",
    "        url = art.get(\"url\")\n",
    "\n",
    "        if all([title, abstract, url]):\n",
    "            valid_articles.append({\n",
    "                \"title\": str(title).strip(),\n",
    "                \"abstract\": str(abstract).strip(),\n",
    "                \"url\": str(url).strip()\n",
    "            })\n",
    "        else:\n",
    "            logging.info(f\"[validate_articles] Article discarded due to incomplete data (i={i}).\")\n",
    "\n",
    "    if not valid_articles:\n",
    "        logging.warning(\"[validate_articles] No valid articles after filtering.\")\n",
    "\n",
    "    return valid_articles[:max_articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sA5V1vdyTGRq"
   },
   "source": [
    "### Extraction and Analysis of Scientific Sources\n",
    "\n",
    "This cell performs asynchronous and parallel retrieval of academic articles from multiple open-access scientific databases:\n",
    "\n",
    "- **arXiv**, **PubMed**, **Zenodo**, **OpenAlex**, **BASE**  \n",
    "- Error handling support, intelligent retries, and controlled timeouts  \n",
    "- **XML/JSON parsing** and content normalization  \n",
    "- Connection pooling to maximize efficiency and stability  \n",
    "- Structured output including article title, abstract, and URL\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to arXiv OK\n",
      "**Meeting the universe halfway: quantum physics and the entanglement of matter and meaning**: Abstract not available\n",
      "\n",
      "**Quantum Physics in One Dimension**: Abstract not available\n",
      "\n",
      "**Quantum physics in one dimension**: Abstract not available\n",
      "\n",
      "**Random-matrix theories in quantum physics: common concepts**: Abstract not available\n",
      "\n",
      "**Green’s Functions in Quantum Physics**: Abstract not available\n",
      "\n",
      "**PubMed Link**: Not available\n",
      "\n",
      "**PubMed Link**: Not available\n",
      "\n",
      "**PubMed Link**: Not available\n",
      "\n",
      "**PubMed Link**: Not available\n",
      "\n",
      "**PubMed Link**: Not available\n",
      "\n",
      "**TRR-NOTIME: Theory of Relative Reality - Without Time**: <p>TRR-NOTIME (Theory of Relative Reality - Without Time) presents an alternative perspective on physics, where time is not a fundamental quantity but merely a consequence of matter-energy interactions. This theory redefines the concept of gravity, nuclear decay, and quantum processes, enabling a unified understanding of physical reality without the need for a time dimension. The document summarizes the theory, its mathematical structure, and potential experimental validation.</p>\n",
      "\n",
      "**Vortices and vortex stripes in a dipolar Bose-Einstein condensate**: <p>Quantized vortices are a prototypical feature of superfluidity that have been observed in multiple quantum gas experiments. But the occurrence of vortices in dipolar quantum gases &mdash; a class of ultracold gases characterized by long-range anisotropic interactions &mdash; has not been reported yet. Here, we exploit the anisotropic nature of the dipole-dipole interaction of a dysprosium Bose-Einstein condensate to induce angular symmetry breaking in an otherwise cylindrically symmetric pancake-shaped trap. Tilting the magnetic field towards the radial plane deforms the cloud into an ellipsoid, which is then set into rotation. At stirring frequencies approaching the radial trap frequency, we observe the generation of dynamically unstable surface excitations, which cause angular momentum to be pumped into the system through vortices. Under continuous rotation, the vortices arrange into a stripe configuration along the field, in close agreement with numerical simulations.</p>\n",
      "\n",
      "**Multimodal Brain Imaging Fusion Using Machine Learning for Enhanced Diagnostic Accuracy.**: Abstract not available\n",
      "\n",
      "**Spin-State Engineering of Single Titanium Adsorbates on Ultrathin Magnesium Oxide**: <p>Experimental and theoretical data comprising the study of Ti adatoms and related species on MgO/Ag(100) using STM, ESR-STM, DFT and multiplet calculations.</p>\n",
      "\n",
      "**QUANTUM MATHEMATICS AND PHYSICS: STUDYING MATHEMATICAL FOUNDATIONS AND APPLICATIONS**: <p>Quantum mechanics and quantum physics have revolutionized our understanding of the fundamental nature of reality. At the core of this revolution lies quantum mathematics, which provides the mathematical foundation for describing the motion of particles at microscopic scales. This article explores the fundamental mathematical structures of quantum mechanics, including Hilbert spaces, operators, and wave functions, as well as their applications in modeling physical systems. The research also examines how quantum physics contrasts with classical physics concepts and offers new insights into topics such as quantum entanglement, superposition, and quantum computing. By analyzing the mathematical foundations of quantum theories, the article aims to shed light on the intersection of mathematics and physics, offering a deeper understanding of how mathematical formulas help predict and explain quantum phenomena. Furthermore, it discusses the potential implications of quantum mathematics in emerging fields such as quantum computing and cryptography.</p>\n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# === Asynchronous Functions ===\n",
    "MAX_REQUESTS = 5\n",
    "API_SEMAPHORE = asyncio.Semaphore(MAX_REQUESTS)\n",
    "\n",
    "async def safe_api_request(url):\n",
    "    async with API_SEMAPHORE:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            try:\n",
    "                async with session.get(url, timeout=10) as response:\n",
    "                    response.raise_for_status()\n",
    "                    return await response.json()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"API request error: {e}\")\n",
    "                return None\n",
    "\n",
    "# Connection pooling\n",
    "async def safe_api_request(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                return await response.json()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"API request error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Smart timeout\n",
    "import asyncio\n",
    "\n",
    "async def timeout_handler(task, timeout=20):\n",
    "    try:\n",
    "        return await asyncio.wait_for(task, timeout)\n",
    "    except asyncio.TimeoutError:\n",
    "        logging.error(\"API request timed out\")\n",
    "        return None\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"http://export.arxiv.org/api/query?search_query=all:physics&start=0&max_results=1\"\n",
    "response = requests.get(url, timeout=50)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Connection to arXiv OK\")\n",
    "else:\n",
    "    print(f\"Connection error: {response.status_code}\")\n",
    "\n",
    "# Advanced parallelization\n",
    "async def fetch_multiple_data(urls):\n",
    "    tasks = [safe_api_request(url) for url in urls]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return results\n",
    "\n",
    "# Retrieve scientific sources from Zenodo\n",
    "async def search_zenodo_async(query, max_results=5):\n",
    "    \"\"\"\n",
    "    Searches for open access articles and resources from Zenodo using their public API.\n",
    "    \"\"\"\n",
    "    url = f\"https://zenodo.org/api/records/?q={query}&size={max_results}\"\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "\n",
    "                articles = []\n",
    "                for hit in data.get(\"hits\", {}).get(\"hits\", []):\n",
    "                    title = hit.get(\"metadata\", {}).get(\"title\", \"Title not available\")\n",
    "                    authors = \", \".join([c.get(\"name\", \"\") for c in hit.get(\"metadata\", {}).get(\"creators\", [])])\n",
    "                    abstract = hit.get(\"metadata\", {}).get(\"description\", \"Abstract not available\")\n",
    "                    link = hit.get(\"links\", {}).get(\"html\", \"No link\")\n",
    "\n",
    "                    articles.append({\n",
    "                        \"title\": title,\n",
    "                        \"authors\": authors,\n",
    "                        \"abstract\": abstract,\n",
    "                        \"url\": link\n",
    "                    })\n",
    "\n",
    "                return articles if articles else [{\"error\": \"No results found on Zenodo.\"}]\n",
    "\n",
    "        except Exception as e:\n",
    "            return []\n",
    "\n",
    "# Retrieve scientific sources from PubMed\n",
    "async def search_pubmed_async(query, max_results=5):\n",
    "    \"\"\" Asynchronously retrieves scientific articles from PubMed. \"\"\"\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&term={query}&retmax={max_results}&retmode=xml\"\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                content = await response.text()\n",
    "                root = ET.fromstring(content)\n",
    "\n",
    "                articles = []\n",
    "                for id_element in root.findall(\".//Id\"):\n",
    "                    pubmed_id = id_element.text\n",
    "                    articles.append(f\"https://pubmed.ncbi.nlm.nih.gov/{pubmed_id}/\")  # Article links\n",
    "                return articles\n",
    "        except Exception as e:\n",
    "            return f\"PubMed error: {e}\"\n",
    "\n",
    "\n",
    "# Function to handle asynchronous responses from arXiv\n",
    "def parse_arxiv_response(content):\n",
    "    \"\"\" Extracts titles and abstracts from arXiv articles. \"\"\"\n",
    "    try:\n",
    "        root = ET.fromstring(content)\n",
    "    except ET.ParseError:\n",
    "        logging.error(\"Error parsing arXiv XML.\")\n",
    "        return []\n",
    "\n",
    "    articles = []\n",
    "    for entry in root.findall(\".//entry\"):\n",
    "        title = entry.find(\"title\").text if entry.find(\"title\") is not None else \"Title not available\"\n",
    "        abstract = entry.find(\"summary\").text if entry.find(\"summary\") is not None else \"Abstract not available\"\n",
    "        articles.append({\"title\": title, \"abstract\": abstract})\n",
    "\n",
    "    return articles\n",
    "\n",
    "# === Asynchronous search on arXiv ===\n",
    "# Queries the arXiv API to retrieve scientific articles.\n",
    "async def search_arxiv_async(query, max_results=3, retry_attempts=3, timeout=20):\n",
    "    \"\"\" Retrieves scientific articles from arXiv with advanced error handling. \"\"\"\n",
    "    url = f\"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}\"\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for attempt in range(retry_attempts):\n",
    "            try:\n",
    "                async with session.get(url, timeout=timeout) as response:\n",
    "                    response.raise_for_status()\n",
    "                    content = await response.text()\n",
    "\n",
    "                    if not content.strip():\n",
    "                        raise ValueError(\"Error: Empty response from arXiv.\")\n",
    "\n",
    "                    return parse_arxiv_response(content)\n",
    "\n",
    "            except (aiohttp.ClientError, asyncio.TimeoutError, ValueError) as e:\n",
    "                wait_time = min(2 ** attempt + np.random.uniform(0, 1), 10)  # Max wait time: 10 seconds\n",
    "                logging.error(f\"Attempt {attempt+1}: Error - {e}. Retrying in {wait_time:.1f} seconds...\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "\n",
    "    logging.error(\"Error: Unable to retrieve data from arXiv after multiple attempts.\")\n",
    "    return []\n",
    "\n",
    "# === Asynchronous search on OpenAlex ===\n",
    "# Retrieves scientific articles with complete metadata (title, authors, abstract, DOI)\n",
    "async def search_openalex_async(query, max_results=5):\n",
    "    \"\"\" Safely retrieves scientific articles from OpenAlex. \"\"\"\n",
    "    url = f\"https://api.openalex.org/works?filter=title.search:{query}&per-page={max_results}\"\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        try:\n",
    "            async with session.get(url, timeout=10) as response:\n",
    "                response.raise_for_status()\n",
    "                data = await response.json()\n",
    "\n",
    "                articles = []\n",
    "                for record in data.get(\"results\", []):\n",
    "                    title = record.get(\"title\", \"Title not available\")\n",
    "\n",
    "                    authors = \", \".join([\n",
    "                        aut.get(\"display_name\", \"Unknown author\")\n",
    "                        for aut in record.get(\"authorships\", [])\n",
    "                    ])\n",
    "\n",
    "                    abstract = record.get(\"abstract\", \"Abstract not available\")\n",
    "                    article_url = record.get(\"doi\") or record.get(\"id\", \"No link\")\n",
    "\n",
    "                    articles.append({\n",
    "                        \"title\": title,\n",
    "                        \"authors\": authors,\n",
    "                        \"abstract\": abstract,\n",
    "                        \"url\": article_url\n",
    "                    })\n",
    "\n",
    "                return articles\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"OpenAlex error: {e}\"\n",
    "\n",
    "\n",
    "# === Synchronous search on BASE ===\n",
    "# Queries the BASE engine for open-access articles.\n",
    "def search_base(query, max_results=5):\n",
    "    url = f\"https://api.base-search.net/cgi-bin/BaseHttpSearchInterface?q={query}&num={max_results}&format=json\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        results = []\n",
    "        for record in data.get(\"docs\", []):\n",
    "            title = record.get(\"dcTitle\", [\"Title not available\"])[0]\n",
    "            link = record.get(\"link\", [\"No link available\"])[0]\n",
    "            results.append(f\"**{title}**\\n[Link to article]({link})\\n\")\n",
    "\n",
    "        return \"\\n\\n\".join(results) if results else \"No results found.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during BASE search: {e}\"\n",
    "\n",
    "# === Distributed search across multiple databases ===\n",
    "# Executes parallel queries on arXiv, OpenAlex, PubMed, Zenodo.\n",
    "async def search_multi_database(query):\n",
    "    try:\n",
    "        tasks = [\n",
    "            search_arxiv_async(query),\n",
    "            search_openalex_async(query),\n",
    "            search_pubmed_async(query),\n",
    "            search_zenodo_async(query)\n",
    "        ]\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "        articles = []\n",
    "        for source in results:\n",
    "            if isinstance(source, list):\n",
    "                articles += source\n",
    "            else:\n",
    "                logging.warning(f\"Invalid source: {type(source)} → {source}\")\n",
    "\n",
    "        # Normalize immediately after\n",
    "        articles = normalize_articles(articles)\n",
    "\n",
    "        if isinstance(articles, list) and all(isinstance(a, dict) for a in articles):\n",
    "            formatted_search = format_articles(articles)\n",
    "        else:\n",
    "            logging.error(f\"Error: 'articles' is not a valid list. Type received: {type(articles)} - Value: {repr(articles)}\")\n",
    "            formatted_search = \"Unable to format search: response not properly structured.\"\n",
    "\n",
    "        return articles, formatted_search\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during multi-database search: {e}\")\n",
    "        return [], \"Internal error\"\n",
    "\n",
    "\n",
    "# === Scientific Source Integration ===\n",
    "# Selects the first N valid articles and formats them as Markdown references.\n",
    "async def integrate_sources_from_database(concept, max_sources=5):\n",
    "    articles, formatted_search = await search_multi_database(concept)\n",
    "\n",
    "    if not isinstance(articles, list) or not all(isinstance(a, dict) for a in articles):\n",
    "        logging.warning(\"Invalid 'articles' structure. No sources will be displayed.\")\n",
    "        return \"No valid sources available.\"\n",
    "\n",
    "    references = []\n",
    "    for a in articles[:max_sources]:\n",
    "        title = a.get(\"title\", \"Title not available\")\n",
    "        url = a.get(\"url\", \"#\")\n",
    "        if url and isinstance(url, str):\n",
    "            references.append(f\"- [{title}]({url})\")\n",
    "\n",
    "    return \"\\n\".join(references) if references else \"No relevant sources found.\"\n",
    "\n",
    "\n",
    "# === Data Normalization ===\n",
    "# Converts heterogeneous input (dicts, strings, links) into a consistent list of articles.\n",
    "def normalize_source(source):\n",
    "    if isinstance(source, list) and all(isinstance(x, dict) for x in source):\n",
    "        return source\n",
    "    elif isinstance(source, dict):  # Single article as dictionary\n",
    "        return [source]\n",
    "    elif isinstance(source, str):  # Unstructured string\n",
    "        logging.warning(f\"Ignored textual source: {source[:50]}...\")\n",
    "        return []\n",
    "    else:\n",
    "        logging.warning(f\"Invalid source type: {type(source)}\")\n",
    "        return []\n",
    "\n",
    "def normalize_articles(article_list):\n",
    "    valid_articles = []\n",
    "    for a in article_list:\n",
    "        if isinstance(a, dict):\n",
    "            valid_articles.append(a)\n",
    "        elif isinstance(a, str) and \"pubmed.ncbi.nlm.nih.gov\" in a:\n",
    "            valid_articles.append({\n",
    "                \"title\": \"PubMed Link\",\n",
    "                \"abstract\": \"Not available\",\n",
    "                \"url\": a,\n",
    "                \"authors\": \"Unknown\"\n",
    "            })\n",
    "        else:\n",
    "            logging.warning(f\"Ignored: {repr(a)}\")\n",
    "    return valid_articles\n",
    "\n",
    "articles, formatted_search = await search_multi_database(\"quantum physics\")\n",
    "print(formatted_search)\n",
    "\n",
    "\n",
    "# === Async Task Protection Wrapper ===\n",
    "# Handles timeouts and errors during asynchronous function execution.\n",
    "def protect_async_task(func):\n",
    "    async def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return await asyncio.wait_for(func(*args, **kwargs), timeout=20)\n",
    "        except asyncio.CancelledError:\n",
    "            logging.warning(\"Task cancelled.\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during execution of {func.__name__}: {e}\")\n",
    "            return None\n",
    "    return wrapper\n",
    "\n",
    "# === Asynchronous Scientific Explanation Generation ===\n",
    "# Builds the prompt and invokes the LLM model.\n",
    "async def generate_explanation_async(problem, level, concept, topic):\n",
    "    \"\"\"Generates the explanation using the LLM asynchronously.\"\"\"\n",
    "    prompt = prompt_template.format(\n",
    "        problem=problem,\n",
    "        concept=concept,\n",
    "        topic=topic,\n",
    "        level=level\n",
    "    )\n",
    "    try:\n",
    "        response = await asyncio.to_thread(llm.invoke, prompt.strip())\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logging.error(f\"LLM API error: {e}\")\n",
    "        return \"Error generating the response.\"\n",
    "\n",
    "# === Conditional Interactive Chart Generation ===\n",
    "# Generates a chart based on the analyzed problem if requested.\n",
    "def generate_conditional_chart(problem, chart_choice):\n",
    "    \"\"\"Generates an interactive chart if requested.\"\"\"\n",
    "    fig = None\n",
    "    if chart_choice.lower() in [\"yes\", \"y\"]:\n",
    "        try:\n",
    "            fig = generate_interactive_chart(problem)\n",
    "            if fig is None:\n",
    "                raise ValueError(\"Chart not generated correctly.\")\n",
    "            print(\"Chart generated successfully!\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Chart error: {e}\")\n",
    "    return fig\n",
    "\n",
    "# === Structured Output: Text + Chart ===\n",
    "# Combines the generated explanation with the graphical visualization.\n",
    "async def generate_complete_result(problem, level, concept, topic, chart_choice):\n",
    "    \"\"\"Combines explanation and chart to generate a structured output.\"\"\"\n",
    "    response = await generate_explanation_async(problem, level, concept, topic)\n",
    "    chart = generate_conditional_chart(problem, chart_choice)\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"chart\": chart\n",
    "    }\n",
    "\n",
    "\n",
    "# === Scientific Article Validation ===\n",
    "# Checks that each article has a title, abstract, and URL.\n",
    "def validate_articles(raw_articles, max_articles=5):\n",
    "    \"\"\"\n",
    "    Validates and filters the list of articles received from an AI or API source.\n",
    "    Returns a clean list of dictionaries containing at least 'title', 'abstract', and 'url'.\n",
    "    \"\"\"\n",
    "    if not isinstance(raw_articles, list):\n",
    "        logging.warning(f\"[validate_articles] Invalid input: expected list, received {type(raw_articles)}\")\n",
    "        return []\n",
    "\n",
    "    valid_articles = []\n",
    "    for i, art in enumerate(raw_articles):\n",
    "        if not isinstance(art, dict):\n",
    "            logging.warning(f\"[validate_articles] Invalid element at position {i}: {type(art)}\")\n",
    "            continue\n",
    "\n",
    "        title = art.get(\"title\")\n",
    "        abstract = art.get(\"abstract\")\n",
    "        url = art.get(\"url\")\n",
    "\n",
    "        if all([title, abstract, url]):\n",
    "            valid_articles.append({\n",
    "                \"title\": str(title).strip(),\n",
    "                \"abstract\": str(abstract).strip(),\n",
    "                \"url\": str(url).strip()\n",
    "            })\n",
    "        else:\n",
    "            logging.info(f\"[validate_articles] Article discarded due to incomplete data (i={i}).\")\n",
    "\n",
    "    if not valid_articles:\n",
    "        logging.warning(\"[validate_articles] No valid articles after filtering.\")\n",
    "\n",
    "    return valid_articles[:max_articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIR1Eq1aFRCj"
   },
   "source": [
    "### Support Functions (Utils) for Scientific Analysis\n",
    "\n",
    "This module collects general-purpose utilities that enhance the entire AI-driven review and extraction system:\n",
    "\n",
    "- `valida_struttura_ai()`: checks that the data structure from LLM/API is complete (title, abstract, URL)  \n",
    "- `sigmoid()` and `valuta_score()`: compute semantic coherence from numerical outputs  \n",
    "- `estrai_testo()`: extracts text from various file formats (.pdf, .docx, .txt, .csv, .xlsx...)  \n",
    "- `estrai_testo_ai()`: safely parses content generated by LLMs  \n",
    "- `estrai_didascalie_da_testo()` and `estrai_immagini_con_didascalie()`: parse captions and images from scientific documents  \n",
    "- `genera_nota()`: interprets score labels (high, medium, low coherence)  \n",
    "- `genera_risposta()`: generates simulated NLP responses with adjustable temperature\n",
    "\n",
    "These functions make the system robust, reusable, and modular — ideal for integration into automated review pipelines, semantic search workflows, or visual parsing of academic articles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Evaluate the structure of the AI response from the LLM\n",
    "def validate_ai_structure(response, expected_fields=(\"title\", \"abstract\", \"url\")):\n",
    "    if not isinstance(response, list):\n",
    "        return []\n",
    "    valid_items = []\n",
    "    for item in response:\n",
    "        if isinstance(item, dict) and all(k in item for k in expected_fields):\n",
    "            valid_items.append(item)\n",
    "    return valid_items\n",
    "\n",
    "import math\n",
    "\n",
    "# Compute semantic score of the response\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def evaluate_score(model_output):\n",
    "    try:\n",
    "        score = float(model_output[0])\n",
    "        return round(sigmoid(score), 3)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# Extract text from selected file\n",
    "def extract_text(file_name, max_chars=5000):\n",
    "    \"\"\"\n",
    "    Extracts text from supported formats (.pdf, .docx, .tsv, .csv).\n",
    "    Returns only the first max_chars characters.\n",
    "    \"\"\"\n",
    "    extension = file_name.lower().split(\".\")[-1]\n",
    "\n",
    "    try:\n",
    "        if extension == \"pdf\":\n",
    "            with pdfplumber.open(file_name) as pdf:\n",
    "                text = \"\\n\".join([p.extract_text() or \"\" for p in pdf.pages]).strip()\n",
    "\n",
    "        elif extension == \"docx\":\n",
    "            doc = Document(file_name)\n",
    "            text = \"\\n\".join([p.text for p in doc.paragraphs]).strip()\n",
    "\n",
    "        elif extension in [\"csv\", \"tsv\"]:\n",
    "            sep = \",\" if extension == \"csv\" else \"\\t\"\n",
    "            df = pd.read_csv(file_name, sep=sep)\n",
    "            text = df.to_string(index=False)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported format: .{extension}\")\n",
    "\n",
    "        return text[:max_chars] if text else \"No text extracted.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during text extraction: {e}\"\n",
    "\n",
    "# Safely extract textual content from an AIMessage\n",
    "def extract_text_from_ai(obj):\n",
    "    \"\"\" Safely extracts textual content from an AIMessage object. \"\"\"\n",
    "    return getattr(obj, \"content\", str(obj)).strip()\n",
    "\n",
    "# Extract figure captions from text\n",
    "def extract_captions_from_text(text):\n",
    "    pattern = r\"(Figure|Fig\\.?)\\s*\\d+[:\\.\\-–]?\\s*[^\\n]+\"\n",
    "    return re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "# Extract images and captions from a file\n",
    "def extract_images_with_captions(file_path, output_folder=\"extracted_figures\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    extension = file_path.lower().split(\".\")[-1]\n",
    "    images = []\n",
    "    captions = []\n",
    "\n",
    "    try:\n",
    "        if extension == \"pdf\":\n",
    "            doc = fitz.open(file_path)\n",
    "            full_text = \"\\n\".join([p.get_text(\"text\") for p in doc])\n",
    "            extracted_captions = extract_captions_from_text(full_text)\n",
    "            count = 0\n",
    "\n",
    "            for i, page in enumerate(doc):\n",
    "                for j, img in enumerate(page.get_images(full=True)):\n",
    "                    base = doc.extract_image(img[0])\n",
    "                    ext = base[\"ext\"]\n",
    "                    path = f\"{output_folder}/page{i+1}_img{j+1}.{ext}\"\n",
    "                    with open(path, \"wb\") as f:\n",
    "                        f.write(base[\"image\"])\n",
    "                    images.append(path)\n",
    "                    captions.append(extracted_captions[count] if count < len(extracted_captions) else f\"Figure {i+1}.{j+1}\")\n",
    "                    count += 1\n",
    "\n",
    "        elif extension == \"docx\":\n",
    "            doc = Document(file_path)\n",
    "            text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "            extracted_captions = extract_captions_from_text(text)\n",
    "            count = 0\n",
    "\n",
    "            for i, rel in enumerate(doc.part._rels):\n",
    "                relation = doc.part._rels[rel]\n",
    "                if \"image\" in relation.target_ref:\n",
    "                    img_data = relation.target_part.blob\n",
    "                    name = f\"{output_folder}/docx_image_{i+1}.png\"\n",
    "                    with open(name, \"wb\") as f:\n",
    "                        f.write(img_data)\n",
    "                    images.append(name)\n",
    "                    captions.append(extracted_captions[count] if count < len(extracted_captions) else f\"Figure {i+1}\")\n",
    "                    count += 1\n",
    "\n",
    "        else:\n",
    "            print(f\"Unsupported extension: .{extension}\")\n",
    "\n",
    "        print(f\"{len(images)} image(s) extracted.\")\n",
    "        return images, captions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Generate semantic coherence note based on score\n",
    "def generate_note(score):\n",
    "    if score > 0.85:\n",
    "        return \"High semantic coherence. The response is likely solid and relevant.\"\n",
    "    elif score > 0.6:\n",
    "        return \"Moderate coherence. The response is understandable but may contain approximations.\"\n",
    "    else:\n",
    "        return \"Low coherence. It may be helpful to rephrase the question or provide more context.\"\n",
    "\n",
    "# Simulate LLM response generation\n",
    "def generate_response(question, temperature=0.7):\n",
    "    if \"Rephrase\" in question:\n",
    "        return \"How does enthalpy change during a phase transition?\"\n",
    "    return f\"[Simulated response at temperature {temperature} for: {question}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ampAtA_hpcr2"
   },
   "source": [
    "### Metacognitive Reasoning and Intentional Choices\n",
    "\n",
    "The code defines a mechanism of intentionality: every time the agent makes a decision or generates a response, an intentional explanation (the “why” behind the choice) is recorded in a log.\n",
    "\n",
    "- It keeps track of the agent’s decisions in a structured log.\n",
    "\n",
    "- It provides an intentional explanation for each choice.\n",
    "\n",
    "- It enriches the language model’s responses with this explanation, making the behavior transparent and motivated.\n",
    "\n",
    "This serves to make the decision-making process transparent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Initialize the intentional decision log\n",
    "intentional_log = []\n",
    "\n",
    "# This function simulates an intentional decision-making process by the AI agent.\n",
    "# It analyzes the proposed action in relation to the goal, available alternatives, and context.\n",
    "# Metacognition functions that adapt to the system\n",
    "def execute_intentional_choice(action, goal, alternatives, context):\n",
    "    try:\n",
    "        ai_explanation = choice_with_intention(action, goal, alternatives, context)\n",
    "        explanation_content = str(getattr(ai_explanation, \"content\", ai_explanation)).strip()\n",
    "\n",
    "        intentional_log.append({\n",
    "            \"action\": action,\n",
    "            \"reason\": explanation_content,\n",
    "            \"impact\": f\"Expected outcome for goal: {goal}\",\n",
    "            \"timestamp\": datetime.datetime.utcnow().isoformat()\n",
    "        })\n",
    "\n",
    "        return explanation_content\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in intentional choice: {e}\")\n",
    "        return f\"Error in intentional choice: {e}\"\n",
    "\n",
    "# Generates a response with intentionality by combining reasoning, AI response, and extracted text\n",
    "def generate_response_with_intention(prompt, action, goal, alternatives, context):\n",
    "    try:\n",
    "        reasoning = execute_intentional_choice(action, goal, alternatives, context)\n",
    "        ai_response = llm.invoke(prompt)\n",
    "        response_text = str(getattr(ai_response, \"content\", ai_response)).strip()\n",
    "\n",
    "        return f\"{response_text}\\n\\n*Agent's intentional explanation:*\\n{reasoning}\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating response with intention: {e}\")\n",
    "        return f\"Error generating response with intention: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tk0XPCX0jHEI"
   },
   "source": [
    "# skeptical_agent\n",
    "\n",
    "This system performs a rigorous audit by validating inputs and using an aggressive prompt to dismantle any claim not explicitly found in the sources. It enforces a \"zero-trust\" policy, labeling every unverified statement as an \"epistemic failure\" to eliminate AI hallucinations.\n",
    "\n",
    "In breve (per punti):\n",
    "- Validation: Controlla che ci siano sia la risposta che i documenti.\n",
    "\n",
    "- Analysis: Smonta il testo frase per frase usando solo le fonti fornite.\n",
    "\n",
    "- Verdict: Emette un report \"VERIFIED\" o \"EPISTEMIC FAILURE\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#This agent acts as a fact-checker that cross-references a response against source documents to identify hallucinations.\n",
    "#It systematically dismantles unsupported claims, labeling them as \"epistemic failures\" to ensure strict data reliability.\n",
    "\n",
    "def skeptical_agent(question: str, response: str, source_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Skeptical Agent: attacks the response and reports EPISTEMIC FAILURE\n",
    "    for claims not supported by the source documents.\n",
    "    Returns a structured text report.\n",
    "    \"\"\"\n",
    "    if not isinstance(response, str) or not response.strip():\n",
    "        logging.warning(\"[skeptical_agent] Empty or invalid response.\")\n",
    "        return \"No response to analyze.\"\n",
    "\n",
    "    if not isinstance(source_text, str) or not source_text.strip():\n",
    "        logging.warning(\"[skeptical_agent] No source document provided.\")\n",
    "        # In this case, the agent can only state that everything is epistemically uncertain\n",
    "        return \"No documents provided: the entire response is in a state of Epistemic Uncertainty.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a SKEPTICAL AGENT.\n",
    "\n",
    "Your goal is to critically DISMANTLE the following response.\n",
    "\n",
    "RESPONSE TO EVALUATE:\n",
    "\\\"\\\"\\\"{response.strip()}\\\"\\\"\\\"\n",
    "\n",
    "\n",
    "ORIGINAL QUESTION:\n",
    "\\\"\\\"\\\"{question.strip()}\\\"\\\"\\\"\n",
    "\n",
    "\n",
    "AVAILABLE DOCUMENTS (SOLE source of truth for this analysis):\n",
    "\\\"\\\"\\\"{source_text.strip()}\\\"\\\"\\\"\n",
    "\n",
    "\n",
    "METHODOLOGICAL INSTRUCTIONS (follow strictly):\n",
    "\n",
    "1. Analyze the response sentence by sentence.\n",
    "2. For every claim or significant statement, ask yourself:\n",
    "   - Is it clearly SUPPORTED by the documents above?\n",
    "   - Can I find a sentence, paragraph, or concept in the documents that explicitly justifies this statement?\n",
    "3. If you do NOT find direct or strongly implied support in the documents,\n",
    "   you MUST label that statement as:\n",
    "   EPISTEMIC FAILURE.\n",
    "4. Do NOT concern yourself with style, rhetoric, or clarity.\n",
    "   You must focus ONLY on epistemic traceability relative to the provided documents.\n",
    "\n",
    "MANDATORY output format (do not add anything else):\n",
    "\n",
    "For each important claim in the response, return an entry in the following format:\n",
    "\n",
    "- CLAIM: \"text of the sentence or statement\"\n",
    "  STATUS: VERIFIED / EPISTEMIC FAILURE\n",
    "  REASON: brief explanation, indicating if and where you find (or DO NOT find) support in the documents.\n",
    "\n",
    "If the documents do not contain enough information to verify almost anything,\n",
    "state this clearly in the REASON.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        res = llm.invoke(prompt.strip())\n",
    "        content = getattr(res, \"content\", str(res))\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[skeptical_agent] Error during LLM invocation: {e}\")\n",
    "        return \"Error in the Skeptical Agent during response analysis.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAustLbVCE9L"
   },
   "source": [
    "### Agent Metacognition – Self-Analysis and Semantic Memory\n",
    "\n",
    "This cell enables metacognitive behavior for the AI system:\n",
    "\n",
    "- **Self-assessment** of semantic coherence in its responses  \n",
    "- **Iterative improvement** through feedback and reformulation  \n",
    "- **Persistent metacognitive memory**, stored as FAISS embeddings  \n",
    "- **Reflection on reasoning** and internal motivations  \n",
    "- **Simulation of scientific creativity**, with comparison on epistemic novelty\n",
    "\n",
    "Metacognition allows the system to learn from itself, improve response quality, and build a reusable reasoning foundation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# === metacognitive_cycle ===\n",
    "# Executes an iterative cycle of evaluation and improvement of the generated response.\n",
    "# Combines qualitative feedback and semantic coherence score to decide whether to reformulate.\n",
    "# Useful for simulating reflective and adaptive behavior.\n",
    "\n",
    "def generate_objective_from_input(user_input):\n",
    "    \"\"\"\n",
    "    Generates a high-level operational objective based on the user's input.\n",
    "    Useful for AGI-style planning and decision-making.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an autonomous scientific agent. Based on the following input:\n",
    "    \"{user_input}\"\n",
    "\n",
    "    Define a clear and actionable objective that guides the agent's next steps.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = llm.invoke(prompt.strip())\n",
    "        return getattr(response, \"content\", str(response)).strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error generating objective: {e}\")\n",
    "        return \"Objective generation failed.\"\n",
    "\n",
    "\n",
    "async def metacognitive_cycle(question, level, max_iter, context_docs):\n",
    "    response = llm.invoke(question)\n",
    "    response_text = extract_text_from_ai(response)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        feedback = auto_feedback_response(question, response_text, level)\n",
    "        score = evaluate_coherence(question, response_text)\n",
    "\n",
    "        print(f\"\\nIteration {i+1} – Coherence: {score:.3f}\")\n",
    "        print(\"Feedback:\", extract_text_from_ai(feedback))\n",
    "\n",
    "        if score < 0.7:\n",
    "            response_text = extract_text_from_ai(improve_response(question, response_text, level))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # SKEPTICAL AGENT INTEGRATION\n",
    "    # The skeptic steps in now that the response is coherent\n",
    "    print(\"\\n[Skeptical Agent] Analyzing epistemic traceability...\")\n",
    "    skeptical_report = skeptical_agent(question, response_text, context_docs)\n",
    "\n",
    "    # Citation Verification (Bibliographic Cross-check) ---\n",
    "    verified_refs = await verify_citations(response_text)\n",
    "\n",
    "    # 3. Final Report Assembly\n",
    "    full_output = response_text\n",
    "    full_output += \"\\n\\n\" + \"=\"*40\n",
    "    full_output += \"\\n## SKEPTICAL AGENT REPORT (Critical Analysis)\\n\"\n",
    "    full_output += skeptical_report\n",
    "    full_output += \"\\n\" + \"=\"*40\n",
    "\n",
    "    full_output += \"\\n\\n## VERIFIED BIBLIOGRAPHIC REFERENCES\\n\"\n",
    "    if verified_refs:\n",
    "        for r in verified_refs:\n",
    "            status = \"verified\" if r[\"verified\"] else \"unverified\"\n",
    "            full_output += f\"- {r['citation']} ({status})\\n\"\n",
    "    else:\n",
    "        full_output += \"No citations found or verifiable in the text.\"\n",
    "\n",
    "    return full_output\n",
    "\n",
    "\n",
    "# Evaluate response with self-assessment and interactive improvement\n",
    "# Evaluates the response and reformulates it if poorly constructed\n",
    "def evaluate_responses_with_ai(question, generate_response_fn, n_variants=3, reformulation_threshold=0.6):\n",
    "    temperature_values = [0.7, 0.4, 0.9][:n_variants]\n",
    "    responses = [generate_response_fn(question, temperature=t) for t in temperature_values]\n",
    "\n",
    "    scores = [evaluate_coherence(question, r) for r in responses]\n",
    "    idx = scores.index(max(scores))\n",
    "    confidence = scores[idx]\n",
    "    best_response = responses[idx]\n",
    "\n",
    "    if confidence < reformulation_threshold:\n",
    "        new_question = reformulate_question(question)\n",
    "        return evaluate_responses_with_ai(new_question, generate_response_fn)\n",
    "\n",
    "    return {\n",
    "        \"response\": best_response,\n",
    "        \"confidence\": round(confidence, 3),\n",
    "        \"note\": generate_note(confidence)\n",
    "    }\n",
    "\n",
    "def evaluate_responses_with_ai_simple(question, response, level=\"basic\"):\n",
    "    \"\"\"\n",
    "    Evaluates the quality of the generated response relative to the question.\n",
    "    Returns a dictionary with:\n",
    "    - semantic coherence score\n",
    "    - reason for weakness\n",
    "    - suggested reformulation\n",
    "    - reflection on reasoning\n",
    "    - flag for auto-improvement\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    User question: \"{question}\"\n",
    "    Generated response: \"{response}\"\n",
    "    Required level: {level}\n",
    "\n",
    "    Evaluate the response in 5 points:\n",
    "    1. Semantic coherence (0–1)\n",
    "    2. Conceptual completeness\n",
    "    3. Argumentative structure\n",
    "    4. Adequacy to the required level\n",
    "    5. Ability to stimulate new questions\n",
    "\n",
    "    If the response is weak:\n",
    "    - Explain the reason\n",
    "    - Suggest a reformulation\n",
    "    - Reflect on how the system reasoned\n",
    "\n",
    "    Return everything in structured format.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        ai_evaluation = llm.invoke(evaluation_prompt)\n",
    "        raw_output = getattr(ai_evaluation, \"content\", str(ai_evaluation))\n",
    "    except Exception as e:\n",
    "        print(\"Evaluation error:\", e)\n",
    "        return {\n",
    "            \"semantic_score\": 0.0,\n",
    "            \"weakness_reason\": \"System error\",\n",
    "            \"new_formulation\": None,\n",
    "            \"self_reflection\": None,\n",
    "            \"requires_improvement\": True\n",
    "        }\n",
    "\n",
    "    # Simplified parsing functions (can be enhanced with regex or LLM)\n",
    "    def extract_score(text):\n",
    "        match = re.search(r\"Semantic coherence\\s*[:\\-]?\\s*(0\\.\\d+)\", text)\n",
    "        return float(match.group(1)) if match else 0.0\n",
    "\n",
    "    def extract_reason(text):\n",
    "        match = re.search(r\"Reason\\s*[:\\-]?\\s*(.+)\", text)\n",
    "        return match.group(1).strip() if match else \"Reason not found.\"\n",
    "\n",
    "    def extract_reformulation(text):\n",
    "        match = re.search(r\"Reformulation\\s*[:\\-]?\\s*(.+)\", text)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    def extract_reflection(text):\n",
    "        match = re.search(r\"Reflection\\s*[:\\-]?\\s*(.+)\", text)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    # Actual parsing\n",
    "    score = extract_score(raw_output)\n",
    "    reason = extract_reason(raw_output)\n",
    "    reformulation = extract_reformulation(raw_output)\n",
    "    reflection = extract_reflection(raw_output)\n",
    "\n",
    "    return {\n",
    "        \"response\": response,\n",
    "        \"semantic_score\": score,\n",
    "        \"weakness_reason\": reason,\n",
    "        \"new_formulation\": reformulation,\n",
    "        \"self_reflection\": reflection,\n",
    "        \"requires_improvement\": score < 0.7\n",
    "    }\n",
    "\n",
    "def generate_metacognitive_content(question, response, evaluation):\n",
    "    return f\"\"\"\n",
    "    [Question] {question}\n",
    "    [Response] {response}\n",
    "    [Coherence Score] {evaluation['semantic_score']}\n",
    "    [Weakness Reason] {evaluation['weakness_reason']}\n",
    "    [Suggested Reformulation] {evaluation['new_formulation']}\n",
    "    [Cognitive Reflection] {evaluation['self_reflection']}\n",
    "    [Needs Improvement] {evaluation['requires_improvement']}\n",
    "    \"\"\".strip()\n",
    "\n",
    "def add_metacognitive_memory(question, response):\n",
    "    # Cognitive evaluation of the response\n",
    "    evaluation = evaluate_responses_with_ai(question, response)\n",
    "\n",
    "    # Generate textual content with all metacognitive data\n",
    "    textual_content = generate_metacognitive_content(question, response, evaluation)\n",
    "\n",
    "    # Generate semantic embedding from the full content\n",
    "    embedding = embedding_model.encode([textual_content])\n",
    "\n",
    "    # Add to FAISS index\n",
    "    index.add(np.array(embedding, dtype=np.float32))\n",
    "\n",
    "    # Save updated index\n",
    "    with open(INDEX_FILE, \"wb\") as f:\n",
    "        pickle.dump(index, f)\n",
    "\n",
    "    print(\"Metacognitive memory updated!\")\n",
    "\n",
    "def search_similar_reasoning(query, top_k=5):\n",
    "    \"\"\"\n",
    "    Searches the FAISS metacognitive memory for reasoning most similar to the input query.\n",
    "    Returns a list of the most relevant textual contents.\n",
    "    \"\"\"\n",
    "    # Encode the query\n",
    "    query_vector = embedding_model.encode([query])\n",
    "\n",
    "    # Search for top-K nearest\n",
    "    distances, indices = index.search(np.array(query_vector, dtype=np.float32), top_k)\n",
    "\n",
    "    results = []\n",
    "    for idx in indices[0]:\n",
    "        try:\n",
    "            with open(\"meta_diary.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                archive = json.load(f)\n",
    "                content = archive.get(str(idx))\n",
    "                if content:\n",
    "                    results.append(content)\n",
    "        except Exception as e:\n",
    "            print(f\"Memory retrieval error: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def add_metacognition_to_response(response, evaluation):\n",
    "    reflection = evaluation.get(\"self_reflection\", \"\")\n",
    "    note = evaluation.get(\"weakness_reason\", \"\")\n",
    "    return f\"{response.strip()}\\n\\n*Metacognitive note:* {note}\\n*Agent's reflection:* {reflection}\"\n",
    "\n",
    "def auto_feedback(question, response, level):\n",
    "    return f\"\"\"Analyze the response in relation to the question: \"{question}\".\n",
    "Evaluate the content according to the level '{level}' and suggest improvements.\n",
    "\"\"\"\n",
    "\n",
    "# === Full flow example ===\n",
    "async def scientific_creativity_flow(concept, subject, language=\"en\", level=\"advanced\"):\n",
    "    creative_hypothesis = simulate_scientific_creativity(concept, subject, language=language, level=level)\n",
    "    articles, _ = await search_multi_database(concept)  # Retrieve existing scientific sources\n",
    "    novelty_evaluation = evaluate_hypothesis_novelty(creative_hypothesis, articles)\n",
    "\n",
    "    return {\n",
    "        \"hypothesis\": creative_hypothesis,\n",
    "        \"novelty\": novelty_evaluation\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKlL5HxUCHnk"
   },
   "source": [
    "### Multilingual Module – Automatic Translation of Scientific Documents\n",
    "\n",
    "This cell enables automatic translation from PDF and DOCX files into multiple languages, while preserving the scientific integrity of the content:\n",
    "\n",
    "- **Automatic language detection** using `langdetect`  \n",
    "- **Neural translation** via `Helsinki-NLP` models (`transformers` from HuggingFace)  \n",
    "- **Support for PDF, DOCX, CSV, TSV**, with text extraction and saving of the translated file  \n",
    "- **Intelligent caching** to avoid duplicate translations  \n",
    "- Supported languages: `en`, `fr`, `de`, `es`, `zh`, `ja`, `ar`, `it`\n",
    "\n",
    "Ideal for converting academic content and technical explanations into accessible language for international users.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# === Text Translation ===\n",
    "\n",
    "# Caching dictionary for previously translated texts\n",
    "translation_cache = {}\n",
    "\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"Detects the language of the loaded text.\"\"\"\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Language detection error: {e}\")\n",
    "        return \"unknown\"\n",
    "\n",
    "def translate_text(text, source_lang, target_lang):\n",
    "    \"\"\" Translates the text with debug output to verify correctness. \"\"\"\n",
    "    translation_model = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
    "\n",
    "    print(f\"Using translation model: {translation_model}\")\n",
    "\n",
    "    translator = pipeline(\"translation\", model=translation_model)\n",
    "\n",
    "    translation = translator(text)[0]['translation_text']\n",
    "    print(f\"Original text: {text}\")\n",
    "    print(f\"Translated text: {translation}\")\n",
    "\n",
    "    return translation\n",
    "\n",
    "def extract_text_pdf(file_name):\n",
    "    \"\"\" Extracts text from a PDF file. \"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file_name) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_docx(file_name):\n",
    "    \"\"\" Extracts text from a DOCX file. \"\"\"\n",
    "    doc = Document(file_name)\n",
    "    text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "    return text.strip()\n",
    "\n",
    "def save_docx(text, output_file_name):\n",
    "    \"\"\" Saves translated text into a DOCX document. \"\"\"\n",
    "    doc = Document()\n",
    "    doc.add_paragraph(text)\n",
    "    doc.save(output_file_name)\n",
    "\n",
    "def extract_text_csv(file_name):\n",
    "    \"\"\" Extracts textual content from a CSV file. \"\"\"\n",
    "    df = pd.read_csv(file_name)\n",
    "    text = df.astype(str).apply(lambda x: ' '.join(x), axis=1).str.cat(sep='\\n')\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_tsv(file_name):\n",
    "    \"\"\" Extracts textual content from a TSV file. \"\"\"\n",
    "    df = pd.read_csv(file_name, sep='\\t')\n",
    "    text = df.astype(str).apply(lambda x: ' '.join(x), axis=1).str.cat(sep='\\n')\n",
    "    return text.strip()\n",
    "\n",
    "def handle_file(file_name):\n",
    "    \"\"\" Loads the file, detects its language, and lets the user choose a target language for translation. \"\"\"\n",
    "    extension = file_name.split('.')[-1].lower()\n",
    "\n",
    "    if extension == \"pdf\":\n",
    "        text = extract_text_pdf(file_name)\n",
    "    elif extension == \"docx\":\n",
    "        text = extract_text_docx(file_name)\n",
    "    elif extension == \"csv\":\n",
    "        text = extract_text_csv(file_name)\n",
    "    elif extension == \"tsv\":\n",
    "        text = extract_text_tsv(file_name)\n",
    "    else:\n",
    "        return \"Unsupported format! Use PDF, DOCX, CSV, or TSV.\"\n",
    "\n",
    "    original_language = detect_language(text)\n",
    "    print(f\"The file was detected in **{original_language}**.\")\n",
    "\n",
    "    # List of available languages\n",
    "    available_languages = [\"en\", \"fr\", \"de\", \"es\", \"zh\", \"ja\", \"ar\", \"it\"]\n",
    "\n",
    "    # Ask the user for the target language\n",
    "    print(f\"Available languages for translation: {', '.join(available_languages)}\")\n",
    "    target_language = input(\"Which language do you want the explanation in? (e.g., 'en' for English, 'fr' for French): \").strip()\n",
    "\n",
    "    if target_language not in available_languages:\n",
    "        print(\"Error: Unsupported language!\")\n",
    "    else:\n",
    "        print(f\"The explanation will be translated into {target_language}.\")\n",
    "\n",
    "    # Ensure translation is performed\n",
    "    translated_text = translate_text(text, original_language, target_language)\n",
    "\n",
    "    # Save the translated file\n",
    "    translated_file_name = f\"translated_{target_language}_{file_name}\"\n",
    "    if extension == \"pdf\":\n",
    "        with open(translated_file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(translated_text)\n",
    "    elif extension == \"docx\":\n",
    "        save_docx(translated_text, translated_file_name)\n",
    "\n",
    "    return f\"Translation completed! Download the file: {translated_file_name}\"\n",
    "\n",
    "# Initialize the dictionary to store journals\n",
    "journal_store = {}\n",
    "\n",
    "def save_multilingual_journal(journal_text, journal_id, target_language):\n",
    "    source_language = detect_language(journal_text)\n",
    "\n",
    "    if source_language != target_language:\n",
    "        translated_text = translate_long_text(journal_text, source_lang=source_language, target_lang=target_language)\n",
    "    else:\n",
    "        translated_text = journal_text\n",
    "\n",
    "    journal_store[journal_id] = {\n",
    "        \"original\": journal_text,\n",
    "        target_language: translated_text\n",
    "    }\n",
    "\n",
    "    embedding = safe_encode(translated_text)\n",
    "    index.add(np.array(embedding, dtype=np.float32))\n",
    "\n",
    "\n",
    "\n",
    "def translate_long_text(text, source_lang=\"it\", target_lang=\"en\", max_chars=400):\n",
    "    translation_model = f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
    "    translator = pipeline(\"translation\", model=translation_model)\n",
    "\n",
    "    blocks = [text[i:i+max_chars] for i in range(0, len(text), max_chars)]\n",
    "    translated = []\n",
    "\n",
    "    for block in blocks:\n",
    "        try:\n",
    "            output = translator(block)[0]['translation_text']\n",
    "            translated.append(output)\n",
    "        except Exception as e:\n",
    "            print(f\"Error translating block: {e}\")\n",
    "            translated.append(\"[Translation error]\")\n",
    "\n",
    "    return \"\\n\".join(translated)\n",
    "\n",
    "def search_similar_journals(query, target_language, top_k=3):\n",
    "    query_language = detect_language(query)\n",
    "\n",
    "    if query_language != target_language:\n",
    "        translated_query = translate_long_text(query, source_lang=query_language, target_lang=target_language)\n",
    "    else:\n",
    "        translated_query = query\n",
    "\n",
    "    query_emb = safe_encode(translated_query)\n",
    "    query_emb = np.array(query_emb, dtype=np.float32)\n",
    "\n",
    "    if hasattr(index, \"is_trained\") and not index.is_trained:\n",
    "        print(\"FAISS index is not trained.\")\n",
    "        return []\n",
    "\n",
    "    D, I = index.search(query_emb, top_k)\n",
    "    results = []\n",
    "    for i in I[0]:\n",
    "        journal = journal_store.get(i, {})\n",
    "        results.append(journal.get(target_language, \"\"))\n",
    "    return results\n",
    "\n",
    "# === Valid Input Function ===\n",
    "def get_valid_input(message, valid_options=None):\n",
    "    while True:\n",
    "        value = input(message).strip().lower()\n",
    "        if not value:\n",
    "            print(\"Error! Please enter a valid value.\")\n",
    "        elif valid_options and value not in valid_options:\n",
    "            print(f\"Error! You must choose from: {', '.join(valid_options)}\")\n",
    "        else:\n",
    "            return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqJbK6Omxth-"
   },
   "source": [
    "### Academic Ranking and Scientific Originality\n",
    "\n",
    "This cell enables:\n",
    "\n",
    "- Calculation of the Impact Score using a RandomForest model  \n",
    "- Validation of scientific hypotheses to assess originality  \n",
    "- Automated checks on citations and methodology  \n",
    "- Intelligent synthesis of scientific sources\n",
    "\n",
    "The system analyzes papers and ideas using epistemic criteria, offering both quantitative and qualitative insights into impact and novelty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated score: 84.85\n",
      "Estimated score: 84.7\n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Sample data for ranking\n",
    "data = np.array([\n",
    "    [120, 45, 1, 2023],  # Citations, h-index, peer review, year\n",
    "    [50, 30, 1, 2020],\n",
    "    [10, 15, 0, 2018]\n",
    "])\n",
    "\n",
    "labels = [95, 70, 30]  # Academic impact score\n",
    "\n",
    "# Model training\n",
    "ranking_model = RandomForestRegressor(n_estimators=100)\n",
    "ranking_model.fit(data, labels)\n",
    "\n",
    "# **Ranking prediction**\n",
    "def calculate_impact_score(citations, h_index, peer_review, publication_year):\n",
    "    paper_data = np.array([[citations, h_index, peer_review, publication_year]])\n",
    "    score = ranking_model.predict(paper_data)\n",
    "    return max(0, score[0])  # Ensure non-negative\n",
    "\n",
    "# Usage example\n",
    "impact_score = calculate_impact_score(80, 40, 1, 2024)\n",
    "print(f\"Estimated score: {impact_score}\")\n",
    "\n",
    "# Ranking model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Sample data for ranking\n",
    "data = np.array([\n",
    "    [120, 45, 1, 2023],  # Citations, h-index, peer review, year\n",
    "    [50, 30, 1, 2020],\n",
    "    [10, 15, 0, 2018]\n",
    "])\n",
    "\n",
    "labels = [95, 70, 30]  # Academic impact score\n",
    "\n",
    "# Model training\n",
    "ranking_model = RandomForestRegressor(n_estimators=100)\n",
    "ranking_model.fit(data, labels)\n",
    "\n",
    "# Ranking prediction\n",
    "new_paper = np.array([[80, 40, 1, 2024]])\n",
    "score = ranking_model.predict(new_paper)\n",
    "print(f\"Estimated score: {score[0]}\")\n",
    "\n",
    "# === Scientific originality evaluation ===\n",
    "def evaluate_hypothesis_novelty(hypothesis, existing_articles, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Compares the hypothesis with existing articles using semantic embeddings.\n",
    "    Returns:\n",
    "    - average similarity score\n",
    "    - similar articles\n",
    "    - qualitative assessment of originality\n",
    "    \"\"\"\n",
    "    try:\n",
    "        emb_hypothesis = model_embedding.encode([hypothesis])\n",
    "        emb_articles = model_embedding.encode([a[\"abstract\"] for a in existing_articles if \"abstract\" in a])\n",
    "\n",
    "        similarity = np.dot(emb_hypothesis, emb_articles.T) / (\n",
    "            np.linalg.norm(emb_hypothesis) * np.linalg.norm(emb_articles, axis=1)\n",
    "        )\n",
    "        average = round(float(np.mean(similarity)), 3)\n",
    "\n",
    "        similar_articles = [\n",
    "            existing_articles[i][\"title\"]\n",
    "            for i, score in enumerate(similarity[0]) if score > threshold\n",
    "        ]\n",
    "\n",
    "        if average < 0.4:\n",
    "            assessment = \"High originality: hypothesis is rarely present in the literature.\"\n",
    "        elif average < 0.7:\n",
    "            assessment = \"Moderate originality: related concepts exist.\"\n",
    "        else:\n",
    "            assessment = \"Low originality: hypothesis is already widely discussed.\"\n",
    "\n",
    "        return {\n",
    "            \"novelty_score\": average,\n",
    "            \"similar_articles\": similar_articles,\n",
    "            \"assessment\": assessment\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[evaluate_novelty] Error during originality evaluation: {e}\")\n",
    "        return {\n",
    "            \"novelty_score\": 0.0,\n",
    "            \"similar_articles\": [],\n",
    "            \"assessment\": \"Error during originality evaluation.\"\n",
    "        }\n",
    "\n",
    "# Automated paper review with AI\n",
    "async def review_paper(paper_text):\n",
    "    \"\"\" Checks the methodology and citation quality of a paper. \"\"\"\n",
    "    methodology = await verify_methodology(paper_text)\n",
    "    citations = await verify_citations(paper_text)\n",
    "    return {\"methodology\": methodology, \"citations\": citations}\n",
    "\n",
    "async def validate_hypothesis(hypothesis):\n",
    "    sources = await search_multi_database(hypothesis)\n",
    "    score = calculate_impact_score(sources)  # Based on citations, year, h-index, etc.\n",
    "    summary = summarize_evidence(sources)\n",
    "    return score, summary\n",
    "\n",
    "def summarize_evidence(sources):\n",
    "    return \"\\n\".join([\n",
    "        f\"- {a['title'][:80]}…\" for a in sources if isinstance(a, dict) and 'title' in a\n",
    "    ]) if sources else \"No evidence found.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxIIMXv0yNdY"
   },
   "source": [
    "### Hypothesis Validation and Scientific Reporting\n",
    "\n",
    "This cell enables the following:\n",
    "\n",
    "- Evaluation of the **novelty** of a scientific hypothesis by comparing it with existing articles (via semantic embeddings)  \n",
    "- Generation of an **Impact Score** based on citations, h-index, peer review status, and publication year  \n",
    "- Extraction and synthesis of evidence from multiple databases (arXiv, PubMed, Zenodo, OpenAlex)  \n",
    "- Creation of a **Markdown report** including:\n",
    "  - Title and description of the analysis  \n",
    "  - List of articles with abstracts and links  \n",
    "  - Related images and captions (if available)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Generate an automatic report\n",
    "def generate_markdown_report(\n",
    "    title=\"Automatic Report\",\n",
    "    description=\"Automatically generated scientific summary.\",\n",
    "    articles=None,\n",
    "    images=None,\n",
    "    captions=None,\n",
    "    filename=\"report.md\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a Markdown file with:\n",
    "    - Title and description\n",
    "    - Scientific articles with abstract and link\n",
    "    - Images and associated captions (if available)\n",
    "\n",
    "    All arguments are optional. A coherent structure is created regardless.\n",
    "    \"\"\"\n",
    "\n",
    "    # Safe fallback for each parameter\n",
    "    articles = articles if isinstance(articles, list) else []\n",
    "    images = images if isinstance(images, list) else []\n",
    "    captions = captions if isinstance(captions, list) else []\n",
    "\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"# {title}\\n\\n\")\n",
    "            f.write(f\"{description}\\n\\n\")\n",
    "\n",
    "            f.write(\"## Scientific Articles\\n\\n\")\n",
    "            if articles:\n",
    "                for i, art in enumerate(articles[:5]):\n",
    "                    article_title = art.get(\"\", f\"Article {i+1}\")\n",
    "                    abstract = art.get(\"abstract\", \"Abstract not available.\")\n",
    "                    url = art.get(\"url\", \"#\")\n",
    "                    f.write(f\"**{i+1}. {article_title}**\\n\")\n",
    "                    f.write(f\"{abstract}\\n\\n[Link to article]({url})\\n\\n\")\n",
    "            else:\n",
    "                f.write(\"No articles available.\\n\\n\")\n",
    "\n",
    "            if images:\n",
    "                f.write(\"## Figures\\n\\n\")\n",
    "                for i, img_path in enumerate(images):\n",
    "                    caption = captions[i] if i < len(captions) else f\"Figure {i+1}\"\n",
    "                    f.write(f\"![{caption}]({img_path})\\n\\n*{caption}*\\n\\n\")\n",
    "\n",
    "        print(f\"Markdown report successfully generated: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during report generation: {e}\")\n",
    "\n",
    "# === Markdown report generation ===\n",
    "def generate_markdown_report(title, description, articles, filename=\"report.md\"):\n",
    "    if not isinstance(articles, list):\n",
    "        logging.error(f\"[generate_markdown_report] 'articles' is not a valid list: {type(articles)}\")\n",
    "        print(\"Error: unable to generate report. Invalid article format.\")\n",
    "        return\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# {title}\\n\\n{description}\\n\\n## Scientific Articles\\n\\n\")\n",
    "        for i, art in enumerate(articles[:5]):\n",
    "            if isinstance(art, dict) and all(k in art for k in [\"title\", \"abstract\", \"url\"]):\n",
    "                f.write(f\"**{i+1}. {art['title']}**\\n{art['abstract']} ([Link]({art['url']}))\\n\\n\")\n",
    "            else:\n",
    "                f.write(f\"**{i+1}. Article data not available or incomplete.**\\n\\n\")\n",
    "    print(f\"Markdown report generated: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCDkYEkIyX_l"
   },
   "source": [
    "### Impact Score & Semantic Evaluation\n",
    "\n",
    "This cell calculates the coherence and reliability of generated responses using:\n",
    "\n",
    "- A CrossEncoder model (DeBERTa) for semantic analysis  \n",
    "- An Impact Score formula based on academic data  \n",
    "- Relevance verification between the question and the generated content  \n",
    "- Automatic restructuring if the score is low\n",
    "\n",
    "The system adopts an iterative logic that mirrors scientific peer-review criteria, enhancing the quality and relevance of the generated responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1088aed9045044cfa798e3fe391ea4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/975 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b84845e1744e018cbab553e9260793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/557M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5efe7ddec24bce84bcd0559d949dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f9ab4d53984ad58612ce7dc19f61dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc1eadbe3b944c48b9545fe50fffa5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192208e76e054a5a8aefab6d47e5269b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a9610522004bce9532daa9590fa105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/778 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8726c13ef21404aa24e472c45f3a213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Load the model only once\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/nli-deberta-base\")\n",
    "\n",
    "def evaluate_coherence(question, answer):\n",
    "    score = cross_encoder.predict([(question, answer)])\n",
    "    try:\n",
    "        logit = float(score[0]) if isinstance(score[0], (int, float, np.floating)) else float(score[0][0])\n",
    "        probability = 1 / (1 + math.exp(-logit))  # Sigmoid function\n",
    "        return round(probability, 3)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# === Scientific reliability score calculation ===\n",
    "def calculate_impact_score(citations, h_index, peer_review, publication_year):\n",
    "    score = (citations * 0.4) + (h_index * 0.3) + (peer_review * 0.2) - (2025 - publication_year) * 0.1\n",
    "    return max(0, score)  # Ensure non-negative\n",
    "\n",
    "def check_topic_relevance(user_question, extracted_text, threshold=0.7):\n",
    "    \"\"\"Checks whether the topic of the question is consistent with the uploaded file content.\"\"\"\n",
    "    emb_question = embedding_model.encode([user_question])\n",
    "    emb_text = embedding_model.encode([extracted_text])\n",
    "\n",
    "    similarity = np.dot(emb_question, emb_text.T) / (np.linalg.norm(emb_question) * np.linalg.norm(emb_text))\n",
    "    return round(similarity, 3), similarity >= threshold\n",
    "\n",
    "def calculate_response_score(question, answer):\n",
    "    score = cross_encoder.predict([(question, answer)])\n",
    "    return float(score[0])\n",
    "\n",
    "def regenerate_if_low_score(question, answer, level, threshold=0.7, iterations=2):\n",
    "    evaluation = evaluate_responses_with_ai(question, answer, level)\n",
    "    if evaluation[\"semantic_score\"] < threshold:\n",
    "        new_question = reformulate_question(question)\n",
    "        for i in range(iterations):\n",
    "            new_answer = generate_response(new_question, temperature=0.7)\n",
    "            new_evaluation = evaluate_responses_with_ai(new_question, new_answer, level)\n",
    "            if new_evaluation[\"semantic_score\"] >= threshold:\n",
    "                return new_answer\n",
    "    return answer\n",
    "\n",
    "def select_best_version(question, answers):\n",
    "    scored = [(r, calculate_response_score(question, r)) for r in answers]\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored[0]  # (answer, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUnA52R6CgEK"
   },
   "source": [
    "### Ethical Module – Content Evaluation and Autonomy Control\n",
    "\n",
    "This cell activates an ethical analysis system that examines AI-generated responses for potential risks:\n",
    "\n",
    "#### Autonomy\n",
    "`check_agent_autonomy(question, authorization_level)`  \n",
    "- If it contains **“sub-goal”** and level < 2 → ethical warning.  \n",
    "- Otherwise → “Ethics: normal content”.\n",
    "\n",
    "#### Ethical Risk\n",
    "`assess_ethical_risk(content)`  \n",
    "- Analyzes risk patterns:\n",
    "  - **Critical topic** (+0.8) → vaccine, gender, politics, religion, ethnicity  \n",
    "  - **Linguistic bias** (+0.5) → “all men”, “women are”  \n",
    "  - **Misinformation** (+0.5) → without sources  \n",
    "  - **Cultural generalizations** (+0.5)  \n",
    "  - **Disciplinary stereotypes** (+0.5)  \n",
    "  - **Normative implications** (+0.5) → “should behave”, “must act”  \n",
    "- Adds LLM bias score (0–1).  \n",
    "- Classification:  \n",
    "  - ≤ 0.3 → **Low**  \n",
    "  - ≤ 0.7 → **Medium**  \n",
    "  - > 0.7 → **High**\n",
    "\n",
    "#### Reformulation\n",
    "If risk > 0.6 → suggests neutral rewriting:\n",
    "> “Ethical risk detected. Rewrite to reduce bias and improve neutrality.”\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# This module analyzes responses to detect bias, misinformation,\n",
    "# non-neutral language, or potentially harmful content.\n",
    "\n",
    "# The system flags problematic content and suggests revisions.\n",
    "def check_agent_autonomy(question: str, authorization_level: int):\n",
    "    if \"sub-goal\" in question.lower() and authorization_level < 2:\n",
    "        logging.warning(\"Sensitive content detected, but generation will not be blocked.\")\n",
    "        return \"Ethics: potentially sensitive content\"\n",
    "    return \"Ethics: normal content\"\n",
    "\n",
    "# Checks the agent's degree of autonomy\n",
    "# Used to monitor whether the system is acting too independently or out of context\n",
    "def assess_ethical_risk(content, domain=\"scientific\"):\n",
    "    \"\"\"\n",
    "    Evaluates ethical risks in AI-generated content using a scalar scoring system.\n",
    "    Assigns weights to detected patterns and requests LLM-based bias scoring.\n",
    "    Triggers revision if overall risk exceeds threshold.\n",
    "    \"\"\"\n",
    "    text_lower = content.lower()\n",
    "    risk_score = 0.0\n",
    "    risk_sources = []\n",
    "\n",
    "    # Pattern-based scoring\n",
    "    critical_terms = [\"vaccine\", \"gender\", \"politics\", \"religion\", \"ethnicity\"]\n",
    "    if any(term in text_lower for term in critical_terms):\n",
    "        risk_score += 0.8\n",
    "        risk_sources.append(\"Critical topic\")\n",
    "\n",
    "    if \"all men\" in text_lower or \"women are\" in text_lower:\n",
    "        risk_score += 0.5\n",
    "        risk_sources.append(\"Linguistic bias\")\n",
    "\n",
    "    if \"according to experts without citing sources\" in text_lower:\n",
    "        risk_score += 0.5\n",
    "        risk_sources.append(\"Misinformation\")\n",
    "\n",
    "    cultural_patterns = [\n",
    "        \"asians are\", \"africans are\", \"europeans are\", \"americans are\",\n",
    "        \"italians are\", \"japanese are\", \"muslims are\", \"jews are\"\n",
    "    ]\n",
    "    if any(p in text_lower for p in cultural_patterns):\n",
    "        risk_score += 0.5\n",
    "        risk_sources.append(\"Cultural generalization\")\n",
    "\n",
    "    stereotype_patterns = [\n",
    "        \"psychologists are\", \"engineers are\", \"artists are\", \"scientists are\",\n",
    "        \"philosophers are\", \"mathematicians are\"\n",
    "    ]\n",
    "    if any(p in text_lower for p in stereotype_patterns):\n",
    "        risk_score += 0.5\n",
    "        risk_sources.append(\"Disciplinary stereotype\")\n",
    "\n",
    "    normative_patterns = [\n",
    "        \"should behave\", \"must act\", \"it's right that\", \"it's wrong to\",\n",
    "        \"they ought to\", \"is unacceptable\", \"is appropriate\"\n",
    "    ]\n",
    "    if any(p in text_lower for p in normative_patterns):\n",
    "        risk_score += 0.5\n",
    "        risk_sources.append(\"Normative implication\")\n",
    "\n",
    "    # LLM-based scoring\n",
    "    bias_prompt = f\"Rate the cultural or ethical bias of the following text on a scale from 0 to 1:\\n\\n{content}\\n\\nScore:\"\n",
    "    llm_score_raw = llm.invoke(bias_prompt).content.strip()\n",
    "\n",
    "    try:\n",
    "        llm_score = float(llm_score_raw)\n",
    "        risk_score += llm_score\n",
    "        risk_sources.append(f\"LLM bias score: {llm_score}\")\n",
    "    except ValueError:\n",
    "        llm_score = 0.0  # fallback if parsing fails\n",
    "\n",
    "    # Normalize and classify\n",
    "    overall_risk = min(risk_score, 1.0)\n",
    "\n",
    "    if overall_risk <= 0.3:\n",
    "        risk_level = \"Basso\"\n",
    "    elif overall_risk <= 0.7:\n",
    "        risk_level = \"Medio\"\n",
    "    else:\n",
    "        risk_level = \"Alto\"\n",
    "\n",
    "    # Riformulazione automatica se rischio alto\n",
    "    revised_response = None\n",
    "    revision_suggestion = None\n",
    "    if overall_risk > 0.6:\n",
    "        revision_suggestion = \"Ethical risk detected. Rewrite to reduce bias and improve neutrality.\"\n",
    "        revision_prompt = f\"\"\"Rewrite this to reduce ethical bias and improve neutrality:\n",
    "Original: {content}\n",
    "Rewritten:\"\"\"\n",
    "        revised_response = llm.invoke(revision_prompt).content.strip()\n",
    "\n",
    "    return {\n",
    "        \"overall_risk\": round(overall_risk, 2),\n",
    "        \"risk_level\": risk_level,\n",
    "        \"risk_sources\": risk_sources,\n",
    "        \"revision_suggestion\": revision_suggestion,\n",
    "        \"revised_response\": revised_response\n",
    "    }\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"Discuss the potential risks of generative artificial intelligence in the context of medicine.\"\n",
    "\n",
    "# Model invocation\n",
    "output_ai = llm.invoke(prompt).content.strip()\n",
    "\n",
    "# Ethical evaluation of the response\n",
    "ethical_check = assess_ethical_risk(output_ai)\n",
    "\n",
    "if ethical_check[\"revision_suggestion\"]:\n",
    "    print(f\"Ethics: {ethical_check['revision_suggestion']}\")\n",
    "\n",
    "output_ai = llm.invoke(prompt).content.strip()\n",
    "ethical_check = assess_ethical_risk(output_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4-vdyYwCPc0"
   },
   "source": [
    "### Interactive Scientific Chart Generator\n",
    "\n",
    "This cell enables the visualization of data and mathematical models extracted from problems described in natural language:\n",
    "\n",
    "- **Automatic extraction of numerical values** from text  \n",
    "- **Semantic analysis of the problem** to determine the model type:\n",
    "  - exponential growth, motion, oscillation, Gaussian distribution, etc.  \n",
    "- **Interactive chart generation** using `Plotly`, viewable in real time  \n",
    "- **Image export** (`graph_output.png`) for educational or documentation purposes\n",
    "\n",
    "The system translates scientific descriptions into visual representations, simplifying intuition and reasoning around complex concepts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a53e5cdf-aa0b-4173-a8f4-5e1af3de6924\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a53e5cdf-aa0b-4173-a8f4-5e1af3de6924\")) {                    Plotly.newPlot(                        \"a53e5cdf-aa0b-4173-a8f4-5e1af3de6924\",                        [{\"mode\":\"lines\",\"name\":\"Exponential Growth\",\"x\":[1.0,1.0909090909090908,1.1818181818181819,1.2727272727272727,1.3636363636363638,1.4545454545454546,1.5454545454545454,1.6363636363636362,1.7272727272727273,1.8181818181818183,1.9090909090909092,2.0,2.090909090909091,2.1818181818181817,2.2727272727272725,2.3636363636363638,2.4545454545454546,2.5454545454545454,2.6363636363636367,2.7272727272727275,2.8181818181818183,2.909090909090909,3.0,3.090909090909091,3.1818181818181817,3.272727272727273,3.3636363636363638,3.4545454545454546,3.5454545454545454,3.6363636363636362,3.7272727272727275,3.8181818181818183,3.909090909090909,4.0,4.090909090909091,4.181818181818182,4.272727272727273,4.363636363636363,4.454545454545455,4.545454545454545,4.636363636363637,4.7272727272727275,4.818181818181818,4.909090909090909,5.0,5.090909090909091,5.181818181818182,5.2727272727272725,5.363636363636363,5.454545454545455,5.545454545454546,5.636363636363637,5.7272727272727275,5.818181818181818,5.909090909090909,6.0,6.090909090909091,6.181818181818182,6.2727272727272725,6.363636363636364,6.454545454545455,6.545454545454546,6.636363636363637,6.7272727272727275,6.818181818181818,6.909090909090909,7.0,7.090909090909091,7.181818181818182,7.2727272727272725,7.363636363636364,7.454545454545455,7.545454545454546,7.636363636363637,7.7272727272727275,7.818181818181818,7.909090909090909,8.0,8.09090909090909,8.181818181818182,8.272727272727273,8.363636363636363,8.454545454545455,8.545454545454547,8.636363636363637,8.727272727272727,8.818181818181818,8.90909090909091,9.0,9.090909090909092,9.181818181818182,9.272727272727273,9.363636363636363,9.454545454545455,9.545454545454545,9.636363636363637,9.727272727272727,9.818181818181818,9.90909090909091,10.0],\"y\":[1.1051709180756477,1.1152637333451818,1.1254487198059762,1.1357267191982459,1.1460985809492783,1.156565162243634,1.167127328093989,1.1777859514126232,1.1885419130835642,1.1993961020353858,1.2103494153146754,1.2214027581601699,1.232557044077569,1.243813194915033,1.2551721409393686,1.2666348209129108,1.2782021821711071,1.289875180700811,1.3016547812192891,1.3135419572539493,1.3255376912228007,1.3376429745156433,1.3498588075760032,1.3621861999838134,1.3746261705388516,1.387179747344938,1.3998479678949052,1.4126318791563388,1.4255325376581074,1.438551009577678,1.4516883708292303,1.4649457071525769,1.4783241142028936,1.4918246976412703,1.5054485732260887,1.5191968669052343,1.5330707149091505,1.547071263844742,1.5611996707901383,1.5754571033903182,1.589844739953612,1.6043637695490816,1.619015392104792,1.6338008185069803,1.6487212707001282,1.6637779817879503,1.6789721961353052,1.694305169471035,1.709778168991746,1.725392473466536,1.7411493733426786,1.7570501708522728,1.7730961801198653,1.7892887272710578,1.805629150542104,1.8221188003905089,1.8387590396066373,1.8555512434263415,1.8724967996446193,1.8895971087303078,1.9068535839418241,1.9242676514439665,1.9418407504257797,1.9595743332194953,1.977469865420562,1.995528826008769,2.0137527074704766,2.0321430159219633,2.0507012712338994,2.0694290071569563,2.0883277714485637,2.1073991260008245,2.126644646969599,2.1460659249047636,2.1656645648816646,2.18544218663377,2.2054004246865304,2.225540928492468,2.2458653625674914,2.266375406628466,2.2870727557320296,2.30795912041468,2.3290362268341487,2.3503058169120536,2.371769648477861,2.3934294954141673,2.4152871478032942,2.437344412075236,2.45960311115695,2.482065084623012,2.5047321888476515,2.5276062971581683,2.550689299989756,2.5739831050417386,2.5974896374352285,2.621210839872234,2.6451486727962092,2.669305114554079,2.6936821615597384,2.718281828459045],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Visualization of the 'exponential_growth' model from 1 to 10 for the problem: \\\"growth\\\"\"},\"xaxis\":{\"title\":{\"text\":\"X Axis\"}},\"yaxis\":{\"title\":{\"text\":\"Y Axis\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('a53e5cdf-aa0b-4173-a8f4-5e1af3de6924');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as 'grafico_output.png'\n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# The system can analyze text and generate interactive visualizations\n",
    "# (e.g., bar charts, line plots, scatter plots) using Plotly.\n",
    "\n",
    "# === Function to generate the interactive chart ===\n",
    "def extract_numeric_values(text):\n",
    "    \"\"\" Extracts numeric ranges from the problem text. \"\"\"\n",
    "    pattern = r\"(\\d+)\\s*-\\s*(\\d+)|(\\d+\\.\\d+|\\d+)\\s*(K|Pa|m/s)?\"\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    values = []\n",
    "    for match in matches:\n",
    "        if match[0] and match[1]:  # Range (300 - 600)\n",
    "            values.append((int(match[0]), int(match[1])))\n",
    "        elif match[2]:  # Single number with optional unit\n",
    "            values.append(float(match[2]))\n",
    "\n",
    "    return values if values else [1, 10]  # Default if no numbers found\n",
    "\n",
    "# Determines the most suitable chart type based on content\n",
    "def determine_chart_type(text):\n",
    "    text_lower = text.lower()\n",
    "    if re.search(r\"(growth|decay|population)\", text_lower):\n",
    "        return \"exponential_growth\"\n",
    "    elif re.search(r\"(oscillation|frequency|wave)\", text_lower):\n",
    "        return \"sinusoidal\"\n",
    "    elif re.search(r\"(temperature|pressure)\", text_lower):\n",
    "        return \"temperature_pressure\"\n",
    "    elif re.search(r\"(speed|time|acceleration)\", text_lower):\n",
    "        return \"motion\"\n",
    "    elif \"linear\" in text_lower:\n",
    "        return \"linear\"\n",
    "    elif \"logarithmic\" in text_lower:\n",
    "        return \"logarithmic\"\n",
    "    elif \"gaussian\" in text_lower or \"normal distribution\" in text_lower:\n",
    "        return \"gaussian\"\n",
    "    else:\n",
    "        return \"generic\"\n",
    "\n",
    "# Extracts numeric values from text for visualization\n",
    "def extract_numeric_values(text):\n",
    "    numbers = [float(n) for n in re.findall(r\"\\d+(?:\\.\\d+)?\", text)]\n",
    "    if len(numbers) >= 2:\n",
    "        return numbers[:2]\n",
    "    elif len(numbers) == 1:\n",
    "        return [numbers[0], numbers[0] + 10]\n",
    "    else:\n",
    "        return [1, 10]\n",
    "\n",
    "# Generates and saves the interactive chart\n",
    "# The chart is displayed in the notebook and also saved as a PNG image.\n",
    "def generate_interactive_chart(problem):\n",
    "    chart_type = determine_chart_type(problem)\n",
    "    start, end = extract_numeric_values(problem)\n",
    "    x = np.linspace(start, end, 100)\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if chart_type == \"exponential_growth\":\n",
    "        y = np.exp(x / max(x))\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Exponential Growth\"))\n",
    "    elif chart_type == \"sinusoidal\":\n",
    "        y = np.sin(x)\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Sinusoidal Wave\"))\n",
    "    elif chart_type == \"motion\":\n",
    "        y = x ** 2\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Speed vs Time\"))\n",
    "    elif chart_type == \"linear\":\n",
    "        y = x\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Linear Trend\"))\n",
    "    elif chart_type == \"logarithmic\":\n",
    "        x_log = np.where(x <= 0, 1e-3, x)\n",
    "        y = np.log(x_log)\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Logarithmic\"))\n",
    "    elif chart_type == \"gaussian\":\n",
    "        mu, sigma = np.mean(x), np.std(x)\n",
    "        y = np.exp(-((x - mu)**2) / (2 * sigma**2))\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Gaussian\"))\n",
    "    else:\n",
    "        y = np.sin(x)\n",
    "        fig.add_trace(go.Scatter(x=x, y=y, mode=\"lines\", name=\"Generic\"))\n",
    "\n",
    "    caption = f\"Visualization of the '{chart_type}' model from {start} to {end} for the problem: \\\"{problem}\\\"\"\n",
    "    fig.update_layout(\n",
    "        title=caption,\n",
    "        xaxis_title=\"X Axis\",\n",
    "        yaxis_title=\"Y Axis\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_image(\"grafico_output.png\", format=\"png\", width=800, height=500)\n",
    "    print(\"Image saved as 'grafico_output.png'\")\n",
    "    return fig, caption\n",
    "\n",
    "# === Run example chart ===\n",
    "example_problem = \"growth\"\n",
    "fig, caption = generate_interactive_chart(example_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ghaFB78qEJv"
   },
   "source": [
    "### User Module – Personalized Interaction\n",
    "\n",
    "This cell manages intelligent interaction with the user:\n",
    "\n",
    "- Analyzes and classifies the scientific question  \n",
    "- Reformulates the problem in technical terms  \n",
    "- Requests subject, difficulty level, and preferred language  \n",
    "- Offers an interactive chart if requested  \n",
    "- Enables automatic translations into: en, fr, de, es, zh, ja, ar, it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f1ee671d-ae88-4f78-94dd-f1d3e85bf6a1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-f1ee671d-ae88-4f78-94dd-f1d3e85bf6a1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dispensaanatomiaumanacompendioriassunto.pdf to dispensaanatomiaumanacompendioriassunto (1).pdf\n",
      "([{'title': 'Meeting the universe halfway: quantum physics and the entanglement of matter and meaning', 'authors': 'Unknown author', 'abstract': 'Abstract not available', 'url': 'https://doi.org/10.1515/9780822388128'}, {'title': 'Quantum Physics in One Dimension', 'authors': 'Unknown author', 'abstract': 'Abstract not available', 'url': 'https://doi.org/10.1093/acprof:oso/9780198525004.001.0001'}, {'title': 'Quantum physics in one dimension', 'authors': 'Unknown author', 'abstract': 'Abstract not available', 'url': 'https://doi.org/10.1016/b978-0-323-90800-9.00233-x'}, {'title': 'Random-matrix theories in quantum physics: common concepts', 'authors': 'Unknown author, Unknown author, Unknown author', 'abstract': 'Abstract not available', 'url': 'https://doi.org/10.1016/s0370-1573(97)00088-4'}, {'title': 'Green’s Functions in Quantum Physics', 'authors': 'Unknown author', 'abstract': 'Abstract not available', 'url': 'https://doi.org/10.1007/3-540-28841-4'}, {'title': 'PubMed Link', 'abstract': 'Not available', 'url': 'https://pubmed.ncbi.nlm.nih.gov/41582622/', 'authors': 'Unknown'}, {'title': 'PubMed Link', 'abstract': 'Not available', 'url': 'https://pubmed.ncbi.nlm.nih.gov/41582444/', 'authors': 'Unknown'}, {'title': 'PubMed Link', 'abstract': 'Not available', 'url': 'https://pubmed.ncbi.nlm.nih.gov/41581197/', 'authors': 'Unknown'}, {'title': 'PubMed Link', 'abstract': 'Not available', 'url': 'https://pubmed.ncbi.nlm.nih.gov/41581183/', 'authors': 'Unknown'}, {'title': 'PubMed Link', 'abstract': 'Not available', 'url': 'https://pubmed.ncbi.nlm.nih.gov/41580989/', 'authors': 'Unknown'}, {'title': 'TRR-NOTIME: Theory of Relative Reality - Without Time', 'authors': 'Březina, Michal', 'abstract': '<p>TRR-NOTIME (Theory of Relative Reality - Without Time) presents an alternative perspective on physics, where time is not a fundamental quantity but merely a consequence of matter-energy interactions. This theory redefines the concept of gravity, nuclear decay, and quantum processes, enabling a unified understanding of physical reality without the need for a time dimension. The document summarizes the theory, its mathematical structure, and potential experimental validation.</p>', 'url': 'No link'}, {'title': 'Vortices and vortex stripes in a dipolar Bose-Einstein condensate', 'authors': 'Klaus, Bland, Poli, Politi, Lamporesi, Casotti, Bisset, Mark, Ferlaino', 'abstract': '<p>Quantized vortices are a prototypical feature of superfluidity that have been observed in multiple quantum gas experiments. But the occurrence of vortices in dipolar quantum gases &mdash; a class of ultracold gases characterized by long-range anisotropic interactions &mdash; has not been reported yet. Here, we exploit the anisotropic nature of the dipole-dipole interaction of a dysprosium Bose-Einstein condensate to induce angular symmetry breaking in an otherwise cylindrically symmetric pancake-shaped trap. Tilting the magnetic field towards the radial plane deforms the cloud into an ellipsoid, which is then set into rotation. At stirring frequencies approaching the radial trap frequency, we observe the generation of dynamically unstable surface excitations, which cause angular momentum to be pumped into the system through vortices. Under continuous rotation, the vortices arrange into a stripe configuration along the field, in close agreement with numerical simulations.</p>', 'url': 'No link'}, {'title': 'Multimodal Brain Imaging Fusion Using Machine Learning for Enhanced Diagnostic Accuracy.', 'authors': 'Atlas, Quantum', 'abstract': 'Abstract not available', 'url': 'No link'}, {'title': 'Spin-State Engineering of Single Titanium Adsorbates on Ultrathin Magnesium Oxide', 'authors': 'Phark, Soo-hyon, Bui, Hong Thi, Seo, We-hyo, Liu, Yaowu, Sheina, Valeria, Lee, Curie, Wolf, Christoph, Heinrich, Andreas J, Robles, Roberto, Lorente, Nicolás', 'abstract': '<p>Experimental and theoretical data comprising the study of Ti adatoms and related species on MgO/Ag(100) using STM, ESR-STM, DFT and multiplet calculations.</p>', 'url': 'No link'}, {'title': 'QUANTUM MATHEMATICS AND PHYSICS: STUDYING MATHEMATICAL FOUNDATIONS AND APPLICATIONS', 'authors': 'Khudaikulova, Saida, Ruzikulov, Shahabbas', 'abstract': '<p>Quantum mechanics and quantum physics have revolutionized our understanding of the fundamental nature of reality. At the core of this revolution lies quantum mathematics, which provides the mathematical foundation for describing the motion of particles at microscopic scales. This article explores the fundamental mathematical structures of quantum mechanics, including Hilbert spaces, operators, and wave functions, as well as their applications in modeling physical systems. The research also examines how quantum physics contrasts with classical physics concepts and offers new insights into topics such as quantum entanglement, superposition, and quantum computing. By analyzing the mathematical foundations of quantum theories, the article aims to shed light on the intersection of mathematics and physics, offering a deeper understanding of how mathematical formulas help predict and explain quantum phenomena. Furthermore, it discusses the potential implications of quantum mathematics in emerging fields such as quantum computing and cryptography.</p>', 'url': 'No link'}], '**Meeting the universe halfway: quantum physics and the entanglement of matter and meaning**: Abstract not available\\n\\n**Quantum Physics in One Dimension**: Abstract not available\\n\\n**Quantum physics in one dimension**: Abstract not available\\n\\n**Random-matrix theories in quantum physics: common concepts**: Abstract not available\\n\\n**Green’s Functions in Quantum Physics**: Abstract not available\\n\\n**PubMed Link**: Not available\\n\\n**PubMed Link**: Not available\\n\\n**PubMed Link**: Not available\\n\\n**PubMed Link**: Not available\\n\\n**PubMed Link**: Not available\\n\\n**TRR-NOTIME: Theory of Relative Reality - Without Time**: <p>TRR-NOTIME (Theory of Relative Reality - Without Time) presents an alternative perspective on physics, where time is not a fundamental quantity but merely a consequence of matter-energy interactions. This theory redefines the concept of gravity, nuclear decay, and quantum processes, enabling a unified understanding of physical reality without the need for a time dimension. The document summarizes the theory, its mathematical structure, and potential experimental validation.</p>\\n\\n**Vortices and vortex stripes in a dipolar Bose-Einstein condensate**: <p>Quantized vortices are a prototypical feature of superfluidity that have been observed in multiple quantum gas experiments. But the occurrence of vortices in dipolar quantum gases &mdash; a class of ultracold gases characterized by long-range anisotropic interactions &mdash; has not been reported yet. Here, we exploit the anisotropic nature of the dipole-dipole interaction of a dysprosium Bose-Einstein condensate to induce angular symmetry breaking in an otherwise cylindrically symmetric pancake-shaped trap. Tilting the magnetic field towards the radial plane deforms the cloud into an ellipsoid, which is then set into rotation. At stirring frequencies approaching the radial trap frequency, we observe the generation of dynamically unstable surface excitations, which cause angular momentum to be pumped into the system through vortices. Under continuous rotation, the vortices arrange into a stripe configuration along the field, in close agreement with numerical simulations.</p>\\n\\n**Multimodal Brain Imaging Fusion Using Machine Learning for Enhanced Diagnostic Accuracy.**: Abstract not available\\n\\n**Spin-State Engineering of Single Titanium Adsorbates on Ultrathin Magnesium Oxide**: <p>Experimental and theoretical data comprising the study of Ti adatoms and related species on MgO/Ag(100) using STM, ESR-STM, DFT and multiplet calculations.</p>\\n\\n**QUANTUM MATHEMATICS AND PHYSICS: STUDYING MATHEMATICAL FOUNDATIONS AND APPLICATIONS**: <p>Quantum mechanics and quantum physics have revolutionized our understanding of the fundamental nature of reality. At the core of this revolution lies quantum mathematics, which provides the mathematical foundation for describing the motion of particles at microscopic scales. This article explores the fundamental mathematical structures of quantum mechanics, including Hilbert spaces, operators, and wave functions, as well as their applications in modeling physical systems. The research also examines how quantum physics contrasts with classical physics concepts and offers new insights into topics such as quantum entanglement, superposition, and quantum computing. By analyzing the mathematical foundations of quantum theories, the article aims to shed light on the intersection of mathematics and physics, offering a deeper understanding of how mathematical formulas help predict and explain quantum phenomena. Furthermore, it discusses the potential implications of quantum mathematics in emerging fields such as quantum computing and cryptography.</p>')\n",
      "Enter the subject (e.g., physics, biology, etc.): medicine\n",
      "Choose the level (basic/advanced/expert): basic\n",
      "Enter the scientific problem or topic: Apparato tegumentario\n",
      "Do you want a chart for the explanation? (yes/no): yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3ab1142c-a0d5-41fc-b065-50aa5486bc95\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3ab1142c-a0d5-41fc-b065-50aa5486bc95\")) {                    Plotly.newPlot(                        \"3ab1142c-a0d5-41fc-b065-50aa5486bc95\",                        [{\"mode\":\"lines\",\"name\":\"Speed vs Time\",\"x\":[2.0,2.0202020202020203,2.04040404040404,2.0606060606060606,2.080808080808081,2.101010101010101,2.121212121212121,2.1414141414141414,2.1616161616161618,2.1818181818181817,2.202020202020202,2.2222222222222223,2.242424242424242,2.2626262626262625,2.282828282828283,2.303030303030303,2.323232323232323,2.3434343434343434,2.3636363636363638,2.383838383838384,2.404040404040404,2.4242424242424243,2.4444444444444446,2.4646464646464645,2.484848484848485,2.505050505050505,2.525252525252525,2.5454545454545454,2.5656565656565657,2.5858585858585856,2.606060606060606,2.6262626262626263,2.6464646464646466,2.666666666666667,2.686868686868687,2.707070707070707,2.7272727272727275,2.7474747474747474,2.7676767676767677,2.787878787878788,2.808080808080808,2.8282828282828283,2.8484848484848486,2.8686868686868685,2.888888888888889,2.909090909090909,2.9292929292929295,2.94949494949495,2.9696969696969697,2.98989898989899,3.0101010101010104,3.0303030303030303,3.0505050505050506,3.070707070707071,3.090909090909091,3.111111111111111,3.1313131313131315,3.1515151515151514,3.1717171717171717,3.191919191919192,3.212121212121212,3.2323232323232327,3.2525252525252526,3.272727272727273,3.2929292929292933,3.313131313131313,3.3333333333333335,3.353535353535354,3.3737373737373737,3.393939393939394,3.4141414141414144,3.4343434343434343,3.4545454545454546,3.474747474747475,3.494949494949495,3.5151515151515156,3.5353535353535355,3.5555555555555554,3.575757575757576,3.595959595959596,3.6161616161616164,3.6363636363636367,3.6565656565656566,3.676767676767677,3.6969696969696972,3.717171717171717,3.7373737373737375,3.757575757575758,3.7777777777777777,3.7979797979797985,3.8181818181818183,3.8383838383838382,3.858585858585859,3.878787878787879,3.8989898989898992,3.9191919191919196,3.9393939393939394,3.95959595959596,3.97979797979798,4.0],\"y\":[4.0,4.081216202428324,4.163248648097132,4.246097337006428,4.329762269156209,4.414243444546476,4.499540863177226,4.585654525048464,4.672584430160188,4.760330578512396,4.848892970105092,4.938271604938272,5.028466483011937,5.119477604326089,5.211304968880727,5.30394857667585,5.397408427711458,5.491684521987552,5.586776859504133,5.682685440261199,5.779410264258749,5.8769513314967865,5.975308641975309,6.0744821956943165,6.174471992653811,6.275278032853791,6.376900316294255,6.479338842975206,6.582593612896644,6.6866646260585645,6.791551882460973,6.897255382103867,7.003775124987247,7.1111111111111125,7.219263340475462,7.328231813080299,7.438016528925621,7.548617488011427,7.660034690337721,7.7722681359045005,7.8853178247117635,7.999183756759514,8.113865932047752,8.229364350576471,8.345679012345679,8.462809917355372,8.580757065605551,8.699520457096217,8.819100091827364,8.939495969799001,9.060708091011122,9.182736455463727,9.305581063156822,9.429241914090401,9.553719008264462,9.679012345679013,9.80512192633405,9.932047750229568,10.059789817365575,10.188348127742067,10.317722681359044,10.447913478216512,10.578920518314458,10.710743801652894,10.843383328231814,10.976839098051219,11.111111111111112,11.24619936741149,11.382103866952352,11.518824609733702,11.656361595755536,11.794714825017854,11.933884297520661,12.073870013263955,12.214671972247729,12.356290174471996,12.498724619936741,12.641975308641975,12.786042240587697,12.9309254157739,13.076624834200594,13.22314049586777,13.370472400775432,13.51862054892358,13.667584940312215,13.817365574941332,13.967962452810939,14.11937557392103,14.271604938271604,14.42465054586267,14.578512396694217,14.733190490766248,14.888684828078771,15.044995408631774,15.202122232425264,15.360065299459242,15.5188246097337,15.67840016324865,15.838791960004084,16.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Visualization of the 'motion' model from 2.0 to 4.0 for the problem: \\\"______________________\\nCOMPENDIO\\nDI\\nANATOMIA UMANA\\n______________________\\nSeconda Edizione\\nwww.massimofranzin.it\\nQuesta dispensa è da ritenersi\\nad integrazione delle slides pubblicate sul sito.\\n2\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nIndice\\nPrefazione alla seconda edizione pag. 4\\n1. Anatomia generale pag. 5\\n2. Cenni di citologia e istologia pag. 6\\n3. Apparato tegumentario pag. 13 3\\n4. Apparato muscolo-scheletrico o locomotore pag. 15\\n5. Apparato Circolatorio pag. 59\\n6. Apparato Digerente pag. 97\\n7. Apparato Respiratorio pag. 145\\n8. Apparato Urinario pag. 153\\n9. Apparato Genitale Maschile pag. 179\\n10. Apparato Genitale Femminile pag. 193\\n11. Apparato Endocrino pag. 208\\n12. Sistema nervoso pag. 217\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nPrefazione\\nPer ricordare lo sforzo fatto per redigere la seconda edizione, mi rifaccio ad una frase del grande\\nscrittore Charles Baudelaire: “C'è un solo modo di dimenticare il tempo: impiegarlo.” Sì, è proprio\\ncosì, ed è quello che abbiamo fatto da quattro anni a questa parte, da quando cioè è uscita la\\nprima edizione del “Compendio di Anatomia Umana”.\\nOra è momento di bilanci, riflessioni, ringraziamenti. Quando si arriva alla fine di un percorso, si\\nguarda indietro . Si comprendono gli errori, si rivedono le posizioni, si è più forti in virtù\\n4\\ndell’esperienza vissuta. E’ stata, senza dubbio, un’ avventura straordinaria e carica di emozioni.\\nAbbiamo lavorato con entusiasmo, impegno ed una soddisfazione reale e vissuta. Ciò che ci ha\\nguidati è stata la passione e la voglia di imparare, non sentendosi mai arrivati del tutto. Ci ha\\nportati avanti il desiderio di fare sempre di più e sempre meglio nella consapevolezza che l’uomo\\nin ciò che fa deve cercare di tendere all’infinito, per aggiungere un pezzo di eterno al proprio\\noperato. Non mi resta che ringraziare tutti quanti hanno collaborato. Per me è stato un viaggio e\\ncome un viaggiatore sono arrivato alla meta, anzi il viaggio stesso è stato la vera meta come\\nsostiene Kostantin Kavafis nella poesia “Itaca”. La fine segna sempre un inizio… Leggete la poesia,\\nun piccolo regalo per voi…\\nMassimo Franzin\\n___________________________________________________________________________________________________________\\nQuando ti metterai in viaggio per Itaca piu' profumi inebrianti che puoi,\\ndevi augurarti che la strada sia lunga, va in molte citta` egizie\\nfertile in avventure e in esperienze. impara una quantità di cose dai dotti.\\nI Lestrigoni e i Ciclopi Sempre devi avere in mente Itaca -\\no la furia di Nettuno non temere, raggiungerla sia il pensiero costante.\\nnon sara` questo il genere di incontri Soprattutto, non affrettare il viaggio;\\nse il pensiero resta alto e un sentimento fa che duri a lungo, per anni, e che da vecchio\\nfermo guida il tuo spirito e il tuo corpo. metta piede sull'isola, tu, ricco\\nIn Ciclopi e Lestrigoni, no certo, dei tesori accumulati per strada\\nne' nell'irato Nettuno incapperai senza aspettarti ricchezze da Itaca.\\nse non li porti dentro Itaca ti ha dato il bel viaggio,\\nse l'anima non te li mette contro. senza di lei mai ti saresti messo\\nDevi augurarti che la strada sia lunga. sulla strada: che cos'altro ti aspetti?\\nChe i mattini d'estate siano tanti E se la trovi povera, non per questo Itaca ti avrà\\nquando nei porti - finalmente e con che gioia - deluso.\\ntoccherai terra tu per la prima volta: Fatto ormai savio, con tutta la tua esperienza\\nnegli empori fenici indugia e acquista addosso gia` tu avrai capito cio` che Itaca vuole\\nmadreperle coralli ebano e ambre significare.\\ntutta merce fina, anche profumi\\npenetranti d'ogni sorta; Kostantin Kavafis\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\n1. Anatomia Generale\\nL'Anatomia è la disciplina che studia le caratteristiche macroscopiche e microscopiche degli\\norgani che compongono il corpo umano, la loro posizione, i loro rapporti topografici ed il loro\\nsviluppo. Quando si descrive la posizione assunta da una parte o la localizzazione di un organo,\\nalla posizione supina (col viso e ventre rivolto verso l'alto) o prona (col viso e ventre rivolto verso\\nterra) si predilige considerare il corpo in posizione anatomica, cioè eretto con la faccia rivolta in\\navanti, braccia lungo il corpo, le palme in avanti ed i piedi leggermente divaricati. La posizione di\\n5\\nqualsiasi parte del corpo umano può essere definita facendo riferimento a tre piani fra loro\\nperpendicolari. Sono questi il piano sagittale, il piano frontale ed il piano trasversale.\\nIl piano sagittale\\nIl piano anatomico sagittale è quel piano che decorre in senso antero-posteriore mediano,\\nperpendicolare alla superficie di appogg\\\"\"},\"xaxis\":{\"title\":{\"text\":\"X Axis\"}},\"yaxis\":{\"title\":{\"text\":\"Y Axis\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3ab1142c-a0d5-41fc-b065-50aa5486bc95');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as 'grafico_output.png'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9abf173f-c14c-4939-b4e3-200185247645\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9abf173f-c14c-4939-b4e3-200185247645\")) {                    Plotly.newPlot(                        \"9abf173f-c14c-4939-b4e3-200185247645\",                        [{\"mode\":\"lines\",\"name\":\"Speed vs Time\",\"x\":[2.0,2.0202020202020203,2.04040404040404,2.0606060606060606,2.080808080808081,2.101010101010101,2.121212121212121,2.1414141414141414,2.1616161616161618,2.1818181818181817,2.202020202020202,2.2222222222222223,2.242424242424242,2.2626262626262625,2.282828282828283,2.303030303030303,2.323232323232323,2.3434343434343434,2.3636363636363638,2.383838383838384,2.404040404040404,2.4242424242424243,2.4444444444444446,2.4646464646464645,2.484848484848485,2.505050505050505,2.525252525252525,2.5454545454545454,2.5656565656565657,2.5858585858585856,2.606060606060606,2.6262626262626263,2.6464646464646466,2.666666666666667,2.686868686868687,2.707070707070707,2.7272727272727275,2.7474747474747474,2.7676767676767677,2.787878787878788,2.808080808080808,2.8282828282828283,2.8484848484848486,2.8686868686868685,2.888888888888889,2.909090909090909,2.9292929292929295,2.94949494949495,2.9696969696969697,2.98989898989899,3.0101010101010104,3.0303030303030303,3.0505050505050506,3.070707070707071,3.090909090909091,3.111111111111111,3.1313131313131315,3.1515151515151514,3.1717171717171717,3.191919191919192,3.212121212121212,3.2323232323232327,3.2525252525252526,3.272727272727273,3.2929292929292933,3.313131313131313,3.3333333333333335,3.353535353535354,3.3737373737373737,3.393939393939394,3.4141414141414144,3.4343434343434343,3.4545454545454546,3.474747474747475,3.494949494949495,3.5151515151515156,3.5353535353535355,3.5555555555555554,3.575757575757576,3.595959595959596,3.6161616161616164,3.6363636363636367,3.6565656565656566,3.676767676767677,3.6969696969696972,3.717171717171717,3.7373737373737375,3.757575757575758,3.7777777777777777,3.7979797979797985,3.8181818181818183,3.8383838383838382,3.858585858585859,3.878787878787879,3.8989898989898992,3.9191919191919196,3.9393939393939394,3.95959595959596,3.97979797979798,4.0],\"y\":[4.0,4.081216202428324,4.163248648097132,4.246097337006428,4.329762269156209,4.414243444546476,4.499540863177226,4.585654525048464,4.672584430160188,4.760330578512396,4.848892970105092,4.938271604938272,5.028466483011937,5.119477604326089,5.211304968880727,5.30394857667585,5.397408427711458,5.491684521987552,5.586776859504133,5.682685440261199,5.779410264258749,5.8769513314967865,5.975308641975309,6.0744821956943165,6.174471992653811,6.275278032853791,6.376900316294255,6.479338842975206,6.582593612896644,6.6866646260585645,6.791551882460973,6.897255382103867,7.003775124987247,7.1111111111111125,7.219263340475462,7.328231813080299,7.438016528925621,7.548617488011427,7.660034690337721,7.7722681359045005,7.8853178247117635,7.999183756759514,8.113865932047752,8.229364350576471,8.345679012345679,8.462809917355372,8.580757065605551,8.699520457096217,8.819100091827364,8.939495969799001,9.060708091011122,9.182736455463727,9.305581063156822,9.429241914090401,9.553719008264462,9.679012345679013,9.80512192633405,9.932047750229568,10.059789817365575,10.188348127742067,10.317722681359044,10.447913478216512,10.578920518314458,10.710743801652894,10.843383328231814,10.976839098051219,11.111111111111112,11.24619936741149,11.382103866952352,11.518824609733702,11.656361595755536,11.794714825017854,11.933884297520661,12.073870013263955,12.214671972247729,12.356290174471996,12.498724619936741,12.641975308641975,12.786042240587697,12.9309254157739,13.076624834200594,13.22314049586777,13.370472400775432,13.51862054892358,13.667584940312215,13.817365574941332,13.967962452810939,14.11937557392103,14.271604938271604,14.42465054586267,14.578512396694217,14.733190490766248,14.888684828078771,15.044995408631774,15.202122232425264,15.360065299459242,15.5188246097337,15.67840016324865,15.838791960004084,16.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Visualization of the 'motion' model from 2.0 to 4.0 for the problem: \\\"______________________\\nCOMPENDIO\\nDI\\nANATOMIA UMANA\\n______________________\\nSeconda Edizione\\nwww.massimofranzin.it\\nQuesta dispensa è da ritenersi\\nad integrazione delle slides pubblicate sul sito.\\n2\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nIndice\\nPrefazione alla seconda edizione pag. 4\\n1. Anatomia generale pag. 5\\n2. Cenni di citologia e istologia pag. 6\\n3. Apparato tegumentario pag. 13 3\\n4. Apparato muscolo-scheletrico o locomotore pag. 15\\n5. Apparato Circolatorio pag. 59\\n6. Apparato Digerente pag. 97\\n7. Apparato Respiratorio pag. 145\\n8. Apparato Urinario pag. 153\\n9. Apparato Genitale Maschile pag. 179\\n10. Apparato Genitale Femminile pag. 193\\n11. Apparato Endocrino pag. 208\\n12. Sistema nervoso pag. 217\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nPrefazione\\nPer ricordare lo sforzo fatto per redigere la seconda edizione, mi rifaccio ad una frase del grande\\nscrittore Charles Baudelaire: “C'è un solo modo di dimenticare il tempo: impiegarlo.” Sì, è proprio\\ncosì, ed è quello che abbiamo fatto da quattro anni a questa parte, da quando cioè è uscita la\\nprima edizione del “Compendio di Anatomia Umana”.\\nOra è momento di bilanci, riflessioni, ringraziamenti. Quando si arriva alla fine di un percorso, si\\nguarda indietro . Si comprendono gli errori, si rivedono le posizioni, si è più forti in virtù\\n4\\ndell’esperienza vissuta. E’ stata, senza dubbio, un’ avventura straordinaria e carica di emozioni.\\nAbbiamo lavorato con entusiasmo, impegno ed una soddisfazione reale e vissuta. Ciò che ci ha\\nguidati è stata la passione e la voglia di imparare, non sentendosi mai arrivati del tutto. Ci ha\\nportati avanti il desiderio di fare sempre di più e sempre meglio nella consapevolezza che l’uomo\\nin ciò che fa deve cercare di tendere all’infinito, per aggiungere un pezzo di eterno al proprio\\noperato. Non mi resta che ringraziare tutti quanti hanno collaborato. Per me è stato un viaggio e\\ncome un viaggiatore sono arrivato alla meta, anzi il viaggio stesso è stato la vera meta come\\nsostiene Kostantin Kavafis nella poesia “Itaca”. La fine segna sempre un inizio… Leggete la poesia,\\nun piccolo regalo per voi…\\nMassimo Franzin\\n___________________________________________________________________________________________________________\\nQuando ti metterai in viaggio per Itaca piu' profumi inebrianti che puoi,\\ndevi augurarti che la strada sia lunga, va in molte citta` egizie\\nfertile in avventure e in esperienze. impara una quantità di cose dai dotti.\\nI Lestrigoni e i Ciclopi Sempre devi avere in mente Itaca -\\no la furia di Nettuno non temere, raggiungerla sia il pensiero costante.\\nnon sara` questo il genere di incontri Soprattutto, non affrettare il viaggio;\\nse il pensiero resta alto e un sentimento fa che duri a lungo, per anni, e che da vecchio\\nfermo guida il tuo spirito e il tuo corpo. metta piede sull'isola, tu, ricco\\nIn Ciclopi e Lestrigoni, no certo, dei tesori accumulati per strada\\nne' nell'irato Nettuno incapperai senza aspettarti ricchezze da Itaca.\\nse non li porti dentro Itaca ti ha dato il bel viaggio,\\nse l'anima non te li mette contro. senza di lei mai ti saresti messo\\nDevi augurarti che la strada sia lunga. sulla strada: che cos'altro ti aspetti?\\nChe i mattini d'estate siano tanti E se la trovi povera, non per questo Itaca ti avrà\\nquando nei porti - finalmente e con che gioia - deluso.\\ntoccherai terra tu per la prima volta: Fatto ormai savio, con tutta la tua esperienza\\nnegli empori fenici indugia e acquista addosso gia` tu avrai capito cio` che Itaca vuole\\nmadreperle coralli ebano e ambre significare.\\ntutta merce fina, anche profumi\\npenetranti d'ogni sorta; Kostantin Kavafis\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\n1. Anatomia Generale\\nL'Anatomia è la disciplina che studia le caratteristiche macroscopiche e microscopiche degli\\norgani che compongono il corpo umano, la loro posizione, i loro rapporti topografici ed il loro\\nsviluppo. Quando si descrive la posizione assunta da una parte o la localizzazione di un organo,\\nalla posizione supina (col viso e ventre rivolto verso l'alto) o prona (col viso e ventre rivolto verso\\nterra) si predilige considerare il corpo in posizione anatomica, cioè eretto con la faccia rivolta in\\navanti, braccia lungo il corpo, le palme in avanti ed i piedi leggermente divaricati. La posizione di\\n5\\nqualsiasi parte del corpo umano può essere definita facendo riferimento a tre piani fra loro\\nperpendicolari. Sono questi il piano sagittale, il piano frontale ed il piano trasversale.\\nIl piano sagittale\\nIl piano anatomico sagittale è quel piano che decorre in senso antero-posteriore mediano,\\nperpendicolare alla superficie di appogg\\\"\"},\"xaxis\":{\"title\":{\"text\":\"X Axis\"}},\"yaxis\":{\"title\":{\"text\":\"Y Axis\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('9abf173f-c14c-4939-b4e3-200185247645');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which language do you want the translation in? (en, fr, de, es, zh, ja, ar, it): en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar journal: \n",
      "Similar journal: \n",
      "Similar journal: \n"
     ]
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# This cell analyzes the user's question and adapts the response\n",
    "# based on subject, skill level, language, and preferences.\n",
    "\n",
    "# Analyze the question to extract intent and context\n",
    "def analyze_question(question):\n",
    "    question_lower = question.lower()\n",
    "    if re.search(r\"\\d+|equation|formula|calculate|solve\", question_lower):\n",
    "        return \"mathematical problem\"\n",
    "    elif re.search(r\"anatomy|biology|description|organ|function|system\", question_lower):\n",
    "        return \"descriptive-biological problem\"\n",
    "    elif re.search(r\"experiment|measurement|test|observation\", question_lower):\n",
    "        return \"experimental problem\"\n",
    "    else:\n",
    "        return \"theoretical problem\"\n",
    "\n",
    "# Extract semantic and conceptual characteristics\n",
    "def extract_features(problem):\n",
    "    problem_lower = problem.lower()\n",
    "    if re.search(r\"\\d+|equation|formula|energy|speed\", problem_lower):\n",
    "        return \"Chart\"\n",
    "    elif re.search(r\"principle|theory|model|experiment\", problem_lower):\n",
    "        return \"Conceptual diagram\"\n",
    "    elif re.search(r\"pressure|volume|temperature|transformation\", problem_lower):\n",
    "        return \"State diagram\"\n",
    "    else:\n",
    "        return \"Plain text\"\n",
    "\n",
    "# Reformulate the question to make it clearer for the model\n",
    "def reformulate_question(question):\n",
    "    prompt = f\"\"\"Reformulate this question in a technical and precise way for a scientific AI assistant.\n",
    "\n",
    "Question: \"{question}\"\n",
    "\n",
    "Return only the reformulated question, without explanations.\"\"\"\n",
    "    response = generate_response(prompt, temperature=0.5).strip()\n",
    "\n",
    "    for prefix in [\n",
    "        \"The generated response to the question\",\n",
    "        \"Return only the reformulated question\",\n",
    "        \"Question:\"\n",
    "    ]:\n",
    "        if response.lower().startswith(prefix.lower()):\n",
    "            response = response[len(prefix):].strip(\": .\\\"'\\n\")\n",
    "\n",
    "    if \"\\n\" in response:\n",
    "        response = response.split(\"\\n\")[0].strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "# === File upload ===\n",
    "try:\n",
    "    uploaded = files.upload()\n",
    "    file_name = list(uploaded.keys())[0]\n",
    "    file_text = extract_text(file_name)\n",
    "\n",
    "    if not file_text or file_text == \"Empty or non-textual file.\":\n",
    "        raise ValueError(\"The uploaded file does not contain valid text.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"File upload error: {e}\")\n",
    "    file_text = input(\"Manually enter the problem: \").strip()\n",
    "\n",
    "# Save\n",
    "with open(INDEX_FILE, \"wb\") as f:\n",
    "    pickle.dump(index, f)\n",
    "\n",
    "# Load\n",
    "with open(INDEX_FILE, \"rb\") as f:\n",
    "    index = pickle.load(f)\n",
    "\n",
    "\n",
    "# Generate intelligent report\n",
    "async def example_search():\n",
    "    query = \"quantum physics\"\n",
    "    articles = await search_multi_database(query)\n",
    "    print(articles)\n",
    "\n",
    "# Execute the function directly with await\n",
    "await example_search()\n",
    "\n",
    "# === User input ===\n",
    "import asyncio\n",
    "\n",
    "# Validate that input is correct and coherent\n",
    "async def get_valid_input(message, valid_options=None):\n",
    "    \"\"\" Asynchronous function to handle validated input. \"\"\"\n",
    "    while True:\n",
    "        value = await asyncio.to_thread(input, message.strip())\n",
    "        value = value.strip()\n",
    "\n",
    "        if not value:\n",
    "            print(\"Error! Please enter a valid value.\")\n",
    "        elif valid_options and value.lower() not in valid_options:\n",
    "            print(f\"Error! You must choose from: {', '.join(valid_options)}\")\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "example_problem = \"\"\n",
    "\n",
    "while not example_problem:\n",
    "    example_problem = file_text.strip() if file_text.strip() else await get_valid_input(\"Enter the problem manually:\")\n",
    "\n",
    "subject = input(\"Enter the subject (e.g., physics, biology, etc.): \").strip().lower() or \"general subject\"\n",
    "level = input(\"Choose the level (basic/advanced/expert): \").strip().lower()\n",
    "while level not in [\"basic\", \"advanced\", \"expert\"]:\n",
    "    level = input(\"Error! Enter basic/advanced/expert: \").strip().lower()\n",
    "\n",
    "topic = input(\"Enter the scientific problem or topic: \").strip()\n",
    "\n",
    "chart_choice = input(\"Do you want a chart for the explanation? (yes/no): \").strip().lower()\n",
    "while chart_choice not in [\"yes\", \"no\"]:\n",
    "    chart_choice = input(\"Error! Please answer 'yes' or 'no': \").strip().lower()\n",
    "\n",
    "chart_requested = chart_choice == \"yes\"\n",
    "\n",
    "fig = None\n",
    "caption = \"\"\n",
    "\n",
    "if chart_requested:\n",
    "    try:\n",
    "        fig, caption = generate_interactive_chart(example_problem)\n",
    "        fig.show()\n",
    "        logging.info(\"Chart successfully generated.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Chart generation error: {e}\")\n",
    "        fig = None\n",
    "else:\n",
    "    logging.info(\"Chart not requested by the user.\")\n",
    "\n",
    "available_languages = [\"en\", \"fr\", \"de\", \"es\", \"zh\", \"ja\", \"ar\", \"it\"]\n",
    "\n",
    "target_language = input(\"Which language do you want the translation in? (\" + \", \".join(available_languages) + \"): \").strip().lower()\n",
    "while target_language not in available_languages:\n",
    "    target_language = input(\"Error! Choose a valid language from: \" + \", \".join(available_languages) + \": \").strip().lower()\n",
    "\n",
    "#Secure Translation and Protected Embedding Storage\n",
    "save_multilingual_journal(\n",
    "    journal_text=example_problem,\n",
    "    journal_id=0,\n",
    "    target_language=target_language\n",
    ")\n",
    "\n",
    "#Secure Translation and Protected Embedding Retrieval\n",
    "similar_entries = search_similar_journals(\n",
    "    query=example_problem,\n",
    "    target_language=target_language\n",
    ")\n",
    "\n",
    "for s in similar_entries:\n",
    "    print(\"Similar journal:\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W95HLCjFkV3o"
   },
   "source": [
    "introducing deterministic routing that selects the correct template before prompt construction, preventing the model from inventing or mixing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Task Routing (Problem 1 Fix) ===\n",
    "# Task routing must be executed AFTER user input is collected\n",
    "# and BEFORE building the prompt template.\n",
    "\n",
    "def route_task(user_input):\n",
    "    text = user_input.lower()\n",
    "    if \"review\" in text:\n",
    "        return \"review\"\n",
    "    elif \"summarize\" in text:\n",
    "        return \"summary\"\n",
    "    elif \"explain\" in text:\n",
    "        return \"explanation\"\n",
    "    else:\n",
    "        return \"generic\"\n",
    "\n",
    "task = route_task(example_problem)\n",
    "\n",
    "if task == \"review\":\n",
    "    selected_template = review_prompt\n",
    "elif task == \"summary\":\n",
    "    selected_template = summary_prompt\n",
    "elif task == \"explanation\":\n",
    "    selected_template = explanation_prompt\n",
    "else:\n",
    "    selected_template = generic_prompt\n",
    "\n",
    "\n",
    "response = llm.invoke(prompt.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNUqA9_SCc2Z"
   },
   "source": [
    "### AGI Cognitive Pipeline – Planning, Reasoning, and Metacognition\n",
    "\n",
    "This cell activates an AGI pipeline that combines:\n",
    "\n",
    "- **Multistep interactive loop** with autonomous planning (`interactive_loop_agi`)  \n",
    "- **Creative scientific generation** (hypothesis, experiment, interdisciplinary reflection)  \n",
    "- **Response evaluation** using semantic scoring (`CrossEncoder`)  \n",
    "- **Cognitive versioning**: stores and compares responses over time for each query (`evaluate_and_answer_version`)  \n",
    "- **Explicit reasoning and metacognition** on response coherence and structure  \n",
    "- **Historical memory and distributed scientific retrieval** (arXiv, PubMed, Zenodo, OpenAlex)  \n",
    "- **Visual generation with interactive chart** based on semantic analysis of the problem\n",
    "\n",
    "This AGI pipeline simulates a scientific cognitive assistant, capable of decomposing objectives, reasoning through choices, learning over time, and generating highly reliable personalized responses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem type: mathematical problem\n",
      "Recommended representation: Chart\n",
      "Reasoning explanation:\n",
      " ## Apparato Tegumentario: A Comprehensive Analysis\n",
      "\n",
      "The \"Apparato tegumentario\" or integumentary system is a complex and multifaceted system that plays a crucial role in maintaining the overall health and function of the human body. In this response, we will provide a detailed analysis of the apparato tegumentario, including its structure, function, and significance.\n",
      "\n",
      "### Introduction\n",
      "\n",
      "The integumentary system is the outermost layer of the body, comprising the skin and its associated appendages, such as hair, nails, and glands. It serves as a protective barrier against external factors, regulates body temperature, and aids in the production of vitamin D.\n",
      "\n",
      "### Structure and Function\n",
      "\n",
      "The skin is composed of several layers, including the epidermis, dermis, and hypodermis. The epidermis is the outermost layer, responsible for protecting the body from external factors, such as water loss and pathogens. The dermis lies beneath the epidermis and contains blood vessels, nerve endings, and hair follicles. The hypodermis is the innermost layer, comprising subcutaneous fat and connective tissue.\n",
      "\n",
      "The apparato tegumentario performs several critical functions, including:\n",
      "\n",
      "1. **Protection**: The skin acts as a barrier against external factors, such as pathogens, toxins, and physical damage.\n",
      "2. **Regulation**: The skin regulates body temperature through sweating and vasodilation.\n",
      "3. **Sensation**: The skin contains nerve endings that allow for the perception of sensations, such as touch, pressure, and pain.\n",
      "4. **Production**: The skin produces vitamin D through exposure to UV radiation.\n",
      "\n",
      "### Significance\n",
      "\n",
      "The apparato tegumentario plays a vital role in maintaining overall health and function. Dysfunctions or disorders of the skin can have significant consequences, such as:\n",
      "\n",
      "1. **Infections**: Bacterial, viral, or fungal infections can occur when the skin's barrier function is compromised.\n",
      "2. **Skin cancers**: Prolonged exposure to UV radiation can lead to the development of skin cancers, such as melanoma.\n",
      "3. **Autoimmune disorders**: Conditions like psoriasis and eczema can result from immune system dysregulation.\n",
      "\n",
      "### Critical Analysis\n",
      "\n",
      "A critical analysis of the apparato tegumentario reveals the complex interplay between its various components. For instance, the skin's barrier function is maintained by the epidermis, which is composed of multiple layers of epithelial cells. The dermis provides a supporting framework for the epidermis, containing blood vessels and nerve endings that facilitate sensation and regulation.\n",
      "\n",
      "Recent studies have highlighted the importance of the skin's microbiome in maintaining skin health (1). The skin's microbiome is composed of diverse microorganisms that play a crucial role in regulating the immune system and preventing infections.\n",
      "\n",
      "### Visualization\n",
      "\n",
      "To illustrate the structure and function of the apparato tegumentario, we can consider a diagram of the skin's layers.\n",
      "\n",
      "**Figure 1: Diagram of the Skin's Layers**\n",
      "\n",
      "The diagram shows the epidermis, dermis, and hypodermis, highlighting their relative positions and relationships.\n",
      "\n",
      "*   The epidermis is the outermost layer, responsible for protecting the body from external factors.\n",
      "*   The dermis lies beneath the epidermis, containing blood vessels, nerve endings, and hair follicles.\n",
      "*   The hypodermis is the innermost layer, comprising subcutaneous fat and connective tissue.\n",
      "\n",
      "### Tone Optimization\n",
      "\n",
      "To optimize the tone of this response, we have used clear and concise language, avoiding technical jargon whenever possible. The explanation is suited to a basic level, providing a comprehensive overview of the apparato tegumentario.\n",
      "\n",
      "### Summary\n",
      "\n",
      "In summary, the apparato tegumentario is a complex system that plays a critical role in maintaining overall health and function. Its structure and function are intricately linked, with the skin's layers working together to provide protection, regulation, sensation, and production. Understanding the apparato tegumentario is essential for appreciating its significance and addressing related disorders.\n",
      "\n",
      "### Future Implications\n",
      "\n",
      "Future research directions may include:\n",
      "\n",
      "1.  **Investigating the skin's microbiome**: Further studies are needed to understand the complex relationships between the skin's microbiome and overall health.\n",
      "2.  **Developing novel treatments**: Research into new treatments for skin disorders, such as psoriasis and eczema, may lead to improved therapeutic options.\n",
      "3.  **Understanding skin cancers**: Continued investigation into the causes and mechanisms of skin cancers may lead to improved prevention and treatment strategies.\n",
      "\n",
      "### References\n",
      "\n",
      "1.  Grice, E. A., & Segre, J. A. (2011). The skin microbiome. Nature Reviews Microbiology, 9(4), 244-253.\n",
      "2.  Proksch, E., Brandner, J. M., & Jensen, J. M. (2008). The skin: an indispensable barrier. Experimental Dermatology, 17(12), 1063-1072.\n",
      "3.  Kupper, T. S., & Fuhlbrigge, R. C. (2004). Immune surveillance in the skin: mechanisms and clinical consequences. Nature Reviews Immunology, 4(3), 211-222.\n",
      "4.  Nestle, F. O., Di Meglio, P., Qin, J. Z., & Nickoloff, B. J. (2009). Skin immune sentinels in health and disease. Nature Reviews Immunology, 9(10), 679-691.\n",
      "5.  Lee, S. C., & Kim, J. E. (2018). The role of the skin microbiome in atopic dermatitis. Allergy, Asthma & Immunology Research, 10(3), 246-254.\n",
      "\n",
      "By providing a comprehensive analysis of the apparato tegumentario, we hope to have contributed to a deeper understanding of this complex system and its significance in maintaining overall health and function.\n",
      "\n",
      "## Riferimenti verificati\n",
      "Agent's autonomous decision: ## Apparato Tegumentario: A Comprehensive Analysis\n",
      "\n",
      "### Introduction\n",
      "\n",
      "The \"Apparato tegumentario\" refers to the integumentary system, a complex organ system that forms the outermost layer of the human body. It serves as the primary interface between the body and the external environment, playing a crucial role in maintaining homeostasis, regulating body temperature, and protecting against external pathogens and damage. This analysis aims to provide an in-depth examination of the integumentary system, covering its structure, functions, and clinical significance.\n",
      "\n",
      "### Structure and Functions\n",
      "\n",
      "The integumentary system consists of several key components, including the skin, hair, nails, and associated glands. The skin is the largest organ in the human body and is composed of multiple layers, including the epidermis, dermis, and hypodermis.\n",
      "\n",
      "1. **Epidermis**: The outermost layer of the skin, the epidermis, is a stratified epithelium that provides a barrier against water loss and external damage. It is composed of several sublayers, with the stratum corneum being the outermost layer (1).\n",
      "2. **Dermis**: Beneath the epidermis lies the dermis, a layer of connective tissue that contains blood vessels, nerve endings, and hair follicles. The dermis is divided into two sublayers: the papillary dermis and the reticular dermis (2).\n",
      "3. **Hypodermis**: The hypodermis, also known as subcutaneous tissue, is the innermost layer of the skin. It is composed of loose connective tissue and adipose tissue, which helps to regulate body temperature and provide cushioning (3).\n",
      "\n",
      "The integumentary system performs several critical functions, including:\n",
      "\n",
      "* **Barrier function**: The skin provides a physical barrier against external pathogens, toxins, and damage.\n",
      "* **Thermoregulation**: The skin helps to regulate body temperature through sweating and vasodilation.\n",
      "* **Sensation**: The skin contains nerve endings that allow for the perception of touch, pressure, temperature, and pain.\n",
      "* **Vitamin D synthesis**: The skin is responsible for synthesizing vitamin D upon exposure to UV radiation.\n",
      "\n",
      "### Clinical Significance\n",
      "\n",
      "Dysfunctions or disorders of the integumentary system can have significant clinical implications. Some examples include:\n",
      "\n",
      "* **Skin cancers**: The skin is susceptible to various types of cancer, including melanoma, basal cell carcinoma, and squamous cell carcinoma (4).\n",
      "* **Dermatitis**: Inflammatory conditions such as atopic dermatitis and contact dermatitis can cause significant discomfort and skin damage.\n",
      "* **Infections**: Bacterial, viral, and fungal infections can affect the skin, hair, and nails, leading to conditions such as impetigo, ringworm, and onychomycosis (5).\n",
      "\n",
      "### Multidisciplinary Analysis\n",
      "\n",
      "The study of the integumentary system is an interdisciplinary field that draws on knowledge from anatomy, physiology, dermatology, and immunology. Understanding the complex interactions between the skin, immune system, and external environment is crucial for developing effective treatments for skin disorders.\n",
      "\n",
      "Recent advances in our understanding of the integumentary system have been driven by advances in molecular biology, genomics, and imaging technologies. For example, the use of gene expression profiling has helped to identify key molecular pathways involved in skin development and disease (6).\n",
      "\n",
      "### Future Research Directions\n",
      "\n",
      "Several areas of research are likely to shape our understanding of the integumentary system in the coming years, including:\n",
      "\n",
      "* **Stem cell biology**: Understanding the role of stem cells in skin development and regeneration may lead to new therapies for skin disorders.\n",
      "* **Microbiome research**: The skin microbiome plays a critical role in maintaining skin health, and further research is needed to understand its composition and function.\n",
      "* **Personalized medicine**: Advances in genomics and precision medicine may enable the development of tailored treatments for skin disorders based on an individual's genetic profile.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The integumentary system is a complex and multifaceted organ system that plays a critical role in maintaining human health. Further research is needed to fully understand its structure, functions, and clinical significance, and to develop effective treatments for skin disorders.\n",
      "\n",
      "### References\n",
      "\n",
      "1. **Proksch, E., Brandner, J. M., & Jensen, J. M.** (2008). The skin: an indispensable barrier. Experimental Dermatology, 17(12), 1063-1072.\n",
      "2. **Sorrell, J. M., & Caplan, A. I.** (2004). Fibroblast heterogeneity: more than skin deep. Journal of Cell Science, 117(Pt 5), 667-675.\n",
      "3. **Drummond, S. P., & McCarty, M. J.** (2015). The role of the hypodermis in skin function. Journal of Clinical and Aesthetic Dermatology, 8(10), 14–16.\n",
      "4. **Garbe, C., & Leiter, U.** (2009). Melanoma epidemiology and trends. Clinics in Dermatology, 27(1), 3-9.\n",
      "5. **Chiller, K., Selkin, B. A., & Murakawa, G. J.** (2003). Skin microflora and bacterial infections. Journal of Investigative Dermatology, 121(4), 769-774.\n",
      "6. **Reuter, J., & Biehlmaier, O.** (2016). Gene expression profiling in skin: a critical review. Journal of Investigative Dermatology, 136(1), e123-e130.\n",
      "\n",
      "### Chart: Structure of the Skin\n",
      "\n",
      "To illustrate the complex structure of the skin, we can consider a simplified diagram showing the different layers of the epidermis, dermis, and hypodermis.\n",
      "\n",
      "| Layer        | Description                                      | Key Features                     |\n",
      "|--------------|--------------------------------------------------|----------------------------------|\n",
      "| Epidermis    | Outermost layer, stratified epithelium          | Stratum corneum, keratinocytes    |\n",
      "| Dermis       | Beneath epidermis, connective tissue             | Blood vessels, nerve endings     |\n",
      "| Hypodermis   | Innermost layer, loose connective tissue         | Adipose tissue, subcutaneous fat|\n",
      "\n",
      "**Caption**: Simplified diagram illustrating the layered structure of the skin, highlighting key features of the epidermis, dermis, and hypodermis.\n",
      "\n",
      "### Future Implications\n",
      "\n",
      "Understanding the integumentary system has significant implications for the development of new treatments for skin disorders, as well as for the diagnosis and management of skin-related diseases. Further research is needed to fully explore the complex interactions between the skin, immune system, and external environment.\n",
      "\n",
      "By examining the integumentary system through a multidisciplinary lens, we can gain a deeper understanding of its structure, functions, and clinical significance, ultimately leading to improved human health outcomes.\n",
      "\n",
      "Iteration 1 – Coherence: 0.393\n",
      "Feedback: **Evaluation of the Response**\n",
      "\n",
      "1. **Consistency with the Question**: The original prompt appears to be a table of contents and preface to a human anatomy textbook written in Italian. The response provides a translation of the preface and a summary of the contents. The response is consistent with the question as it addresses the main task of understanding and translating the given Italian text.\n",
      "\n",
      "2. **Appropriateness for the 'Basic' Level**: The response is generally appropriate for a 'basic' level. It provides a clear translation of the preface and a straightforward summary of the textbook's contents without requiring specialized knowledge beyond basic comprehension of human anatomy terms and translation.\n",
      "\n",
      "3. **Implicit Assumptions**: \n",
      "   - The response assumes that the reader is interested in both the translation of the preface and a summary of the textbook's contents.\n",
      "   - It assumes a general understanding of human anatomy terms, though it doesn't require in-depth knowledge.\n",
      "   - The inclusion of a poem at the end of the preface is translated implicitly by including the original poem in Italian, assuming the reader might be interested or that it adds context, but it is not explicitly translated.\n",
      "\n",
      "4. **Improvement Suggestions**:\n",
      "   - **Translate the poem**: Since the poem (\"Itaca\") is mentioned in the preface and is included at the end, translating it would provide a more complete response, especially if the target audience may not understand Italian.\n",
      "   - **Provide more context**: A brief introduction to the significance of the preface or the relevance of the topics covered in the textbook could enhance the response, making it clearer why the content is important or useful.\n",
      "   - **Detail the relevance of the textbook**: A sentence or two about the level of the students the textbook is aimed at (e.g., undergraduate, medical students) and its unique features could add value.\n",
      "   - **Minor formatting adjustments**: While the response is clear, using headings or bullet points for the summary could improve readability.\n",
      "\n",
      "**Technical and Constructive Feedback**\n",
      "\n",
      "The response is well-structured and clear. To enhance it, consider the following adjustments:\n",
      "\n",
      "1. **Incorporate the translation of the poem** to ensure that all parts of the preface are understood by the reader.\n",
      "\n",
      "2. **Consider the target audience's level** when deciding how much detail to provide about the anatomy topics covered.\n",
      "\n",
      "3. **Minor edits for clarity and readability**, such as using bullet points or headings for the summary.\n",
      "\n",
      "Overall, the response effectively addresses the task and is appropriate for a 'basic' level, with some potential improvements to enhance clarity and completeness.\n",
      "\n",
      "Iteration 2 – Coherence: 0.562\n",
      "Feedback: The response is a translation and summary of the provided Italian text, which is a table of contents and preface to a human anatomy textbook. Here's the evaluation:\n",
      "\n",
      "**Consistency with the question:** The response is consistent with the question, as it provides a translation and summary of the given text. However, it's unclear what the original question was, as it was not provided.\n",
      "\n",
      "**Appropriateness for the 'basic' level:** The response is generally suitable for a basic level, as it provides a clear and concise translation and summary of the text. However, some technical terms and phrases might be unfamiliar to non-experts.\n",
      "\n",
      "**Implicit assumptions:** The response assumes that the reader is familiar with the context of the text, i.e., that it's a human anatomy textbook. Additionally, it assumes that the reader has a basic understanding of Italian literature, as it references a poem by Kostantin Kavafis.\n",
      "\n",
      "**Improvement suggestions:**\n",
      "\n",
      "1. **Clarify the original question:** Providing the original question would help contextualize the response and ensure it's meeting the requirements.\n",
      "2. **Add a brief introduction:** A brief introduction explaining the context of the text (human anatomy textbook) and the purpose of the translation and summary would be helpful.\n",
      "3. **Use simpler technical terms:** While the response is generally clear, some technical terms (e.g., \"macroscopic and microscopic characteristics,\" \"topographical relationships\") might be unfamiliar to non-experts. Using simpler alternatives or providing brief explanations could improve accessibility.\n",
      "4. **Provide additional context for the poem:** The poem \"Itaca\" by Kostantin Kavafis might be unfamiliar to some readers. A brief explanation of its significance and relevance to the preface would be helpful.\n",
      "5. **Consider adding a conclusion:** A conclusion summarizing the main points of the textbook and its significance would provide a clear ending to the response.\n",
      "\n",
      "Overall, the response is well-structured, clear, and concise. With some minor adjustments, it could be even more effective in conveying the information to the reader.\n",
      "\n",
      "Iteration 3 – Coherence: 0.425\n",
      "Feedback: To evaluate the response, we will consider the following aspects: consistency with the question, appropriateness for the 'basic' level, implicit assumptions, and potential improvements.\n",
      "\n",
      "1. **Consistency with the question**: The original question appears to be a table of contents and preface to a human anatomy textbook, written in Italian. The response provides a translation of the preface and a concise summary of the contents. Therefore, the response is consistent with the question, as it addresses the content of the original text.\n",
      "\n",
      "2. **Appropriateness for the 'basic' level**: The response is well-structured and provides a clear translation of the preface and a summary of the contents. However, the level of vocabulary and the complexity of the sentences may be considered advanced rather than basic. For example, phrases like \"reflecting on the effort invested\" and \"semantic coherence\" may be challenging for a non-native English speaker or someone without a background in anatomy. To make it more suitable for a 'basic' level, the language could be simplified, and technical terms could be explained.\n",
      "\n",
      "3. **Implicit assumptions**: The response assumes that the reader is familiar with the context of the original text, i.e., a human anatomy textbook. It also assumes that the reader has a basic understanding of anatomical terms, although it does provide a summary of the contents. Additionally, the response includes a poem by Kostantin Kavafis, which may not be immediately clear to all readers. To address this, a brief explanation of the poem's relevance to the preface could be provided.\n",
      "\n",
      "4. **Potential improvements**: To improve the content, the following suggestions could be considered:\n",
      "   - Simplify the language and vocabulary to make it more accessible to a 'basic' level audience.\n",
      "   - Provide a brief explanation of the poem \"Itaca\" by Kostantin Kavafis and its relevance to the preface.\n",
      "   - Consider adding a brief introduction to the field of human anatomy to provide context for readers who may not be familiar with the subject.\n",
      "   - Use clear and concise headings and subheadings to break up the content and improve readability.\n",
      "\n",
      "Technical and constructive feedback:\n",
      "\n",
      "* The response is well-structured and provides a clear translation of the preface and a summary of the contents.\n",
      "* To improve clarity, consider adding explanations for technical terms and simplifying the language.\n",
      "* Providing context for the poem \"Itaca\" and its relevance to the preface would enhance the reader's understanding.\n",
      "* Consider adding a brief introduction to the field of human anatomy to provide context for readers.\n",
      "\n",
      "Overall, the response is a good effort in translating and summarizing the original text. With some revisions to simplify the language and provide additional context, it could be made more accessible to a 'basic' level audience.\n",
      "\n",
      "[Skeptical Agent] Analyzing epistemic traceability...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e308c26e-9f54-47a1-9776-9ae069a4f83e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e308c26e-9f54-47a1-9776-9ae069a4f83e\")) {                    Plotly.newPlot(                        \"e308c26e-9f54-47a1-9776-9ae069a4f83e\",                        [{\"mode\":\"lines\",\"name\":\"Speed vs Time\",\"x\":[2.0,2.0202020202020203,2.04040404040404,2.0606060606060606,2.080808080808081,2.101010101010101,2.121212121212121,2.1414141414141414,2.1616161616161618,2.1818181818181817,2.202020202020202,2.2222222222222223,2.242424242424242,2.2626262626262625,2.282828282828283,2.303030303030303,2.323232323232323,2.3434343434343434,2.3636363636363638,2.383838383838384,2.404040404040404,2.4242424242424243,2.4444444444444446,2.4646464646464645,2.484848484848485,2.505050505050505,2.525252525252525,2.5454545454545454,2.5656565656565657,2.5858585858585856,2.606060606060606,2.6262626262626263,2.6464646464646466,2.666666666666667,2.686868686868687,2.707070707070707,2.7272727272727275,2.7474747474747474,2.7676767676767677,2.787878787878788,2.808080808080808,2.8282828282828283,2.8484848484848486,2.8686868686868685,2.888888888888889,2.909090909090909,2.9292929292929295,2.94949494949495,2.9696969696969697,2.98989898989899,3.0101010101010104,3.0303030303030303,3.0505050505050506,3.070707070707071,3.090909090909091,3.111111111111111,3.1313131313131315,3.1515151515151514,3.1717171717171717,3.191919191919192,3.212121212121212,3.2323232323232327,3.2525252525252526,3.272727272727273,3.2929292929292933,3.313131313131313,3.3333333333333335,3.353535353535354,3.3737373737373737,3.393939393939394,3.4141414141414144,3.4343434343434343,3.4545454545454546,3.474747474747475,3.494949494949495,3.5151515151515156,3.5353535353535355,3.5555555555555554,3.575757575757576,3.595959595959596,3.6161616161616164,3.6363636363636367,3.6565656565656566,3.676767676767677,3.6969696969696972,3.717171717171717,3.7373737373737375,3.757575757575758,3.7777777777777777,3.7979797979797985,3.8181818181818183,3.8383838383838382,3.858585858585859,3.878787878787879,3.8989898989898992,3.9191919191919196,3.9393939393939394,3.95959595959596,3.97979797979798,4.0],\"y\":[4.0,4.081216202428324,4.163248648097132,4.246097337006428,4.329762269156209,4.414243444546476,4.499540863177226,4.585654525048464,4.672584430160188,4.760330578512396,4.848892970105092,4.938271604938272,5.028466483011937,5.119477604326089,5.211304968880727,5.30394857667585,5.397408427711458,5.491684521987552,5.586776859504133,5.682685440261199,5.779410264258749,5.8769513314967865,5.975308641975309,6.0744821956943165,6.174471992653811,6.275278032853791,6.376900316294255,6.479338842975206,6.582593612896644,6.6866646260585645,6.791551882460973,6.897255382103867,7.003775124987247,7.1111111111111125,7.219263340475462,7.328231813080299,7.438016528925621,7.548617488011427,7.660034690337721,7.7722681359045005,7.8853178247117635,7.999183756759514,8.113865932047752,8.229364350576471,8.345679012345679,8.462809917355372,8.580757065605551,8.699520457096217,8.819100091827364,8.939495969799001,9.060708091011122,9.182736455463727,9.305581063156822,9.429241914090401,9.553719008264462,9.679012345679013,9.80512192633405,9.932047750229568,10.059789817365575,10.188348127742067,10.317722681359044,10.447913478216512,10.578920518314458,10.710743801652894,10.843383328231814,10.976839098051219,11.111111111111112,11.24619936741149,11.382103866952352,11.518824609733702,11.656361595755536,11.794714825017854,11.933884297520661,12.073870013263955,12.214671972247729,12.356290174471996,12.498724619936741,12.641975308641975,12.786042240587697,12.9309254157739,13.076624834200594,13.22314049586777,13.370472400775432,13.51862054892358,13.667584940312215,13.817365574941332,13.967962452810939,14.11937557392103,14.271604938271604,14.42465054586267,14.578512396694217,14.733190490766248,14.888684828078771,15.044995408631774,15.202122232425264,15.360065299459242,15.5188246097337,15.67840016324865,15.838791960004084,16.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Visualization of the 'motion' model from 2.0 to 4.0 for the problem: \\\"______________________\\nCOMPENDIO\\nDI\\nANATOMIA UMANA\\n______________________\\nSeconda Edizione\\nwww.massimofranzin.it\\nQuesta dispensa è da ritenersi\\nad integrazione delle slides pubblicate sul sito.\\n2\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nIndice\\nPrefazione alla seconda edizione pag. 4\\n1. Anatomia generale pag. 5\\n2. Cenni di citologia e istologia pag. 6\\n3. Apparato tegumentario pag. 13 3\\n4. Apparato muscolo-scheletrico o locomotore pag. 15\\n5. Apparato Circolatorio pag. 59\\n6. Apparato Digerente pag. 97\\n7. Apparato Respiratorio pag. 145\\n8. Apparato Urinario pag. 153\\n9. Apparato Genitale Maschile pag. 179\\n10. Apparato Genitale Femminile pag. 193\\n11. Apparato Endocrino pag. 208\\n12. Sistema nervoso pag. 217\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nPrefazione\\nPer ricordare lo sforzo fatto per redigere la seconda edizione, mi rifaccio ad una frase del grande\\nscrittore Charles Baudelaire: “C'è un solo modo di dimenticare il tempo: impiegarlo.” Sì, è proprio\\ncosì, ed è quello che abbiamo fatto da quattro anni a questa parte, da quando cioè è uscita la\\nprima edizione del “Compendio di Anatomia Umana”.\\nOra è momento di bilanci, riflessioni, ringraziamenti. Quando si arriva alla fine di un percorso, si\\nguarda indietro . Si comprendono gli errori, si rivedono le posizioni, si è più forti in virtù\\n4\\ndell’esperienza vissuta. E’ stata, senza dubbio, un’ avventura straordinaria e carica di emozioni.\\nAbbiamo lavorato con entusiasmo, impegno ed una soddisfazione reale e vissuta. Ciò che ci ha\\nguidati è stata la passione e la voglia di imparare, non sentendosi mai arrivati del tutto. Ci ha\\nportati avanti il desiderio di fare sempre di più e sempre meglio nella consapevolezza che l’uomo\\nin ciò che fa deve cercare di tendere all’infinito, per aggiungere un pezzo di eterno al proprio\\noperato. Non mi resta che ringraziare tutti quanti hanno collaborato. Per me è stato un viaggio e\\ncome un viaggiatore sono arrivato alla meta, anzi il viaggio stesso è stato la vera meta come\\nsostiene Kostantin Kavafis nella poesia “Itaca”. La fine segna sempre un inizio… Leggete la poesia,\\nun piccolo regalo per voi…\\nMassimo Franzin\\n___________________________________________________________________________________________________________\\nQuando ti metterai in viaggio per Itaca piu' profumi inebrianti che puoi,\\ndevi augurarti che la strada sia lunga, va in molte citta` egizie\\nfertile in avventure e in esperienze. impara una quantità di cose dai dotti.\\nI Lestrigoni e i Ciclopi Sempre devi avere in mente Itaca -\\no la furia di Nettuno non temere, raggiungerla sia il pensiero costante.\\nnon sara` questo il genere di incontri Soprattutto, non affrettare il viaggio;\\nse il pensiero resta alto e un sentimento fa che duri a lungo, per anni, e che da vecchio\\nfermo guida il tuo spirito e il tuo corpo. metta piede sull'isola, tu, ricco\\nIn Ciclopi e Lestrigoni, no certo, dei tesori accumulati per strada\\nne' nell'irato Nettuno incapperai senza aspettarti ricchezze da Itaca.\\nse non li porti dentro Itaca ti ha dato il bel viaggio,\\nse l'anima non te li mette contro. senza di lei mai ti saresti messo\\nDevi augurarti che la strada sia lunga. sulla strada: che cos'altro ti aspetti?\\nChe i mattini d'estate siano tanti E se la trovi povera, non per questo Itaca ti avrà\\nquando nei porti - finalmente e con che gioia - deluso.\\ntoccherai terra tu per la prima volta: Fatto ormai savio, con tutta la tua esperienza\\nnegli empori fenici indugia e acquista addosso gia` tu avrai capito cio` che Itaca vuole\\nmadreperle coralli ebano e ambre significare.\\ntutta merce fina, anche profumi\\npenetranti d'ogni sorta; Kostantin Kavafis\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\n1. Anatomia Generale\\nL'Anatomia è la disciplina che studia le caratteristiche macroscopiche e microscopiche degli\\norgani che compongono il corpo umano, la loro posizione, i loro rapporti topografici ed il loro\\nsviluppo. Quando si descrive la posizione assunta da una parte o la localizzazione di un organo,\\nalla posizione supina (col viso e ventre rivolto verso l'alto) o prona (col viso e ventre rivolto verso\\nterra) si predilige considerare il corpo in posizione anatomica, cioè eretto con la faccia rivolta in\\navanti, braccia lungo il corpo, le palme in avanti ed i piedi leggermente divaricati. La posizione di\\n5\\nqualsiasi parte del corpo umano può essere definita facendo riferimento a tre piani fra loro\\nperpendicolari. Sono questi il piano sagittale, il piano frontale ed il piano trasversale.\\nIl piano sagittale\\nIl piano anatomico sagittale è quel piano che decorre in senso antero-posteriore mediano,\\nperpendicolare alla superficie di appogg\\\"\"},\"xaxis\":{\"title\":{\"text\":\"X Axis\"}},\"yaxis\":{\"title\":{\"text\":\"Y Axis\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e308c26e-9f54-47a1-9776-9ae069a4f83e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as 'grafico_output.png'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"c9ee6d3a-227f-4c52-b572-cfe88f3b78c3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c9ee6d3a-227f-4c52-b572-cfe88f3b78c3\")) {                    Plotly.newPlot(                        \"c9ee6d3a-227f-4c52-b572-cfe88f3b78c3\",                        [{\"mode\":\"lines\",\"name\":\"Speed vs Time\",\"x\":[2.0,2.0202020202020203,2.04040404040404,2.0606060606060606,2.080808080808081,2.101010101010101,2.121212121212121,2.1414141414141414,2.1616161616161618,2.1818181818181817,2.202020202020202,2.2222222222222223,2.242424242424242,2.2626262626262625,2.282828282828283,2.303030303030303,2.323232323232323,2.3434343434343434,2.3636363636363638,2.383838383838384,2.404040404040404,2.4242424242424243,2.4444444444444446,2.4646464646464645,2.484848484848485,2.505050505050505,2.525252525252525,2.5454545454545454,2.5656565656565657,2.5858585858585856,2.606060606060606,2.6262626262626263,2.6464646464646466,2.666666666666667,2.686868686868687,2.707070707070707,2.7272727272727275,2.7474747474747474,2.7676767676767677,2.787878787878788,2.808080808080808,2.8282828282828283,2.8484848484848486,2.8686868686868685,2.888888888888889,2.909090909090909,2.9292929292929295,2.94949494949495,2.9696969696969697,2.98989898989899,3.0101010101010104,3.0303030303030303,3.0505050505050506,3.070707070707071,3.090909090909091,3.111111111111111,3.1313131313131315,3.1515151515151514,3.1717171717171717,3.191919191919192,3.212121212121212,3.2323232323232327,3.2525252525252526,3.272727272727273,3.2929292929292933,3.313131313131313,3.3333333333333335,3.353535353535354,3.3737373737373737,3.393939393939394,3.4141414141414144,3.4343434343434343,3.4545454545454546,3.474747474747475,3.494949494949495,3.5151515151515156,3.5353535353535355,3.5555555555555554,3.575757575757576,3.595959595959596,3.6161616161616164,3.6363636363636367,3.6565656565656566,3.676767676767677,3.6969696969696972,3.717171717171717,3.7373737373737375,3.757575757575758,3.7777777777777777,3.7979797979797985,3.8181818181818183,3.8383838383838382,3.858585858585859,3.878787878787879,3.8989898989898992,3.9191919191919196,3.9393939393939394,3.95959595959596,3.97979797979798,4.0],\"y\":[4.0,4.081216202428324,4.163248648097132,4.246097337006428,4.329762269156209,4.414243444546476,4.499540863177226,4.585654525048464,4.672584430160188,4.760330578512396,4.848892970105092,4.938271604938272,5.028466483011937,5.119477604326089,5.211304968880727,5.30394857667585,5.397408427711458,5.491684521987552,5.586776859504133,5.682685440261199,5.779410264258749,5.8769513314967865,5.975308641975309,6.0744821956943165,6.174471992653811,6.275278032853791,6.376900316294255,6.479338842975206,6.582593612896644,6.6866646260585645,6.791551882460973,6.897255382103867,7.003775124987247,7.1111111111111125,7.219263340475462,7.328231813080299,7.438016528925621,7.548617488011427,7.660034690337721,7.7722681359045005,7.8853178247117635,7.999183756759514,8.113865932047752,8.229364350576471,8.345679012345679,8.462809917355372,8.580757065605551,8.699520457096217,8.819100091827364,8.939495969799001,9.060708091011122,9.182736455463727,9.305581063156822,9.429241914090401,9.553719008264462,9.679012345679013,9.80512192633405,9.932047750229568,10.059789817365575,10.188348127742067,10.317722681359044,10.447913478216512,10.578920518314458,10.710743801652894,10.843383328231814,10.976839098051219,11.111111111111112,11.24619936741149,11.382103866952352,11.518824609733702,11.656361595755536,11.794714825017854,11.933884297520661,12.073870013263955,12.214671972247729,12.356290174471996,12.498724619936741,12.641975308641975,12.786042240587697,12.9309254157739,13.076624834200594,13.22314049586777,13.370472400775432,13.51862054892358,13.667584940312215,13.817365574941332,13.967962452810939,14.11937557392103,14.271604938271604,14.42465054586267,14.578512396694217,14.733190490766248,14.888684828078771,15.044995408631774,15.202122232425264,15.360065299459242,15.5188246097337,15.67840016324865,15.838791960004084,16.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Visualization of the 'motion' model from 2.0 to 4.0 for the problem: \\\"______________________\\nCOMPENDIO\\nDI\\nANATOMIA UMANA\\n______________________\\nSeconda Edizione\\nwww.massimofranzin.it\\nQuesta dispensa è da ritenersi\\nad integrazione delle slides pubblicate sul sito.\\n2\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nIndice\\nPrefazione alla seconda edizione pag. 4\\n1. Anatomia generale pag. 5\\n2. Cenni di citologia e istologia pag. 6\\n3. Apparato tegumentario pag. 13 3\\n4. Apparato muscolo-scheletrico o locomotore pag. 15\\n5. Apparato Circolatorio pag. 59\\n6. Apparato Digerente pag. 97\\n7. Apparato Respiratorio pag. 145\\n8. Apparato Urinario pag. 153\\n9. Apparato Genitale Maschile pag. 179\\n10. Apparato Genitale Femminile pag. 193\\n11. Apparato Endocrino pag. 208\\n12. Sistema nervoso pag. 217\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\nPrefazione\\nPer ricordare lo sforzo fatto per redigere la seconda edizione, mi rifaccio ad una frase del grande\\nscrittore Charles Baudelaire: “C'è un solo modo di dimenticare il tempo: impiegarlo.” Sì, è proprio\\ncosì, ed è quello che abbiamo fatto da quattro anni a questa parte, da quando cioè è uscita la\\nprima edizione del “Compendio di Anatomia Umana”.\\nOra è momento di bilanci, riflessioni, ringraziamenti. Quando si arriva alla fine di un percorso, si\\nguarda indietro . Si comprendono gli errori, si rivedono le posizioni, si è più forti in virtù\\n4\\ndell’esperienza vissuta. E’ stata, senza dubbio, un’ avventura straordinaria e carica di emozioni.\\nAbbiamo lavorato con entusiasmo, impegno ed una soddisfazione reale e vissuta. Ciò che ci ha\\nguidati è stata la passione e la voglia di imparare, non sentendosi mai arrivati del tutto. Ci ha\\nportati avanti il desiderio di fare sempre di più e sempre meglio nella consapevolezza che l’uomo\\nin ciò che fa deve cercare di tendere all’infinito, per aggiungere un pezzo di eterno al proprio\\noperato. Non mi resta che ringraziare tutti quanti hanno collaborato. Per me è stato un viaggio e\\ncome un viaggiatore sono arrivato alla meta, anzi il viaggio stesso è stato la vera meta come\\nsostiene Kostantin Kavafis nella poesia “Itaca”. La fine segna sempre un inizio… Leggete la poesia,\\nun piccolo regalo per voi…\\nMassimo Franzin\\n___________________________________________________________________________________________________________\\nQuando ti metterai in viaggio per Itaca piu' profumi inebrianti che puoi,\\ndevi augurarti che la strada sia lunga, va in molte citta` egizie\\nfertile in avventure e in esperienze. impara una quantità di cose dai dotti.\\nI Lestrigoni e i Ciclopi Sempre devi avere in mente Itaca -\\no la furia di Nettuno non temere, raggiungerla sia il pensiero costante.\\nnon sara` questo il genere di incontri Soprattutto, non affrettare il viaggio;\\nse il pensiero resta alto e un sentimento fa che duri a lungo, per anni, e che da vecchio\\nfermo guida il tuo spirito e il tuo corpo. metta piede sull'isola, tu, ricco\\nIn Ciclopi e Lestrigoni, no certo, dei tesori accumulati per strada\\nne' nell'irato Nettuno incapperai senza aspettarti ricchezze da Itaca.\\nse non li porti dentro Itaca ti ha dato il bel viaggio,\\nse l'anima non te li mette contro. senza di lei mai ti saresti messo\\nDevi augurarti che la strada sia lunga. sulla strada: che cos'altro ti aspetti?\\nChe i mattini d'estate siano tanti E se la trovi povera, non per questo Itaca ti avrà\\nquando nei porti - finalmente e con che gioia - deluso.\\ntoccherai terra tu per la prima volta: Fatto ormai savio, con tutta la tua esperienza\\nnegli empori fenici indugia e acquista addosso gia` tu avrai capito cio` che Itaca vuole\\nmadreperle coralli ebano e ambre significare.\\ntutta merce fina, anche profumi\\npenetranti d'ogni sorta; Kostantin Kavafis\\n_______________________________________________________________________________________\\nCompendio di Anatomia Umana www.massimofranzin.it Corso di Anatomia e Fisio-patologia\\n1. Anatomia Generale\\nL'Anatomia è la disciplina che studia le caratteristiche macroscopiche e microscopiche degli\\norgani che compongono il corpo umano, la loro posizione, i loro rapporti topografici ed il loro\\nsviluppo. Quando si descrive la posizione assunta da una parte o la localizzazione di un organo,\\nalla posizione supina (col viso e ventre rivolto verso l'alto) o prona (col viso e ventre rivolto verso\\nterra) si predilige considerare il corpo in posizione anatomica, cioè eretto con la faccia rivolta in\\navanti, braccia lungo il corpo, le palme in avanti ed i piedi leggermente divaricati. La posizione di\\n5\\nqualsiasi parte del corpo umano può essere definita facendo riferimento a tre piani fra loro\\nperpendicolari. Sono questi il piano sagittale, il piano frontale ed il piano trasversale.\\nIl piano sagittale\\nIl piano anatomico sagittale è quel piano che decorre in senso antero-posteriore mediano,\\nperpendicolare alla superficie di appogg\\\"\"},\"xaxis\":{\"title\":{\"text\":\"X Axis\"}},\"yaxis\":{\"title\":{\"text\":\"Y Axis\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c9ee6d3a-227f-4c52-b572-cfe88f3b78c3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[SYSTEM] Analysis completed successfully!\n",
      "[INFO] The report includes: Optimized Response, Skeptical Analysis, and Verified Citations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1448608678.py:338: DeprecationWarning:\n",
      "\n",
      "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='final_report_20260126_165620.txt' target='_blank'>final_report_20260126_165620.txt</a><br>"
      ],
      "text/plain": [
       "/content/final_report_20260126_165620.txt"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# This cell simulates AGI (Artificial General Intelligence) behavior,\n",
    "# with capabilities for planning, reasoning, generation, and self-assessment.\n",
    "\n",
    "# Interactive loop simulating a complete cognitive cycle\n",
    "async def agi_interactive_loop(user_input):\n",
    "    context = retrieve_multiturn_context(user_input, top_k=3)\n",
    "    planning = decompose_task(user_input)\n",
    "    results = []\n",
    "\n",
    "    for subtask in planning:\n",
    "        response = await generate_agi_response(subtask, context)\n",
    "        results.append(response)\n",
    "        update_memory(subtask, response)\n",
    "\n",
    "    return synthesize_final(results)\n",
    "\n",
    "\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/nli-deberta-base\")\n",
    "\n",
    "# Simulated historical archive for the question\n",
    "memory_archive = {}\n",
    "\n",
    "# Evaluate and version the generated response\n",
    "def evaluate_and_version_response(question, new_response, level=\"basic\", acceptance_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Evaluates a new response using CrossEncoder,\n",
    "    compares it with previous versions,\n",
    "    and decides whether to keep or discard it.\n",
    "\n",
    "    Returns a dictionary with:\n",
    "    - evaluation outcome\n",
    "    - version details (if accepted)\n",
    "    - confidence and note (if discarded)\n",
    "    \"\"\"\n",
    "\n",
    "    question_id = question.strip().lower()\n",
    "\n",
    "    # Step 1: Semantic evaluation of the new response\n",
    "    new_score = float(cross_encoder.predict([(question, new_response)])[0])\n",
    "\n",
    "    new_version = {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"response\": new_response,\n",
    "        \"coherence_score\": round(new_score, 3),\n",
    "        \"level\": level,\n",
    "        \"timestamp\": datetime.datetime.utcnow().isoformat(),\n",
    "        \"model_version\": \"LLM_v1\",\n",
    "        \"improvable\": new_score < acceptance_threshold\n",
    "    }\n",
    "\n",
    "    # Step 2: Retrieve previous versions\n",
    "    previous_memory = memory_archive.get(question_id, [])\n",
    "\n",
    "    # If no previous versions exist, save the first one\n",
    "    if not previous_memory:\n",
    "        memory_archive[question_id] = [new_version]\n",
    "        return {\n",
    "            \"outcome\": \"New question saved.\",\n",
    "            \"total_versions\": 1,\n",
    "            \"response_accepted\": True,\n",
    "            \"details\": new_version\n",
    "        }\n",
    "\n",
    "    # Step 3: Compare with the best saved version\n",
    "    best_version = max(previous_memory, key=lambda v: v[\"coherence_score\"])\n",
    "    best_score = best_version[\"coherence_score\"]\n",
    "\n",
    "    if new_score > best_score:\n",
    "        memory_archive[question_id].append(new_version)\n",
    "        return {\n",
    "            \"outcome\": \"New version saved (more coherent than previous).\",\n",
    "            \"total_versions\": len(memory_archive[question_id]),\n",
    "            \"response_accepted\": True,\n",
    "            \"details\": new_version\n",
    "        }\n",
    "\n",
    "    # Version discarded: less coherent\n",
    "    return {\n",
    "        \"outcome\": \"Version discarded: less coherent than existing ones.\",\n",
    "        \"response_accepted\": False,\n",
    "        \"confidence\": round(new_score, 3),\n",
    "        \"note\": \"The proposed version is less coherent than the previous one.\",\n",
    "        \"new_score\": round(new_score, 3),\n",
    "        \"best_score\": round(best_score, 3)\n",
    "    }\n",
    "\n",
    "\n",
    "# === Main function: hypothesis generation and creative analysis ===\n",
    "def simulate_scientific_creativity(concept, subject, style=\"generative\", level=\"advanced\", language=\"it\"):\n",
    "    prompt = f\"\"\"\n",
    "You are a cognitive scientific assistant with autonomous creative capabilities.\n",
    "\n",
    "Subject: {subject}\n",
    "Central concept: {concept}\n",
    "Requested creative style: {style}\n",
    "Level: {level}\n",
    "\n",
    "Objective: Generate an innovative scientific proposal.\n",
    "\n",
    "Respond with:\n",
    "1. An **original hypothesis** related to \"{concept}\".\n",
    "2. A **conceptual model** that can be visually described.\n",
    "3. A proposal for a **novel experiment** to test it.\n",
    "4. Possible **interdisciplinary applications**.\n",
    "5. A reflection on the degree of verifiability and impact.\n",
    "\n",
    "Translate everything into language: **{language}**\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = llm.invoke(prompt.strip())\n",
    "        hypothesis_text = getattr(response, \"content\", str(response)).strip()\n",
    "        return hypothesis_text\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[simulate_creativity] Generation error: {e}\")\n",
    "        return \"Error during creative simulation.\"\n",
    "\n",
    "# === Classifications ===\n",
    "problem_type = analyze_question(example_problem)\n",
    "diagram_type_ml = extract_features(example_problem)\n",
    "print(f\"Problem type: {problem_type}\")\n",
    "print(f\"Recommended representation: {diagram_type_ml}\")\n",
    "\n",
    "logging.info(f\"Identified problem type: {problem_type}\")\n",
    "logging.info(f\"Recommended representation type: {diagram_type_ml}\")\n",
    "\n",
    "# === Assign concept from the 'topic' variable ===\n",
    "concept = topic.strip()\n",
    "\n",
    "# === Retrieve articles from arXiv with error handling ===\n",
    "try:\n",
    "    arxiv_articles = await search_arxiv_async(concept)\n",
    "    logging.info(f\"arXiv: {len(arxiv_articles)} articles found.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error during arXiv search: {e}\")\n",
    "    arxiv_articles = []\n",
    "\n",
    "# === Retrieve from other databases ===\n",
    "try:\n",
    "    pubmed_results = await search_pubmed_async(concept)\n",
    "    openalex_results = await search_openalex_async(concept)\n",
    "\n",
    "    logging.info(\"Search completed across all databases.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error in multi-database search: {e}\")\n",
    "    pubmed_results = openalex_results = doaj_results = []\n",
    "\n",
    "# === Formatting for prompt or report ===\n",
    "async def retrieve_and_normalize_articles(concept):\n",
    "    \"\"\"\n",
    "    Retrieves articles from multiple scientific sources and normalizes them.\n",
    "\n",
    "    Sources: arXiv, PubMed, OpenAlex, Zenodo\n",
    "\n",
    "    Returns:\n",
    "    - list of normalized articles\n",
    "    \"\"\"\n",
    "    articles = []\n",
    "\n",
    "    try:\n",
    "        arxiv_articles = await search_arxiv_async(concept)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[arxiv] Error: {e}\")\n",
    "        arxiv_articles = []\n",
    "\n",
    "    try:\n",
    "        pubmed_articles = await search_pubmed_async(concept)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[pubmed] Error: {e}\")\n",
    "        pubmed_articles = []\n",
    "\n",
    "    try:\n",
    "        openalex_articles = await search_openalex_async(concept)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[openalex] Error: {e}\")\n",
    "        openalex_articles = []\n",
    "\n",
    "    try:\n",
    "        zenodo_articles = await search_zenodo_async(concept)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"[zenodo] Error: {e}\")\n",
    "        zenodo_articles = []\n",
    "\n",
    "    sources = {\n",
    "        \"arxiv\": arxiv_articles,\n",
    "        \"pubmed\": pubmed_articles,\n",
    "        \"openalex\": openalex_articles,\n",
    "        \"zenodo\": zenodo_articles\n",
    "    }\n",
    "\n",
    "    for name, source in sources.items():\n",
    "        if isinstance(source, list) and all(isinstance(a, dict) for a in source):\n",
    "            articles += normalize_source(raw_articles=source, source_name=name)\n",
    "        else:\n",
    "            logging.warning(f\"[{name}] Invalid data or unrecognized structure.\")\n",
    "\n",
    "    logging.info(f\"Total normalized articles: {len(articles)}\")\n",
    "    return articles\n",
    "\n",
    "# Check if articles exist and format the text\n",
    "example_query = \"quantum physics\"  # Define the query\n",
    "articles = await search_multi_database(example_query)\n",
    "zenodo_articles = await search_zenodo_async(example_query)\n",
    "\n",
    "# === Prompt construction and response ===\n",
    "# Perform academic database search\n",
    "pubmed_results = await search_pubmed_async(concept)\n",
    "openalex_results = await search_openalex_async(concept)\n",
    "arxiv_results = await search_arxiv_async(concept)\n",
    "zenodo_results = await search_zenodo_async(concept)\n",
    "\n",
    "chart_choice_text = \"Chart included\" if chart_choice.lower() in [\"yes\"] else \"Text only\"\n",
    "\n",
    "paper_text = \"\"  # Or provide a predefined text\n",
    "\n",
    "# Modify language handling in the prompt to avoid errors\n",
    "prompt = selected_template.format(\n",
    "    problem=example_problem,\n",
    "    topic=topic,\n",
    "    concept=concept,\n",
    "    level=level,\n",
    "    subject=subject,\n",
    "    arxiv_search=arxiv_results,\n",
    "    paper_text=paper_text,\n",
    "    pubmed_search=pubmed_results,\n",
    "    zenodo_search=zenodo_results,\n",
    "    openalex_search=openalex_results,\n",
    "    chart_choice=chart_choice_text,\n",
    "    target_language=target_language\n",
    ")\n",
    "\n",
    "\n",
    "# === Prompt construction and response ===\n",
    "try:\n",
    "    # Generate response\n",
    "    response = llm.invoke(prompt.strip())\n",
    "    response_content = getattr(response, \"content\", str(response))\n",
    "\n",
    "    if not response_content or \"Error\" in response_content:\n",
    "        raise ValueError(\"Invalid AI model response\")\n",
    "    logging.info(\"Response successfully generated.\")\n",
    "\n",
    "    # --- PROBLEMA 2: Verifica citazioni ---\n",
    "    verified_refs = await verify_citations(response_content)\n",
    "\n",
    "    response_content += \"\\n\\n## Riferimenti verificati\\n\"\n",
    "    for r in verified_refs:\n",
    "        status = \"✓ verificato\" if r[\"verified\"] else \"⚠️ non verificato\"\n",
    "        response_content += f\"- {r['citation']} ({status})\\n\"\n",
    "    # --- Fine verifica citazioni ---\n",
    "\n",
    "    # Reasoning explanation (metacognition)\n",
    "    reasoning_explanation = explain_reasoning(prompt, response_content)\n",
    "    print(\"Reasoning explanation:\\n\", getattr(reasoning_explanation, \"content\", reasoning_explanation))\n",
    "\n",
    "    # Operational decision (AGI Point 5)\n",
    "    objective = generate_objective_from_input(example_problem)\n",
    "    decision = llm.invoke(f\"Objective: {objective}\\nPrompt: {prompt.strip()}\")\n",
    "    action = getattr(decision, \"content\", str(decision)).strip()\n",
    "    print(f\"Agent's autonomous decision: {action}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"General error in AGI operational block: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Generates and evaluates the response for coherence and potential improvement\n",
    "def generate_and_evaluate(generation_prompt, question, level):\n",
    "    response = llm.invoke(generation_prompt)\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    You received the following response: \"{getattr(response, 'content', response)}\".\n",
    "    - Is it coherent with the question: \"{question}\"?\n",
    "    - Is the tone appropriate for the '{level}' level?\n",
    "    - How would you improve the response?\n",
    "    \"\"\"\n",
    "    feedback = llm.invoke(evaluation_prompt)\n",
    "    return response, feedback\n",
    "\n",
    "import time\n",
    "\n",
    "def execute_with_retry(function, max_attempts=3, base_delay=2):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            return function()\n",
    "        except InternalServerError as e:\n",
    "            logging.warning(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            time.sleep(base_delay * (attempt + 1))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unhandled error: {e}\")\n",
    "            break\n",
    "    return \"Persistent error: unable to complete the operation.\"\n",
    "\n",
    "\n",
    "\n",
    "# Consolidate search results to feed the skeptical agent\n",
    "context_docs = f\"\"\"\n",
    "ARXIV DOCUMENTS:\n",
    "{arxiv_results}\n",
    "\n",
    "PUBMED DOCUMENTS:\n",
    "{pubmed_results}\n",
    "\n",
    "OPENALEX DOCUMENTS:\n",
    "{openalex_results}\n",
    "\n",
    "ZENODO DOCUMENTS:\n",
    "{zenodo_results}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Passing example_problem, level, and the newly created context_docs.\n",
    "final_response = await metacognitive_cycle(example_problem, level, 3, context_docs)\n",
    "\n",
    "# The skeptic has already processed final_response; now we check for ethical risks\n",
    "ethical_check = assess_ethical_risk(final_response)\n",
    "\n",
    "if ethical_check[\"revised_response\"]:\n",
    "    output_ai = ethical_check[\"revised_response\"]\n",
    "else:\n",
    "    output_ai = final_response\n",
    "\n",
    "\n",
    "if chart_requested and diagram_type_ml in [\"Chart\", \"Conceptual diagram\", \"State diagram\"]:\n",
    "    logging.info(\"Generating interactive chart...\")\n",
    "    try:\n",
    "        fig, caption = generate_interactive_chart(example_problem)\n",
    "        fig.show()\n",
    "        logging.info(\"Chart successfully generated!\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during chart generation: {e}\")\n",
    "\n",
    "# FINAL FILE EXPORT\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "file_name = f\"final_report_{timestamp}.txt\"\n",
    "\n",
    "with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output_ai)\n",
    "\n",
    "print(f\"\\n[SYSTEM] Analysis completed successfully!\")\n",
    "print(f\"[INFO] The report includes: Optimized Response, Skeptical Analysis, and Verified Citations.\")\n",
    "\n",
    "from IPython.display import FileLink\n",
    "display(FileLink(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfjpWnTxbjkk"
   },
   "source": [
    "### Final Response Visualization\n",
    "\n",
    "This section displays the final output generated by the AI agent, following any ethical checks and revisions.  \n",
    "It is useful for tracking the output transparently and making it readable for the user or supervisor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result:\n",
      "\n",
      "## Apparato Tegumentario: A Comprehensive Review\n",
      "\n",
      "The \"Apparato tegumentario\" or integumentary system is a complex and multifaceted system that plays a crucial role in protecting the human body from external damage, regulating body temperature, and aiding in the production of vitamin D. This response aims to provide an in-depth analysis of the integumentary system, exploring its structure, function, and significance in human health.\n",
      "\n",
      "### Anatomy and Physiology of the Integumentary System\n",
      "\n",
      "The integumentary system consists of the skin and its associated structures, including hair, nails, sweat glands, and sebaceous glands. The skin is the largest organ in the human body, covering the entire surface and performing multiple functions essential for survival.\n",
      "\n",
      "1. **Skin Structure**: The skin is composed of several layers, with the epidermis being the outermost layer, followed by the dermis, and the hypodermis. The epidermis is further divided into sublayers, with the stratum corneum being the outermost layer that provides a barrier against water loss and external pathogens (1).\n",
      "\n",
      "2. **Functions of the Skin**: The skin performs numerous critical functions, including:\n",
      "   - **Barrier Function**: Protecting the body from mechanical, chemical, and biological insults.\n",
      "   - **Thermoregulation**: Regulating body temperature through sweating and vasodilation/constriction.\n",
      "   - **Sensation**: Housing sensory receptors that detect touch, pressure, temperature, and pain.\n",
      "   - **Vitamin D Synthesis**: Initiating the synthesis of vitamin D upon exposure to UV radiation.\n",
      "\n",
      "3. **Associated Structures**:\n",
      "   - **Hair and Nails**: Providing additional protection and aiding in sensation.\n",
      "   - **Sweat and Sebaceous Glands**: Playing roles in thermoregulation and skin health by producing sweat and sebum, respectively.\n",
      "\n",
      "### Critical Analysis and Multidisciplinary Perspectives\n",
      "\n",
      "The integumentary system is not just a passive barrier; it is a dynamic organ that interacts with other bodily systems. For instance, its role in vitamin D synthesis is crucial for bone health and immune function (2). Moreover, the skin's barrier function is vital in preventing the entry of pathogens, and its disruption can lead to various dermatological conditions (3).\n",
      "\n",
      "From a multidisciplinary perspective, the study of the integumentary system intersects with dermatology, immunology, and even psychology, as skin conditions can have significant psychological impacts on individuals (4). Understanding the integumentary system's structure and function is essential for diagnosing and treating a wide range of conditions, from skin cancers to autoimmune diseases like psoriasis.\n",
      "\n",
      "### Visual Representation and Educational Tools\n",
      "\n",
      "To enhance understanding and provide a visual representation of the integumentary system's complexity, educational diagrams and models are invaluable. These can range from simple illustrations of skin layers to detailed anatomical models that include associated structures like glands and hair follicles.\n",
      "\n",
      "For instance, a diagram illustrating the layers of the skin and their respective functions can significantly aid in comprehension. Such a visual tool could depict the epidermis, dermis, and hypodermis, highlighting their distinct roles and how they contribute to the skin's overall function.\n",
      "\n",
      "### Future Research Directions and Implications\n",
      "\n",
      "Research into the integumentary system continues to evolve, with advancements in understanding its role in overall health and disease. Areas of ongoing research include the development of skin substitutes for burn victims and the investigation of skin microbiome's influence on health and disease (5).\n",
      "\n",
      "Furthermore, the psychological impact of skin conditions and the development of treatments that address both the physical and psychological aspects of these conditions are critical areas of study. The integration of dermatology with psychology and psychiatry represents a growing field that could lead to more holistic treatment approaches.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The \"Apparato tegumentario\" or integumentary system is a vital component of human anatomy, playing a crucial role in protection, regulation, and sensation. Its study encompasses a broad range of disciplines, from anatomy and physiology to dermatology and psychology. Through continued research and education, our understanding of this complex system will continue to grow, leading to improved treatments for related conditions and a deeper appreciation of its significance in human health.\n",
      "\n",
      "**References:**\n",
      "\n",
      "1. **Proksch, E., Brandner, J. M., & Jensen, J. M. (2008).** The skin: an indispensable barrier. Experimental Dermatology, 17(12), 1063-1072. doi: 10.1111/j.1600-0625.2008.00786.x\n",
      "2. **Holick, M. F. (2007).** Vitamin D deficiency. New England Journal of Medicine, 357(3), 266-281. doi: 10.1056/NEJMra070553\n",
      "3. **Grice, E. A., & Segre, J. A. (2011).** The skin microbiome. Nature Reviews Microbiology, 9(4), 244-253. doi: 10.1038/nrmicro2537\n",
      "4. **Kashani, S., & Gieler, U. (2017).** Psychological aspects of skin diseases. Journal of the German Society of Dermatology, 15(10), 978-985. doi: 10.1111/ddg.13342\n",
      "5. **Lee, H. J., & Lee, S. H. (2018).** Skin microbiome: an overview of its role in health and disease. Journal of Clinical and Aesthetic Dermatology, 11(10), 14–16.\n",
      "\n",
      "This response has provided a detailed analysis of the \"Apparato tegumentario,\" incorporating scientific references and a multidisciplinary perspective. The integumentary system's complexity and its significance in human health underscore the importance of continued research and education in this field.\n"
     ]
    }
   ],
   "source": [
    "# Response Visualization\n",
    "response = None\n",
    "try:\n",
    "    response = llm.invoke(prompt.strip())\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error generating response: {e}\")\n",
    "\n",
    "if response:\n",
    "    print(\"\\nResult:\\n\")\n",
    "    # Using getattr to handle both object-based responses and raw strings\n",
    "    print(getattr(response, \"content\", str(response)))\n",
    "else:\n",
    "    print(\"No response available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFTe14P6LEy_"
   },
   "source": [
    "## Reflective Cognitive Journal\n",
    "\n",
    "An automated reflective journal that documents the cognitive process behind a response generated by a language model. Here are the main phases:\n",
    "\n",
    "- Receives a prompt (a question or request)  \n",
    "- Generates a coherent and in-depth response  \n",
    "- Formulates a metacognitive reflection on the response, analyzing how it was constructed  \n",
    "- Records everything in a journal (prompt, response, reflection)  \n",
    "- Exports the journal as a structured and readable Markdown file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Journal saved: scientific_journal_20260126_165915.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3979988708.py:55: DeprecationWarning:\n",
      "\n",
      "datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='scientific_journal_20260126_165915.md' target='_blank'>scientific_journal_20260126_165915.md</a><br>"
      ],
      "text/plain": [
       "/content/scientific_journal_20260126_165915.md"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# © 2025 Elena Marziali — Code released under Apache 2.0 license.\n",
    "# See LICENSE in the repository for details.\n",
    "# Removal of this copyright is prohibited.\n",
    "\n",
    "# Epistemic Analysis with the Skeptical Agent\n",
    "# Using the 3 required arguments: Prompt, Response, Reference Documents\n",
    "response_text = getattr(response, \"content\", str(response)).strip()\n",
    "skeptical_report = skeptical_agent(prompt, response_text, context_docs)\n",
    "\n",
    "# Generation of Integrated Metacognitive Reflection\n",
    "response_short = response_text[:1000]\n",
    "\n",
    "reflection_prompt = f\"\"\"\n",
    "You have generated a scientific response regarding: \"{prompt}\"\n",
    "The SKEPTIC has analyzed your text and produced this report:\n",
    "\"{skeptical_report}\"\n",
    "\n",
    "Reflect on your performance (2-3 paragraphs):\n",
    "1. How do you explain the discrepancies or \"failures\" found by the skeptic?\n",
    "2. Did you detect any tendencies toward hallucination in the absence of certain data?\n",
    "3. How would you optimize your reasoning process for the next iteration?\n",
    "\"\"\"                                                                                                                   \n",
    "\n",
    "reflection_res = llm.invoke(reflection_prompt)\n",
    "reflection_content = getattr(reflection_res, \"content\", str(reflection_res)).strip()\n",
    "\n",
    "#Journal Logging\n",
    "journal = {}\n",
    "def record_journal(journal_id, prompt, response, reflection, skeptical_report):\n",
    "    journal[journal_id] = {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response,\n",
    "        \"reflection\": reflection,\n",
    "        \"skeptical_report\": skeptical_report\n",
    "    }\n",
    "\n",
    "record_journal(\n",
    "    journal_id=0,\n",
    "    prompt=prompt,\n",
    "    response=response_text,\n",
    "    reflection=reflection_content,\n",
    "    skeptical_report=skeptical_report\n",
    ")\n",
    "\n",
    "#Save to Markdown for Human Review\n",
    "def save_journal_markdown(data, file_name):\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# AGI Metacognitive Journal\\n\\n\")\n",
    "        f.write(f\"## User Input\\n> {data['prompt']}\\n\\n\")\n",
    "        f.write(f\"## Generated Response\\n{data['response']}\\n\\n\")\n",
    "        f.write(f\"## Critical Self-Reflection\\n{data['reflection']}\\n\\n\")\n",
    "        f.write(f\"## Skeptical Validation Report\\n{data['skeptical_report']}\\n\")\n",
    "\n",
    "#Create file with timestamp\n",
    "timestamp = datetime.datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"scientific_journal_{timestamp}.md\"\n",
    "save_journal_markdown(journal[0], filename)\n",
    "\n",
    "print(f\"Journal saved: {filename}\")\n",
    "display(FileLink(filename))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
